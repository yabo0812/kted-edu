{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   LangGraph 활용 - ReAct 에이전트 활용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
    "import os\n",
    "print(os.getenv('LANGSMITH_TRACING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **레스토랑 메뉴 DB**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 문서 로드`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "import re\n",
    "\n",
    "# 메뉴판 텍스트 데이터를 로드\n",
    "loader = TextLoader(\"./data/restaurant_menu.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(len(documents))\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 문서 분할 (Chunking)\n",
    "def split_menu_items(document):\n",
    "    \"\"\"\n",
    "    메뉴 항목을 분리하는 함수 \n",
    "    \"\"\"\n",
    "    # 정규표현식 정의 \n",
    "    pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "    menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "    \n",
    "    # 각 메뉴 항목을 Document 객체로 변환\n",
    "    menu_documents = []\n",
    "    for i, item in enumerate(menu_items, 1):\n",
    "        # 메뉴 이름 추출\n",
    "        menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "        \n",
    "        # 새로운 Document 객체 생성\n",
    "        menu_doc = Document(\n",
    "            page_content=item.strip(),\n",
    "            metadata={\n",
    "                \"source\": document.metadata['source'],\n",
    "                \"menu_number\": i,\n",
    "                \"menu_name\": menu_name\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "    \n",
    "    return menu_documents\n",
    "\n",
    "\n",
    "# 메뉴 항목 분리 실행\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"총 {len(menu_documents)}개의 메뉴 항목이 처리되었습니다.\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 와인 메뉴 텍스트를 로드\n",
    "wine_loader = TextLoader(\"./data/restaurant_wine.txt\", encoding=\"utf-8\")\n",
    "\n",
    "# 와인 메뉴 문서 생성\n",
    "wine_docs = wine_loader.load()\n",
    "\n",
    "# 와인 메뉴 문서 분할\n",
    "wine_documents = []\n",
    "for doc in wine_docs:\n",
    "    wine_documents += split_menu_items(doc)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"총 {len(wine_documents)}개의 와인 메뉴 항목이 처리되었습니다.\")\n",
    "for doc in wine_documents[:2]:\n",
    "    print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 벡터스토어 저장`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 임베딩 모델 생성\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 메뉴판 Chroma 인덱스 생성\n",
    "menu_db = Chroma.from_documents(\n",
    "    documents=menu_documents, \n",
    "    embedding=embeddings_model,   \n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "# 와인 메뉴 Chroma 인덱스 생성\n",
    "wine_db = Chroma.from_documents(\n",
    "    documents=wine_documents, \n",
    "    embedding=embeddings_model,   \n",
    "    collection_name=\"restaurant_wine\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 벡터 스토어 로드`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 임베딩 모델 생성\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 메뉴판 Chroma 인덱스 로드\n",
    "menu_db = Chroma(\n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=embeddings_model,\n",
    ")\n",
    "\n",
    "# 와인 메뉴 Chroma 인덱스 로드\n",
    "wine_db = Chroma(\n",
    "    collection_name=\"restaurant_wine\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=embeddings_model,\n",
    ")\n",
    "\n",
    "print(f\"메뉴판 DB: {menu_db._collection.count()}개의 문서가 있습니다.\")\n",
    "print(f\"와인 메뉴 DB: {wine_db._collection.count()}개의 문서가 있습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) 벡터 검색기 테스트`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever 생성\n",
    "menu_retriever = menu_db.as_retriever(\n",
    "    search_kwargs={'k': 2},\n",
    ")\n",
    "\n",
    "# 쿼리 테스트\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요?\"\n",
    "docs = menu_retriever.invoke(query)\n",
    "print(f\"검색 결과: {len(docs)}개\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_retriever = wine_db.as_retriever(\n",
    "    search_kwargs={'k': 2},\n",
    ")\n",
    "\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "docs = wine_retriever.invoke(query)\n",
    "print(f\"검색 결과: {len(docs)}개\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Tool 정의**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 사용자 정의 - @tool decorator`\n",
    "- 메뉴 검색을 위한 벡터저장소를 초기화 (기존 저장소를 로드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 메뉴 Chroma 인덱스 로드\n",
    "menu_db = Chroma(\n",
    "    collection_name=\"restaurant_menu\",\n",
    "    embedding_function=embeddings_model,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "# Tool 정의 \n",
    "@tool\n",
    "def search_menu(query: str, k: int = 2) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant menu information from the encrypted database.\n",
    "    Use this tool only for menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = menu_db.similarity_search(query, k=k)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 메뉴 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(search_menu))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_menu.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_menu.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_menu.args_schema.model_json_schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 와인 메뉴 Chroma 인덱스 로드\n",
    "wine_db = Chroma(\n",
    "    collection_name=\"restaurant_wine\",\n",
    "    embedding_function=embeddings_model,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "# Tool 정의\n",
    "@tool\n",
    "def search_wine(query: str, k: int = 2) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant wine menu information from the encrypted database.\n",
    "    Use this tool only for wine-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = wine_db.similarity_search(query, k=k)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 와인 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(search_wine))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_wine.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_wine.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_wine.args_schema.model_json_schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# LLM에 도구를 바인딩 (2개의 도구 바인딩)\n",
    "llm_with_tools = llm.bind_tools(tools=[search_menu, search_wine])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) LangChain 내장 도구`\n",
    "- 일반 웹 검색을 위한 Tavily 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "search_web = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 모델 \n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# 도구 목록\n",
    "tools = [search_menu, search_web]\n",
    "\n",
    "# 모델에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 도구 호출 \n",
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"스테이크 메뉴의 가격은 얼마인가요?\")])\n",
    "\n",
    "# 결과 출력\n",
    "pprint(tool_call.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출 \n",
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"인공지능 최신 동향은 무엇인가요?\")])\n",
    "\n",
    "# 결과 출력\n",
    "pprint(tool_call.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출 \n",
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"3+3은 얼마인가요?\")])\n",
    "\n",
    "# 결과 출력\n",
    "pprint(tool_call.additional_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Tool Node**\n",
    "\n",
    "- AI 모델이 요청한 도구(tool) 호출을 실행하는 역할을 처리하는 LangGraph 콤포넌트\n",
    "- 작동 방식:\n",
    "    - 가장 최근의 AIMessage에서 도구 호출 요청을 추출 (반드시, AIMessage는 반드시 tool_calls가 채워져 있어야 함)\n",
    "    - 요청된 도구들을 병렬로 실행\n",
    "    - 각 도구 호출에 대해 ToolMessage를 생성하여 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 도구 노드(Tool Node) 정의`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# 도구 노드 정의 \n",
    "tool_node = ToolNode(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출 \n",
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"스테이크 메뉴의 가격은 얼마인가요?\")])\n",
    "\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출 내용 출력\n",
    "pprint(tool_call.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 도구 노드(Tool Node) 실행`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출 결과를 메시지로 추가하여 실행 \n",
    "results = tool_node.invoke({\"messages\": [tool_call]})\n",
    "\n",
    "# 실행 결과 출력하여 확인 \n",
    "for result in results['messages']:\n",
    "    print(f\"메시지 타입: {type(result)}\")\n",
    "    print(f\"메시지 내용: {result.content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 메시지 개수 출력\n",
    "len(results['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 메시지에서 Document 객체 추출\n",
    "for doc in eval(results['messages'][0].content):\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **ReAct Agent**\n",
    "\n",
    "- ReAct(Reasoning and Acting) : 가장 일반적인 에이전트\n",
    "- 동작 방식:\n",
    "    - 행동 (act): 모델이 특정 도구를 호출\n",
    "    - 관찰 (observe): 도구의 출력을 모델에 다시 전달\n",
    "    - 추론 (reason): 모델이 도구 출력을 바탕으로 다음 행동을 결정 (예: 또 다른 도구를 호출하거나 직접 응답을 생성)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 조건부 엣지 함수를 사용자 정의`\n",
    "- `should_continue` 함수에서 도구 호출 여부에 따라 종료 여부를 결정\n",
    "- 도구 실행이 필요한 경우에는 그래프가 종료되지 않고 계속 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# LangGraph MessagesState 사용 (메시지 리스트를 저장하는 상태)\n",
    "class GraphState(MessagesState):\n",
    "    ...\n",
    "\n",
    "\n",
    "# 노드 구성 \n",
    "def call_model(state: GraphState):\n",
    "    system_prompt = SystemMessage(\"\"\"You are a helpful AI assistant. Please respond to the user's query to the best of your ability!\n",
    "\n",
    "중요: 답변을 제공할 때 반드시 정보의 출처를 명시해야 합니다. 출처는 다음과 같이 표시하세요:\n",
    "- 도구를 사용하여 얻은 정보: [도구: 도구이름]\n",
    "- 모델의 일반 지식에 기반한 정보: [일반 지식]\n",
    "\n",
    "항상 정확하고 관련성 있는 정보를 제공하되, 확실하지 않은 경우 그 사실을 명시하세요. 출처를 명확히 표시함으로써 사용자가 정보의 신뢰성을 판단할 수 있도록 해주세요.\"\"\")\n",
    "    \n",
    "    # 시스템 메시지와 이전 메시지를 결합하여 모델 호출\n",
    "    messages = [system_prompt] + state['messages']\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "    # 메시지 리스트로 반환하고 상태 업데이트\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: GraphState):\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # 마지막 메시지에 도구 호출이 있으면 도구 실행\n",
    "    if last_message.tool_calls:\n",
    "        return \"execute_tools\"\n",
    "    \n",
    "    return END\n",
    "\n",
    "# 그래프 구성\n",
    "builder = StateGraph(GraphState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"execute_tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_conditional_edges(\n",
    "    \"call_model\", \n",
    "    should_continue,\n",
    "    {\n",
    "        \"execute_tools\": \"execute_tools\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "builder.add_edge(\"execute_tools\", \"call_model\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 출력 \n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "inputs = {\"messages\": [HumanMessage(content=\"스테이크 메뉴의 가격은 얼마인가요?\")]}\n",
    "messages = graph.invoke(inputs)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) tools_condition 활용`\n",
    "- LangGraph에서 제공하는 도구 사용을 위한 조건부 엣지 함수\n",
    "- 최신 메시지(결과)가 도구 호출이면 -> `tools_condition`이 도구로 라우팅\n",
    "- 최신 메시지(결과)가 도구 호출이 아니면 -> `tools_condition`이 `END`로 라우팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# 노드 함수 정의\n",
    "def call_model(state: GraphState):\n",
    "    system_prompt = SystemMessage(\"\"\"You are a helpful AI assistant. Please respond to the user's query to the best of your ability!\n",
    "\n",
    "중요: 답변을 제공할 때 반드시 정보의 출처를 명시해야 합니다. 출처는 다음과 같이 표시하세요:\n",
    "- 도구를 사용하여 얻은 정보: [도구: 도구이름]\n",
    "- 모델의 일반 지식에 기반한 정보: [일반 지식]\n",
    "\n",
    "항상 정확하고 관련성 있는 정보를 제공하되, 확실하지 않은 경우 그 사실을 명시하세요. 출처를 명확히 표시함으로써 사용자가 정보의 신뢰성을 판단할 수 있도록 해주세요.\"\"\")\n",
    "    \n",
    "    # 시스템 메시지와 이전 메시지를 결합하여 모델 호출\n",
    "    messages = [system_prompt] + state['messages']\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "    # 메시지 리스트로 반환하고 상태 업데이트\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 그래프 구성\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "builder.add_node(\"agent\", call_model)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"agent\")\n",
    "\n",
    "# tools_condition을 사용한 조건부 엣지 추가\n",
    "builder.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 출력\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "inputs = {\"messages\": [HumanMessage(content=\"파스타에 어울리는 와인을 추천해주세요.\")]}\n",
    "messages = graph.invoke(inputs)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) ReAct 활용`\n",
    "- LangGraph에서 제공하는 ReAct 에이전트 콤포넌트를 활용하여 도구 호출과 응답 생성을 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 도구 목록 정의\n",
    "tools = [search_menu, search_wine, search_web]\n",
    "\n",
    "# LLM 모델 생성\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# 시스템 프롬프트 정의\n",
    "system_prompt = \"\"\"You are a helpful AI assistant. Please respond to the user's query to the best of your ability!\n",
    "\n",
    "중요: 답변을 제공할 때 반드시 정보의 출처를 명시해야 합니다. 출처는 다음과 같이 표시하세요:\n",
    "- 도구를 사용하여 얻은 정보: [도구: 도구이름]\n",
    "- 모델의 일반 지식에 기반한 정보: [일반 지식]\n",
    "\n",
    "항상 정확하고 관련성 있는 정보를 제공하되, 확실하지 않은 경우 그 사실을 명시하세요. 출처를 명확히 표시함으로써 사용자가 정보의 신뢰성을 판단할 수 있도록 해주세요.\"\"\"\n",
    "\n",
    "# 시스템 프롬프트와 함께 에이전트 생성\n",
    "graph = create_react_agent(\n",
    "    model, \n",
    "    tools=tools, \n",
    "    prompt=system_prompt\n",
    ")\n",
    "\n",
    "# 사용\n",
    "inputs = {\"messages\": [(\"user\", \"스테이크 메뉴의 가격은 얼마인가요?\")]}\n",
    "messages = graph.invoke(inputs)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

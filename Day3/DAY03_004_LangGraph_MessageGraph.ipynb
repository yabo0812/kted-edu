{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   LangGraph 활용 - 메시지 그래프 + 리듀서 구현\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
    "import os\n",
    "print(os.getenv('LANGSMITH_TRACING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Reducer (리듀서)**\n",
    "\n",
    "- **State Reducer**는 LangGraph의 **상태 관리 핵심 메커니즘**\n",
    "\n",
    "- 각 노드의 출력을 **전체 그래프 상태에 통합**하는 방식을 정의\n",
    "\n",
    "- **Reducer의 필요성**:\n",
    "\n",
    "    - **상태 덮어쓰기 문제**: 기본적으로 각 노드의 반환값은 해당 상태 키의 이전 값을 덮어쓰는 방식으로 동작 (override)\n",
    "    \n",
    "    - **누적 업데이트 필요**: 특히 메시지 리스트와 같은 경우, 이전 상태에 새로운 값을 추가하고 싶을 때가 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Reducer를 별도로 지정하지 않은 경우 `\n",
    "\n",
    "- **기본 Reducer**는 이전 값을 **자동으로 덮어쓰는** 방식으로 작동\n",
    "- Reducer 설정이 없는 경우 **자동으로 기본값**이 적용\n",
    "- 이는 단순한 상태 업데이트에는 적합하나 **데이터 누적이 필요한 경우 부적절**\n",
    "- 기본 Reducer는 **간단한 상태 관리**에 적합하지만 복잡한 데이터 처리에는 한계가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 상태 정의 \n",
    "class DocumentState(TypedDict):\n",
    "    query: str\n",
    "    documents: List[str]\n",
    "\n",
    "# Node 1: query 업데이트\n",
    "def node_1(state: DocumentState) -> DocumentState:\n",
    "    print(\"---Node 1 (query update)---\")\n",
    "    query = state[\"query\"]\n",
    "    return {\"query\": query}\n",
    "\n",
    "# Node 2: 검색된 문서 추가 \n",
    "def node_2(state: DocumentState) -> DocumentState:\n",
    "    print(\"---Node 2 (add documents)---\")\n",
    "    return {\"documents\": [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]}\n",
    "\n",
    "# Node 3: 추가적인 문서 검색 결과 추가\n",
    "def node_3(state: DocumentState) -> DocumentState:\n",
    "    print(\"---Node 3 (add more documents)---\")\n",
    "    return {\"documents\": [\"doc2.pdf\", \"doc4.pdf\", \"doc5.pdf\"]}\n",
    "\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(DocumentState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# 논리 구성\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# 그래프 실행\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\"query\": \"채식주의자를 위한 비건 음식을 추천해주세요.\", \"documents\": None}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"-\"*100)\n",
    "print(\"최종 상태:\")\n",
    "print(\"쿼리:\", final_state['query'])\n",
    "print(\"검색된 문서:\", final_state['documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) Reducer를 별도로 지정하는 경우 `\n",
    "\n",
    "- **Annotated**를 통해 **사용자 정의 Reducer**를 지정할 수 있음 \n",
    "- **operator.add**를 사용하면 리스트 형태의 데이터를 **누적 관리**할 수 있음 \n",
    "- 여기서는 기존 리스트에 새로운 메시지를 추가하는 방식으로 작동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "class ReducerState(TypedDict):\n",
    "    query: str\n",
    "    documents: Annotated[List[str], add]\n",
    "\n",
    "# Node 1: query 업데이트\n",
    "def node_1(state: ReducerState) -> ReducerState:\n",
    "    print(\"---Node 1 (query update)---\")\n",
    "    query = state[\"query\"]\n",
    "    return {\"query\": query}\n",
    "\n",
    "# Node 2: 검색된 문서 추가 \n",
    "def node_2(state: ReducerState) -> ReducerState:\n",
    "    print(\"---Node 2 (add documents)---\")\n",
    "    return {\"documents\": [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]}\n",
    "\n",
    "# Node 3: 추가적인 문서 검색 결과 추가\n",
    "def node_3(state: ReducerState) -> ReducerState:\n",
    "    print(\"---Node 3 (add more documents)---\")\n",
    "    return {\"documents\": [\"doc2.pdf\", \"doc4.pdf\", \"doc5.pdf\"]}\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(ReducerState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# 논리 구성\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# 그래프 실행\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\"query\": \"채식주의자를 위한 비건 음식을 추천해주세요.\", \"documents\": []}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"-\"*100)\n",
    "print(\"최종 상태:\")\n",
    "print(\"쿼리:\", final_state['query'])\n",
    "print(\"검색된 문서:\", final_state['documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Custom Reducer 사용 `\n",
    "\n",
    "- **Custom Reducer**는 **복잡한 상태 관리**가 필요할 때 사용됨 \n",
    "- **중복 제거**나 **최대/최소값 유지**와 같은 특수한 로직을 구현할 수 있음 \n",
    "- 비즈니스 요구사항에 맞는 **맞춤형 상태 관리**가 가능\n",
    "- 상황에 따라 **조건부 병합**과 같은 고급 기능을 구현할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated\n",
    "\n",
    "# Custom reducer: 중복된 문서를 제거하며 리스트 병합\n",
    "def reduce_unique_documents(left: list | None, right: list | None) -> list:\n",
    "    \"\"\"Combine two lists of documents, removing duplicates.\"\"\"\n",
    "    if not left:\n",
    "        left = []\n",
    "    if not right:\n",
    "        right = []\n",
    "    # 중복 제거: set을 사용하여 중복된 문서를 제거하고 다시 list로 변환\n",
    "    return list(set(left + right))\n",
    "\n",
    "# 상태 정의 (documents 필드 포함)\n",
    "class CustomReducerState(TypedDict):\n",
    "    query: str\n",
    "    documents: Annotated[List[str], reduce_unique_documents]  # Custom Reducer 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 1: query 업데이트\n",
    "def node_1(state: CustomReducerState) -> CustomReducerState:\n",
    "    print(\"---Node 1 (query update)---\")\n",
    "    query = state[\"query\"]\n",
    "    return {\"query\": query}\n",
    "\n",
    "# Node 2: 검색된 문서 추가 \n",
    "def node_2(state: CustomReducerState) -> CustomReducerState:\n",
    "    print(\"---Node 2 (add documents)---\")\n",
    "    return {\"documents\": [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]}\n",
    "\n",
    "# Node 3: 추가적인 문서 검색 결과 추가\n",
    "def node_3(state: CustomReducerState) -> CustomReducerState:\n",
    "    print(\"---Node 3 (add more documents)---\")\n",
    "    return {\"documents\": [\"doc2.pdf\", \"doc4.pdf\", \"doc5.pdf\"]}\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(CustomReducerState)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# 논리 구성\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# 그래프 실행\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\"query\": \"채식주의자를 위한 비건 음식을 추천해주세요.\", \"documents\": []}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"-\"*100)\n",
    "print(\"최종 상태:\")\n",
    "print(\"쿼리:\", final_state['query'])\n",
    "print(\"검색된 문서:\", final_state['documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Message 사용**\n",
    "\n",
    "- **LangGraph**는 **메시지 목록** 기반의 채팅 모델 인터페이스를 활용\n",
    "\n",
    "- `HumanMessage`와 `AIMessage` 등 다양한 메시지 타입을 지원\n",
    "\n",
    "- 그래프 상태에서 대화 기록은 **메시지 객체 리스트**로 저장되며, 이를 통해 효율적인 대화 관리를 가능\n",
    "\n",
    "- **reducer 함수**를 통해 상태 업데이트 시 메시지 목록이 어떻게 갱신될지 정의할 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) operator.add`\n",
    "\n",
    "- 메시지 목록에 새로운 메시지를 간단히 추가하는 기본적인 reducer 함수\n",
    "    1. `messages` 키가 메시지 리스트를 저장\n",
    "    2. `add` reducer가 새 메시지를 기존 리스트에 추가\n",
    "    3. 모든 종류의 메시지(`HumanMessage`, `AIMessage` 등)가 허용됨\n",
    "\n",
    "- 주의사항:\n",
    "    - `operator.add`는 단순히 리스트를 연결\n",
    "    - 중복 메시지도 추가됨\n",
    "    - 메시지 삭제나 수정은 불가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from operator import add\n",
    "\n",
    "# 상태 정의\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add]\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# chatbot 노드 함수 정의\n",
    "def chatbot(state: GraphState) -> GraphState:\n",
    "    # LLM을 사용하여 챗봇 메시지 생성\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow Graph\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 초기 상태\n",
    "initial_state = {\"messages\": [(\"user\", \"안녕하세요!\")]}\n",
    "\n",
    "# 그래프 실행\n",
    "for event in graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    pprint(event['messages'])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) add_messages`\n",
    "\n",
    "- 메시지 ID를 기반으로 기존 메시지를 업데이트하거나 새 메시지를 추가하는 고급 관리 기능을 제공\n",
    "    - 새 메시지는 기존 목록에 추가\n",
    "    - 기존 메시지 업데이트도 올바르게 처리 (메시지 ID를 추적)\n",
    "\n",
    "- 기존 메시지의 중복 추가를 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# add_messages 사용 상태 정의\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# chatbot 노드 함수 정의\n",
    "def chatbot(state: GraphState) -> GraphState:\n",
    "    # LLM을 사용하여 챗봇 메시지 생성\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Workflow Graph\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 초기 상태\n",
    "initial_state = {\"messages\": [(\"user\", \"안녕하세요!\")]}\n",
    "\n",
    "# 그래프 실행\n",
    "for event in graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    pprint(event['messages'])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) MessagesState`\n",
    "\n",
    "- **`MessagesState`** 는 메시지 관리를 위해 미리 정의된 상태 타입\n",
    "\n",
    "- 이 상태는 **`add_messages` reducer**를 기본으로 사용하여 메시지 업데이트를 자동으로 처리\n",
    "\n",
    "- `AnyMessage` 객체 리스트를 포함하는 **단일 `messages` 키**로 구성되어 있어 구조가 단순함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# messages 키를 가진 상태 생성 (messages 키는 기본 제공)\n",
    "class GraphState(MessagesState):  # MessagesState 상속\n",
    "    ... \n",
    "    # 추가적인 필드 정의 가능\n",
    "    # custom_field: str\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# chatbot 노드 함수 정의\n",
    "def chatbot(state: GraphState) -> GraphState:\n",
    "    # LLM을 사용하여 챗봇 메시지 생성\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Workflow Graph\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 초기 상태\n",
    "initial_state = {\"messages\": [(\"user\", \"안녕하세요!\")]}\n",
    "\n",
    "# 그래프 실행\n",
    "for event in graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    pprint(event['messages'])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) MessagesState 커스텀 필드 추가`\n",
    "\n",
    "- **MessagesState**를 상속받아 추가 필드를 포함하는 새로운 상태 타입을 정의할 수 있음 \n",
    "\n",
    "- 기존 `messages` 키의 **`add_messages` reducer** 기능을 그대로 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# MessagesState를 상속하여 커스텀 필드 추가\n",
    "class GraphState(MessagesState):\n",
    "    # 사용자의 감정 상태를 추적하는 필드 추가\n",
    "    emotion: Optional[str] \n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# 감정 분석을 위한 프롬프트 템플릿\n",
    "EMOTION_PROMPT = \"\"\"\n",
    "사용자의 메시지를 분석하여 감정 상태를 파악해주세요.\n",
    "가능한 감정 상태: 행복, 슬픔, 화남, 중립\n",
    "\n",
    "사용자 메시지: {message}\n",
    "\n",
    "감정 상태만 한 단어로 답변해주세요.\n",
    "\"\"\"\n",
    "\n",
    "# 감정 분석 노드\n",
    "def analyze_emotion(state: GraphState) -> GraphState:\n",
    "    # 가장 최근 사용자 메시지 가져오기\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    \n",
    "    # 감정 분석 실행\n",
    "    emotion_analysis = llm.invoke(EMOTION_PROMPT.format(message=last_message))\n",
    "    \n",
    "    # 상태 업데이트\n",
    "    return {\n",
    "        \"emotion\": emotion_analysis.content.strip()\n",
    "    }\n",
    "\n",
    "# 챗봇 응답 노드\n",
    "def chatbot(state: GraphState) -> GraphState:\n",
    "    # 현재 감정 상태를 고려한 시스템 메시지 생성\n",
    "    system_message = f\"\"\"\n",
    "    사용자의 현재 감정 상태는 {state['emotion']}입니다.\n",
    "    이를 고려하여 공감적이고 적절한 응답을 해주세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 기존 메시지에 시스템 메시지 추가\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + state[\"messages\"]\n",
    "    \n",
    "    # LLM 응답 생성\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Workflow Graph 구성\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# 노드 추가\n",
    "builder.add_node(\"analyze_emotion\", analyze_emotion)\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 엣지 추가\n",
    "builder.add_edge(START, \"analyze_emotion\")\n",
    "builder.add_edge(\"analyze_emotion\", \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태\n",
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"오늘 정말 힘든 하루였어요...\"}]\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "for event in graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    if \"emotion\" in event:\n",
    "        print(f\"감정 상태: {event['emotion']}\")\n",
    "    if \"messages\" in event:\n",
    "        print(\"메시지:\")\n",
    "        for msg in event[\"messages\"]:\n",
    "            print(f\"{msg.type}: {msg.content}\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **[예제]**\n",
    "\n",
    "- 문제: 주어진 텍스트에 대해 검색-요약-팩트체크의 3단계 파이프라인을 구현하는 LangGraph 워크플로우를 작성하세요.\n",
    "\n",
    "- 입력/출력:\n",
    "  * 입력: 검색할 주제나 질문\n",
    "  * 출력: 관련 정보 검색 결과, 요약본, 팩트체크 결과\n",
    "\n",
    "- 제약사항:\n",
    "  * LangGraph의 StateGraph를 사용하여 구현\n",
    "  * 최소 3개의 노드(검색, 요약, 팩트체크) 구현\n",
    "  * MessagesState를 상속한 커스텀 상태 클래스 사용\n",
    "  * 각 단계의 신뢰도 점수 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Dict, Any\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "class ResearchState(MessagesState):\n",
    "    search_results: Optional[List[Dict[str, Any]]]  # 검색 결과를 저장하는 필드\n",
    "    summary: Optional[str]\n",
    "    fact_check: Optional[Dict[str, Any]]\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# 검색 노드\n",
    "def search_info(state: ResearchState) -> ResearchState:\n",
    "    search_tool = TavilySearchResults(\n",
    "        max_results=5,  # 반환할 결과의 수\n",
    "        search_depth=\"advanced\",  # 검색 깊이: basic 또는 advanced\n",
    "        include_answer=True,  # 결과에 직접적인 답변 포함\n",
    "        include_raw_content=True,  # 페이지의 원시 콘텐츠 포함\n",
    "        include_images=True,  # 결과에 이미지 포함\n",
    "    )\n",
    "\n",
    "    # 사용자의 마지막 메시지에서 쿼리 추출\n",
    "    query = state[\"messages\"][-1].content\n",
    "    \n",
    "    # 검색 실행\n",
    "    results = search_tool.invoke(query)\n",
    "    \n",
    "    return {\n",
    "        \"search_results\": results  \n",
    "    }\n",
    "\n",
    "# 요약 노드\n",
    "def generate_summary(state: ResearchState) -> ResearchState:\n",
    "    if not state[\"search_results\"]:\n",
    "        return {\"summary\": \"검색 결과가 없습니다.\"}\n",
    "    \n",
    "    summary_prompt = \"\"\"\n",
    "    다음 검색 결과들을 요약해주세요:\n",
    "    {search_results}\n",
    "    \n",
    "    핵심 포인트 3-4개로 간단히 요약:\n",
    "    \"\"\"\n",
    "    \n",
    "    # 검색 결과를 문자열로 변환하여 프롬프트에 포함\n",
    "    formatted_results = []\n",
    "    for item in state[\"search_results\"]:\n",
    "        if \"raw_content\" in item:\n",
    "            formatted_results.append(f\"제목: {item.get('title', 'No title')}\\n내용: {item['raw_content']}\\n링크: {item.get('url', 'No URL')}\\n\")\n",
    "        else:\n",
    "            formatted_results.append(f\"제목: {item.get('title', 'No title')}\\n내용: {item.get('content', 'No content')}\\n링크: {item.get('url', 'No URL')}\\n\")\n",
    "    \n",
    "    search_text = \"\\n\\n\".join(formatted_results)\n",
    "    \n",
    "    summary = llm.invoke(summary_prompt.format(\n",
    "        search_results=search_text\n",
    "    ))\n",
    "    \n",
    "    return {\"summary\": summary.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class FactCheckResult(BaseModel):\n",
    "    \"\"\"팩트체크 결과를 위한 스키마\"\"\"\n",
    "    confidence: str = Field(\n",
    "        description=\"문장에 대한 팩트체크 신뢰도 점수 (0-1 사이의 값)\"\n",
    "    )\n",
    "\n",
    "# 팩트체크 노드\n",
    "def check_fact(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"요약 내용에 대한 팩트체크를 수행하는 노드\"\"\"\n",
    "    \n",
    "    if not state[\"summary\"]:\n",
    "        return {\"fact_check\": {\"scores\": {}}}\n",
    "    \n",
    "    fact_check_prompt = \"\"\"다음 요약 내용의 각 문장에 대해 신뢰도를 평가해주세요.\n",
    "\n",
    "요약 내용:\n",
    "{summary}\n",
    "\n",
    "각 문장의 신뢰도를 0과 1 사이의 숫자로 평가하여 JSON 형식으로 반환해주세요.\n",
    "신뢰도가 높을수록 1에 가깝고, 낮을수록 0에 가깝습니다.\n",
    "\n",
    "예시 응답 형식:\n",
    "{{\n",
    "    \"scores\": {{\n",
    "        \"1\": 0.9,  # 첫 번째 문장의 신뢰도\n",
    "        \"2\": 0.7,  # 두 번째 문장의 신뢰도\n",
    "        \"3\": 0.85  # 세 번째 문장의 신뢰도\n",
    "    }}\n",
    "}}\n",
    "\n",
    "요약의 각 문장을 평가하여 위와 같은 형식으로 신뢰도 점수를 반환해주세요.\"\"\"\n",
    "    \n",
    "    fact_checker = llm.with_structured_output(FactCheckResult)\n",
    "    \n",
    "    try:\n",
    "        result = fact_checker.invoke(\n",
    "            fact_check_prompt.format(summary=state[\"summary\"])\n",
    "        )\n",
    "        return {\"fact_check\": result.model_dump()}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"팩트체크 중 오류 발생: {str(e)}\")\n",
    "        return {\"fact_check\": {\"scores\": {}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 구성\n",
    "builder = StateGraph(ResearchState)\n",
    "\n",
    "builder.add_node(\"search_info\", search_info)\n",
    "builder.add_node(\"generate_summary\", generate_summary)\n",
    "builder.add_node(\"check_fact\", check_fact)\n",
    "\n",
    "builder.add_edge(START, \"search_info\")\n",
    "builder.add_edge(\"search_info\", \"generate_summary\")\n",
    "builder.add_edge(\"generate_summary\", \"check_fact\")\n",
    "builder.add_edge(\"check_fact\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"인공지능의 환경적 영향은?\"}]\n",
    "})\n",
    "\n",
    "print(f\"검색 결과 수: {len(result['search_results'])}\")\n",
    "print(\"검색 결과:\", result[\"search_results\"])\n",
    "print(\"-\" * 100)\n",
    "print(f\"요약: {result['summary']}\")\n",
    "print(f\"팩트체크 결과: {result['fact_check']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **병렬 처리**\n",
    "\n",
    "- **분기(branching)** 기능을 통해 LangGraph에서 노드의 병렬 실행이 가능\n",
    "\n",
    "- 병렬 처리는 **독립적인 작업**들을 동시에 실행함으로써 전체 처리 시간을 단축\n",
    "\n",
    "- 다양한 데이터 소스에서 **정보 수집 및 처리**가 필요한 경우 병렬 실행이 특히 효과적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 표준 엣지를 사용한 분기 (Fan-out/Fan-in)`\n",
    "\n",
    "- **Fan-out** 구조는 하나의 노드에서 여러 병렬 노드로 데이터를 분산시키는 방식을 구현\n",
    "\n",
    "- **Fan-in** 구조는 병렬로 처리된 여러 노드의 결과를 단일 노드에서 취합하는 역할\n",
    "\n",
    "- 가장 기본적이고 직관적인 병렬 처리 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 검색 엔진에서 정보 가져오기\n",
    "\n",
    "import operator\n",
    "from typing import Annotated, Any, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 상태 정의: 검색 결과를 누적할 리스트를 포함\n",
    "class SearchState(TypedDict):\n",
    "    search_results: Annotated[list, operator.add]\n",
    "\n",
    "# 각 검색 엔진에 대한 노드 정의\n",
    "def search_engine_a(state: SearchState):\n",
    "    print(\"Searching with Engine A...\")\n",
    "    return {\"search_results\": [\"Result A1\", \"Result A2\"]}\n",
    "\n",
    "def search_engine_b(state: SearchState):\n",
    "    print(\"Searching with Engine B...\")\n",
    "    return {\"search_results\": [\"Result B1\"]}\n",
    "\n",
    "def combine_results(state: SearchState):\n",
    "    print(\"Combining search results...\")\n",
    "    return {\"search_results\": [\"Combined Result\"]}\n",
    "\n",
    "# 그래프 구성\n",
    "search_builder = StateGraph(SearchState)\n",
    "search_builder.add_node(\"engine_a\", search_engine_a)\n",
    "search_builder.add_node(\"engine_b\", search_engine_b)\n",
    "search_builder.add_node(\"combine\", combine_results)\n",
    "\n",
    "# 엣지 연결: START -> engine_a, engine_b (병렬 실행) -> combine -> END\n",
    "search_builder.add_edge(START, \"engine_a\")\n",
    "search_builder.add_edge(START, \"engine_b\")\n",
    "search_builder.add_edge(\"engine_a\", \"combine\")\n",
    "search_builder.add_edge(\"engine_b\", \"combine\")\n",
    "search_builder.add_edge(\"combine\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "search_graph = search_builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(search_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "search_graph.invoke({\"search_results\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 조건부 엣지를 사용한 분기 (Conditional Branching)`\n",
    "\n",
    "- **Fan-out** 구조는 하나의 노드에서 여러 병렬 노드로 데이터를 분산시키는 방식을 구현\n",
    "\n",
    "- **Fan-in** 구조는 병렬로 처리된 여러 노드의 결과를 단일 노드에서 취합하는 역할\n",
    "\n",
    "- 가장 기본적이고 직관적인 병렬 처리 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**구현 예시**\n",
    "\n",
    "- 초기 그리팅 후 조건부로 서비스를 실행\n",
    "- 선택된 서비스들을 병렬로 실행\n",
    "- 모든 서비스 실행 후 최종 처리를 수행\n",
    "- 전체 과정의 상태를 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 상태 정의: aggregate 리스트와 라우팅을 위한 user_intent 필드 포함\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list, operator.add]  # aggregate 대신 messages 사용\n",
    "    user_intent: str  # 라우팅 조건\n",
    "\n",
    "# 서비스 노드 정의\n",
    "def greet_service(state: ChatState):\n",
    "    print(f'Adding \"greet\" to {state[\"messages\"]}')\n",
    "    return {\"messages\": [\"Hello!\"]} \n",
    "\n",
    "def weather_service(state: ChatState):\n",
    "    print(f'Adding \"weather\" to {state[\"messages\"]}')\n",
    "    return {\"messages\": [\"The weather is sunny.\"]}\n",
    "\n",
    "def news_service(state: ChatState):\n",
    "    print(f'Adding \"news\" to {state[\"messages\"]}')\n",
    "    return {\"messages\": [\"Here's the latest news.\"]}\n",
    "\n",
    "def help_service(state: ChatState):\n",
    "    print(f'Adding \"help\" to {state[\"messages\"]}')\n",
    "    return {\"messages\": [\"How can I help you?\"]}\n",
    "\n",
    "def process_response(state: ChatState):\n",
    "    print(f'Adding \"process\" to {state[\"messages\"]}')\n",
    "    return {\"messages\": [\"Processing complete.\"]}\n",
    "\n",
    "# 라우팅 함수: user_intent 값에 따라 서비스 노드 결정\n",
    "def route_services(state: ChatState) -> Sequence[str]:\n",
    "    if state[\"user_intent\"] == \"weather_news\":\n",
    "        # 날씨와 뉴스 서비스를 병렬 실행\n",
    "        return [\"weather_service\", \"news_service\"]\n",
    "    \n",
    "    # 기본적으로 인사와 뉴스 서비스를 병렬 실행\n",
    "    return [\"help_service\", \"news_service\"]\n",
    "\n",
    "# 그래프 구성\n",
    "chat_builder = StateGraph(ChatState)\n",
    "\n",
    "# 노드 추가\n",
    "chat_builder.add_node(\"greet\", greet_service)\n",
    "chat_builder.add_node(\"weather_service\", weather_service)\n",
    "chat_builder.add_node(\"news_service\", news_service)\n",
    "chat_builder.add_node(\"help_service\", help_service)\n",
    "chat_builder.add_node(\"process\", process_response)\n",
    "\n",
    "# 엣지 추가\n",
    "chat_builder.add_edge(START, \"greet\")\n",
    "\n",
    "# 중간 노드 정의\n",
    "intermediates = [\"weather_service\", \"news_service\", \"help_service\"]\n",
    "\n",
    "# greet 노드에서 조건부 엣지 추가\n",
    "chat_builder.add_conditional_edges(\n",
    "    \"greet\",\n",
    "    route_services,\n",
    "    intermediates,\n",
    ")\n",
    "\n",
    "# 중간 노드들을 process 노드에 연결\n",
    "for node in intermediates:\n",
    "    chat_builder.add_edge(node, \"process\")\n",
    "\n",
    "chat_builder.add_edge(\"process\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "chat_graph = chat_builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(chat_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"weather_news\" 의도를 가지고 실행\n",
    "chat_graph.invoke({\"messages\": [], \"user_intent\": \"weather_news\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 의도를 가지고 실행\n",
    "chat_graph.invoke({\"messages\": [], \"user_intent\": \"news\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 다단계 분기 (Multi-step Parallel Paths)`\n",
    "\n",
    "- **다단계 분기**는 각각의 병렬 경로에서 여러 단계의 독립적인 처리를 지원 \n",
    "\n",
    "- 각 분기는 **서로 다른 데이터 처리 파이프라인**을 포함할 수 있어, 복잡한 워크플로우 구현이 가능\n",
    "\n",
    "- 최종적으로 각 분기의 결과는 하나의 노드에서 **통합되어 처리**될 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리와 모델 예측을 병렬로 수행하기\n",
    "\n",
    "import operator\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class ModelState(TypedDict):\n",
    "    data: Annotated[list, operator.add]\n",
    "\n",
    "def fetch_data_a(state: ModelState):\n",
    "    return {\"data\": [\"Data A1\"]}\n",
    "\n",
    "def preprocess_data_a(state: ModelState):\n",
    "    return {\"data\": [\"Preprocessed A1\"]}\n",
    "\n",
    "def fetch_data_b(state: ModelState):\n",
    "    return {\"data\": [\"Data B1\"]}\n",
    "\n",
    "def make_prediction(state: ModelState):\n",
    "    return {\"data\": [\"Prediction from A and B\"]}\n",
    "\n",
    "model_builder = StateGraph(ModelState)\n",
    "model_builder.add_node(\"fetch_a\", fetch_data_a)\n",
    "model_builder.add_node(\"preprocess_a\", preprocess_data_a)\n",
    "model_builder.add_node(\"fetch_b\", fetch_data_b)\n",
    "model_builder.add_node(\"predict\", make_prediction)\n",
    "\n",
    "model_builder.add_edge(START, \"fetch_a\")\n",
    "model_builder.add_edge(START, \"fetch_b\")\n",
    "model_builder.add_edge(\"fetch_a\", \"preprocess_a\")\n",
    "model_builder.add_edge([\"preprocess_a\", \"fetch_b\"], \"predict\")\n",
    "model_builder.add_edge(\"predict\", END)\n",
    "\n",
    "model_graph = model_builder.compile()\n",
    "\n",
    "display(Image(model_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "model_graph.invoke({\"data\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) 동적 엣지 생성 및 개별 상태 전달하기 (Map-Reduce 패턴)`\n",
    "\n",
    "- **기본 동작의 한계**\n",
    "\n",
    "    - 기본적으로 LangGraph의 노드와 엣지는 미리 정의되며, 모든 노드는 동일한 공유 상태(shared state)를 사용함. 하지만 다음과 같은 경우에는 문제가 발생할 수 있음. \n",
    "\n",
    "    -  **동적 엣지:** 실행 시점에 따라 연결해야 할 노드의 수가 달라지는 경우 (예: 입력 데이터에 따라 다른 개수의 하위 작업을 생성해야 하는 경우)\n",
    "    -  **개별 상태:** 각 노드가 독립적인 상태를 가지고 작업해야 하는 경우 (예: 각 하위 작업이 서로 다른 데이터를 처리해야 하는 경우)\n",
    "\n",
    "- **Map-Reduce 패턴**\n",
    "\n",
    "    1.  **Map:**  하나의 노드(mapper)가 여러 개의 객체(또는 작업)를 생성\n",
    "    2.  **Reduce:** 다른 노드(reducer)가 mapper가 생성한 객체들을 처리하고 결과를 결합\n",
    "\n",
    "-  **`Send` 객체**\n",
    "\n",
    "    - LangGraph에서는 `Send` 객체를 사용하여 map 단계를 구현할 수 있음 \n",
    "    - `Send` 객체는 조건부 엣지(`add_conditional_edges`)의 `condition_function`에서 반환될 수 있으며, 다음과 같은 두 가지 인수를 받아서 구현\n",
    "\n",
    "        1.  **`node_name` (str):**  실행할 노드의 이름\n",
    "        2.  **`state` (dict):** 해당 노드에 전달할 개별 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 글로벌 상태 정의\n",
    "class WebScrapingState(TypedDict):\n",
    "    urls: List[str]  # 스크래핑할 URL 목록 (글로벌)\n",
    "    scraped_data: Annotated[List[dict], operator.add]  # 스크래핑된 데이터 (글로벌, 누적)\n",
    "\n",
    "# 노드 정의\n",
    "def define_urls(state: WebScrapingState):\n",
    "    \"\"\"URL 목록을 정의합니다. (글로벌 상태 사용)\"\"\"\n",
    "    print(\"Using provided URLs...\")\n",
    "    return {\"urls\": state[\"urls\"]}  # 글로벌 상태(urls) 사용\n",
    "\n",
    "def scrape_website(state: dict):  # 로컬 상태를 받음\n",
    "    \"\"\"각 웹사이트를 스크래핑합니다. (로컬 상태 사용)\"\"\"\n",
    "    print(f\"Scraping {state['url']}...\")  # 로컬 상태(url) 사용\n",
    "    # 실제 스크래핑 로직 (여기서는 시뮬레이션)\n",
    "    return {\"scraped_data\": [f\"Data from {state['url']}\"]} # 글로벌 상태(scraped_data) 사용\n",
    "\n",
    "def route_to_scraping(state: WebScrapingState):\n",
    "    \"\"\"스크래핑 노드로 라우팅합니다. (글로벌 상태 사용, 로컬 상태 생성)\"\"\"\n",
    "    # 글로벌 상태(urls)를 사용하여 로컬 상태({\"url\": url})를 생성하고 Send로 전달\n",
    "    return [Send(\"scrape_website\", {\"url\": url}) for url in state[\"urls\"]]\n",
    "\n",
    "\n",
    "# 그래프 구성\n",
    "graph = StateGraph(WebScrapingState)  \n",
    "graph.add_node(\"define_urls\", define_urls)\n",
    "graph.add_node(\"scrape_website\", scrape_website)\n",
    "\n",
    "graph.set_entry_point(\"define_urls\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"define_urls\",\n",
    "    route_to_scraping,\n",
    "    [\"scrape_website\"]  # 스크래핑 노드로 라우팅\n",
    ")\n",
    "\n",
    "graph.add_edge(\"scrape_website\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "compiled_graph = graph.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(compiled_graph.get_graph().draw_mermaid_png()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행 (외부에서 URL 목록 입력)\n",
    "initial_state = {\"urls\": [\"https://example.com\", \"https://example.net\", \"https://example.org\"]}\n",
    "result = compiled_graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "    define_urls[define_urls]\n",
    "    scrape_website[scrape_website]\n",
    "    _start((START)) --> define_urls\n",
    "    define_urls --\"Send(scrape_website)\"--> scrape_website\n",
    "    scrape_website --> _end((END))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **[예제]**\n",
    "\n",
    "- LangGraph의 `Send` API를 사용하여 여러 단계를 거치는 리서치 어시스턴트를 구축합니다. 사용자가 질문을 하면, 어시스턴트는 다음 단계를 수행합니다.\n",
    "\n",
    "    1.  **검색 (Search):** Tavily 검색을 통해 관련 정보를 찾습니다.\n",
    "    2.  **요약 (Summary):** 검색 결과를 요약합니다.\n",
    "    3. **팩트체크 (병렬처리):** 요약된 정보의 각 문장에 대해 신뢰도를 평가합니다. (Send API 사용)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 기본 설정 및 상태 정의`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, TypedDict, Optional\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "import operator\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 팩트 체크 결과를 위한 Pydantic 모델\n",
    "class FactCheckResult(BaseModel):\n",
    "    sentence: str\n",
    "    score: float\n",
    "\n",
    "# 전체 상태 정의 (글로벌 상태)\n",
    "class OverallState(TypedDict):\n",
    "    query: str  # 검색 쿼리\n",
    "    search_results: Optional[List[Dict[str, Any]]] \n",
    "    summary: Optional[str]  # 요약문\n",
    "    fact_check: Annotated[List[FactCheckResult], operator.add]  # 팩트체크 결과 (누적)\n",
    "\n",
    "# 로컬 상태 (단일 문장 팩트체크용)\n",
    "class SentenceState(TypedDict):\n",
    "    sentence: str  # 팩트체크할 문장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 검색 노드 (Search Node)`\n",
    "\n",
    "- Tavily 검색 도구를 사용하여 사용자 쿼리에 대한 검색을 수행\n",
    "- `fact_check`는 빈 리스트로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_info(state: OverallState) -> OverallState:\n",
    "    search_tool = TavilySearchResults(\n",
    "        max_results=5,  # 반환할 결과의 수\n",
    "        search_depth=\"advanced\",  # 검색 깊이: basic 또는 advanced\n",
    "        include_answer=True,  # 결과에 직접적인 답변 포함\n",
    "        include_raw_content=True,  # 페이지의 원시 콘텐츠 포함\n",
    "        include_images=True,  # 결과에 이미지 포함\n",
    "    )\n",
    "    \n",
    "    # 사용자의 쿼리 추출\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    # 검색 실행\n",
    "    results = search_tool.invoke({\"query\": query})\n",
    "\n",
    "    return {\n",
    "        \"search_results\": results\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 요약 노드 (Summary Node)`\n",
    "\n",
    "*   검색 결과가 없으면 \"검색 결과가 없습니다.\"를 반환합니다.\n",
    "*   LLM을 사용하여 검색 결과를 3-4개의 핵심 포인트로 요약합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(state: OverallState) -> OverallState:\n",
    "    if not state[\"search_results\"]:\n",
    "        return {\"summary\": \"검색 결과가 없습니다.\"}\n",
    "\n",
    "    summary_prompt = \"\"\"\n",
    "    다음 검색 결과들을 요약해주세요:\n",
    "    {search_results}\n",
    "\n",
    "    핵심 포인트 3-4개로 간단히 요약:\n",
    "    \"\"\"\n",
    "\n",
    "    # 검색 결과를 문자열로 변환하여 프롬프트에 포함\n",
    "    formatted_results = []\n",
    "    for item in state[\"search_results\"]:\n",
    "        if \"raw_content\" in item:\n",
    "            formatted_results.append(f\"제목: {item.get('title', 'No title')}\\n내용: {item['raw_content']}\\n링크: {item.get('url', 'No URL')}\\n\")\n",
    "        else:\n",
    "            formatted_results.append(f\"제목: {item.get('title', 'No title')}\\n내용: {item.get('content', 'No content')}\\n링크: {item.get('url', 'No URL')}\\n\")\n",
    "    search_text = \"\\n\\n\".join(formatted_results)\n",
    "    summary_prompt = summary_prompt.format(search_results=search_text)\n",
    "\n",
    "    summary = llm.invoke(summary_prompt)\n",
    "\n",
    "    return {\"summary\": summary.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4)  팩트 체크 노드 (Fact-Check Node)`\n",
    "\n",
    "- `Send` API를 사용하여 요약된 문장들을 병렬로 팩트 체크하는 노드를 정의\n",
    "\n",
    "-  **fact_check_sentences 노드**: \n",
    "    - 요약이 없으면 빈 결과를 반환. \n",
    "    - 요약된 텍스트를 문장 단위로 분리하고, 각 문장에 대해 `Send(\"fact_check_sentence\", {\"sentence\": s})`를 호출하여 **fact_check_sentence 노드**로 작업을 보냄\n",
    "    - `Send`는 각 문장에 대한 별도의 실행 경로를 생성하여 병렬 처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Send\n",
    "\n",
    "def fact_check_sentences(state: OverallState):\n",
    "    if not state[\"summary\"]:\n",
    "        return {\"fact_check\": []}\n",
    "\n",
    "    # 요약된 문장들을 분리 (간단하게 개항문자로 분리)\n",
    "    sentences = state[\"summary\"].split(\"\\n\\n\")\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]  # 빈 문자열 제거\n",
    "\n",
    "    print(f\"Fact-checking {len(sentences)} sentences...\")\n",
    "\n",
    "    # 각 문장에 대해 팩트 체크 작업을 생성 (Send 사용)\n",
    "    return [\n",
    "        Send(\"fact_check_sentence\", {\"sentence\": s}) for s in sentences\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **fact_check_single_sentence 함수** : \n",
    "\n",
    "    - **fact_check_sentences 노드**가 `Send` 한 것을 받아서 처리\n",
    "    - 전달 받은 단일 문장에 대한 팩트 체크를 수행\n",
    "    - LLM을 호출하여 신뢰도 점수를 얻고, `FactCheckResult` 형태로 결과를 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_check_single_sentence(state: SentenceState) -> OverallState:\n",
    "    \"\"\"개별 문장에 대한 팩트체크 수행\"\"\"\n",
    "    sentence = state[\"sentence\"]\n",
    "    print(f\"Fact-checking sentence: {sentence}\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    다음 문장의 사실 여부를 평가하고 신뢰도 점수를 0과 1 사이로 제공해주세요. 숫자만 출력하세요:\n",
    "    문장: {sentence}\n",
    "    신뢰도 점수:\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # 팩트체크 결과 생성\n",
    "    print(f\"Fact-check result: {response.content}\")\n",
    "    \n",
    "    try:\n",
    "        score = float(response.content)\n",
    "        score = max(0.0, min(1.0, score))  # 0과 1 사이로 제한\n",
    "    except ValueError:\n",
    "        score = 0.5  # 기본값\n",
    "    \n",
    "    return {\n",
    "        \"fact_check\": [FactCheckResult(sentence=sentence, score=score)]\n",
    "    } #type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) 그래프 구성`\n",
    "\n",
    "- **add_edge**: 노드 간의 일반적인 흐름을 정의 (검색 -> 요약)\n",
    "\n",
    "- **add_conditional_edges**:  `START` 노드에서 사용자 쿼리가 있으면 `fact_check_sentences`로, 그렇지 않으면 `END`로 분기\n",
    "\n",
    "- `builder.add_edge(\"fact_check_sentence\", END)` : 팩트 체크 결과를 반환하는 노드를 `END`에 연결.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 구성\n",
    "builder = StateGraph(OverallState)\n",
    "\n",
    "# 노드 추가\n",
    "builder.add_node(\"search\", search_info)\n",
    "builder.add_node(\"generate_summary\", generate_summary)\n",
    "builder.add_node(\"fact_check_sentence\", fact_check_single_sentence)\n",
    "\n",
    "# 엣지 추가\n",
    "builder.add_edge(START, \"search\")\n",
    "builder.add_edge(\"search\", \"generate_summary\")\n",
    "builder.add_conditional_edges(\n",
    "    \"generate_summary\",\n",
    "    fact_check_sentences,\n",
    "    [\"fact_check_sentence\"]   # 팩트체크 문장 노드로 라우팅\n",
    ")\n",
    "\n",
    "builder.add_edge(\"fact_check_sentence\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(6) 그래프 실행`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 질문\n",
    "inputs = {\"query\": \"기후 변화의 주요 원인은 무엇인가요?\"}\n",
    "\n",
    "# 그래프 실행\n",
    "result = graph.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

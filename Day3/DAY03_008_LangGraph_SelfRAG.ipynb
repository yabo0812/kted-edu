{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b606ae",
   "metadata": {},
   "source": [
    "#   LangGraph 활용 - Self RAG \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752dabf",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c9bdf",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a25cd",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da601321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf5b3ab",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57fa174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
    "import os\n",
    "print(os.getenv('LANGSMITH_TRACING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4536a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Self-RAG**\n",
    "\n",
    "- Self-RAG (Retrieval-Augmented Generation with Self-Reflection) \n",
    "\n",
    "- 주요 단계: \n",
    "\n",
    "   1. 검색 결정 (Retrieval Decision):\n",
    "      - 입력: 질문 `x` 또는 질문 `x`와 생성된 답변 `y`\n",
    "      - 목적: 검색기 `R`을 사용하여 `D` 개의 청크를 검색할지 결정\n",
    "      - 출력: \"yes\", \"no\", \"continue\" 중 하나\n",
    "      - 의미: 시스템이 추가 정보가 필요한지 판단\n",
    "\n",
    "   2. 검색된 문서 관련성 평가:\n",
    "      - 입력: 질문 `x`와 각 검색된 청크 `d`\n",
    "      - 목적: 각 청크가 질문에 유용한 정보를 제공하는지 평가\n",
    "      - 출력: \"relevant\" 또는 \"irrelevant\"\n",
    "      - 의미: 관련 없는 정보를 필터링하여 품질을 향상\n",
    "\n",
    "   3. 생성된 답변의 환각 평가:\n",
    "      - 입력: 질문 `x`, 청크 `d`, 생성된 텍스트 `y`\n",
    "      - 목적: 생성된 텍스트가 청크의 정보에 의해 지지되는지 평가\n",
    "      - 출력: \"fully supported\", \"partially supported\", \"no support\"\n",
    "      - 의미: 환각(hallucination)을 감지하고 정보의 신뢰성을 확인\n",
    "\n",
    "   4. 생성된 답변의 유용성 평가:\n",
    "      - 입력: 질문 `x`와 생성된 텍스트 `y`\n",
    "      - 목적: 생성된 텍스트가 질문에 유용한 응답인지 평가\n",
    "      - 출력: 5점 척도 (5: 매우 유용, 1: 전혀 유용하지 않음)\n",
    "      - 의미: 응답의 품질과 관련성을 수치화\n",
    "\n",
    "- 논문: https://arxiv.org/abs/2310.11511"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a6041",
   "metadata": {},
   "source": [
    "### **1. 벡터저장소** \n",
    "- 메뉴 검색을 위해 저장해둔 저장소를 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8405546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Chroma 인덱스 로드\n",
    "vector_db = Chroma(\n",
    "    embedding_function=embeddings_model,   \n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5555957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기 생성 \n",
    "retriever= vector_db.as_retriever(search_kwargs={\"k\":3})\n",
    "\n",
    "# 검색 테스트\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "results = retriever.invoke(query)\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf34963",
   "metadata": {},
   "source": [
    "### **2. Retrieval Grader** \n",
    "\n",
    "- 검색 평가자는 **키워드 관련성**과 **의미적 관련성**을 기준으로 결과를 평가\n",
    "\n",
    "- 평가는 **'yes/no' 이진법**으로 진행하며 불확실한 경우 'no' 처리\n",
    "\n",
    "- 부분 관련성이나 맥락 정보도 **답변 형성 기여도** 기준으로 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27442c44",
   "metadata": {},
   "source": [
    "`(1) 데이터 모델 및 LLM 초기화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97666fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "# 검색된 문서의 관련성 평가 결과를 위한 데이터 모델 정의\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: Literal['yes', 'no'] = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM 모델 초기화 및 구조화된 출력 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9db983c",
   "metadata": {},
   "source": [
    "`(2) LCEL 체인 구성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d27a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 관련성 평가를 위한 시스템 프롬프트 정의\n",
    "system_prompt = \"\"\"당신은 사용자 질문에 대한 검색 결과의 관련성을 평가하는 전문가입니다.\n",
    "\n",
    "평가 기준:\n",
    "1. 키워드 관련성: 문서가 질문의 주요 단어나 유사어를 포함하는지 확인\n",
    "2. 의미적 관련성: 문서의 전반적인 주제가 질문의 의도와 일치하는지 평가\n",
    "3. 부분 관련성: 질문의 일부를 다루거나 맥락 정보를 제공하는 문서도 고려\n",
    "4. 답변 가능성: 직접적인 답이 아니더라도 답변 형성에 도움될 정보 포함 여부 평가\n",
    "\n",
    "점수 체계:\n",
    "- 관련 있으면 'yes', 없으면 'no'로 평가\n",
    "- 확실하지 않은 경우 'no'로 평가하여 불포함 쪽으로 결정\n",
    "\n",
    "주의사항:\n",
    "- 단순 단어 매칭이 아닌 질문의 전체 맥락을 고려하세요\n",
    "- 완벽한 답변이 아니어도 유용한 정보가 있다면 관련 있다고 판단하세요\n",
    "\n",
    "당신의 평가는 정보 검색 시스템 개선에 중요합니다. 균형 잡힌 평가를 해주세요.\"\"\"\n",
    "\n",
    "human_prompt = \"\"\"\n",
    "다음 문서가 사용자 질문에 관련 있는지 평가해주세요.\n",
    "\n",
    "[Retrieved document]\n",
    "{document}\n",
    "\n",
    "[User question]\n",
    "{question}\n",
    "\n",
    "[Grade the relevance of the retrieved document]\n",
    "\"\"\"\n",
    "\n",
    "# 채점 프롬프트 템플릿 생성\n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", human_prompt),\n",
    "])\n",
    "\n",
    "\n",
    "# Retrieval Grader 파이프라인 구성\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32958f",
   "metadata": {},
   "source": [
    "`(3) 평가 수행`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c168371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련성 평가 실행\n",
    "question = \"이 식당을 대표하는 메뉴는 무엇인가요?\"\n",
    "retrieved_docs = vector_db.similarity_search(question, k=2)\n",
    "print(f\"검색된 문서 수: {len(retrieved_docs)}\")\n",
    "print(\"===============================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "relevant_docs = []\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(\"문서:\", doc.page_content)\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "    relevance = retrieval_grader.invoke(\n",
    "        input={\"question\": question, \"document\": doc}\n",
    "        )\n",
    "    print(f\"문서 관련성: {relevance}\")\n",
    "\n",
    "    if relevance.binary_score == 'yes':\n",
    "        relevant_docs.append(doc)\n",
    "    \n",
    "    print(\"===========================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c857cd8",
   "metadata": {},
   "source": [
    "### **3. Answer Generator** \n",
    "\n",
    "- **답변 생성** 시 문맥 내 정보만 사용하고 추측 배제\n",
    "- 답변은 **직접 관련 정보**만 포함하여 간결하게 작성\n",
    "- 정보 부족 시 \"**주어진 정보만으로는 답할 수 없습니다**\" 명시\n",
    "- 필요시 **직접 인용문** 활용하여 정확성 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ecbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 RAG 체인\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def generator_answer(question, docs):\n",
    "\n",
    "    template = \"\"\"\n",
    "    Answer the question based solely on the given context. Do not use any external information or knowledge.\n",
    "\n",
    "    [Instructions]\n",
    "        1. 질문과 관련된 정보를 문맥에서 신중하게 확인합니다.\n",
    "        2. 답변에 질문과 직접 관련된 정보만 사용합니다.\n",
    "        3. 문맥에 명시되지 않은 내용에 대해 추측하지 않습니다.\n",
    "        4. 불필요한 정보를 피하고, 답변을 간결하고 명확하게 작성합니다.\n",
    "        5. 문맥에서 답을 찾을 수 없으면 \"주어진 정보만으로는 답할 수 없습니다.\"라고 답변합니다.\n",
    "        6. 적절한 경우 문맥에서 직접 인용하며, 따옴표를 사용합니다.\n",
    "\n",
    "    [Context]\n",
    "    {context}\n",
    "\n",
    "    [Question]\n",
    "    {question}\n",
    "\n",
    "    [Answer]\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    llm = ChatOpenAI(model='gpt-4.1-mini', temperature=0)    \n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    \n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    generation = rag_chain.invoke(\n",
    "        {\"context\": format_docs(docs), \"question\": question}\n",
    "        )\n",
    "\n",
    "    return generation\n",
    "\n",
    "\n",
    "# 관령성 평가를 통과한 문서를 기반으로 질문에 대한 답변 생성\n",
    "generation = generator_answer(question, docs=relevant_docs)\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338cb8d",
   "metadata": {},
   "source": [
    "### **4. Hallucination Grader** \n",
    "\n",
    "- **시스템 프롬프트**는 사실 기반 답변을 평가하는 전문가 역할을 정의함\n",
    "- 평가는 **두 가지 기준**으로 진행: 사실 근거 시 'yes', 근거 부족 시 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c386c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환각(Hallucination) 평가 결과를 위한 데이터 모델 정의\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM 모델 초기화 및 구조화된 출력 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "\n",
    "# 환각 평가를 위한 시스템 프롬프트 정의\n",
    "system_prompt = \"\"\"\n",
    "You are an expert evaluator assessing whether an LLM-generated answer is grounded in and supported by a given set of facts.\n",
    "\n",
    "[Your task]\n",
    "    - LLM이 생성한 답변을 검토합니다.\n",
    "    - 답변이 주어진 사실로 완전히 뒷받침되는지 판단합니다.\n",
    "\n",
    "[Evaluation criteria]\n",
    "    - 답변에 주어진 사실이나 명확히 추론할 수 있는 정보 외의 내용이 없어야 합니다.\n",
    "    - 답변의 모든 핵심 내용이 주어진 사실에서 비롯되어야 합니다.\n",
    "    - 사실적 정확성에 집중하고, 글쓰기 스타일이나 완전성은 평가하지 않습니다.\n",
    "\n",
    "[Scoring]\n",
    "    - 'yes': 답변이 사실에 근거하고 완전히 지원되는 경우.\n",
    "    - 'no': 답변에 사실에 근거하지 않은 정보나 주장이 포함된 경우.\n",
    "\n",
    "Your evaluation is crucial in ensuring the reliability and factual accuracy of AI-generated responses. Be thorough and critical in your assessment.\n",
    "\"\"\"\n",
    "\n",
    "# 환각 평가 프롬프트 템플릿 생성\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"[Set of facts]\\n{documents}\\n\\n[LLM generation]\\n{generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Hallucination Grader 파이프라인 구성\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "\n",
    "# 환각 평가 실행\n",
    "hallucination = hallucination_grader.invoke(\n",
    "    {\"documents\": relevant_docs, \"generation\": generation}\n",
    "    )\n",
    "print(f\"환각 평가: {hallucination}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38b0b0",
   "metadata": {},
   "source": [
    "### **5. Answer Grader** \n",
    "\n",
    "- 답변 평가는 **정보 포함 여부**를 기준으로 'yes' 또는 'no'로 판단\n",
    "- 시스템은 **단순명확한 기준**으로 답변의 적절성을 평가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답변 평가 결과를 위한 데이터 모델 정의\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM 모델 초기화 및 구조화된 출력 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# 답변 평가를 위한 시스템 프롬프트 정의\n",
    "system_prompt = \"\"\"\n",
    "You are an expert evaluator tasked with assessing whether an LLM-generated answer effectively addresses and resolves a user's question.\n",
    "\n",
    "[Your task]\n",
    "    - 사용자의 질문을 신중히 분석하여 핵심 의도와 요구 사항을 이해합니다.\n",
    "    - LLM이 생성한 답변이 질문을 충분히 해결했는지 판단합니다.\n",
    "\n",
    "[Evaluation criteria]\n",
    "    - 관련성: 답변이 질문과 직접적으로 관련되어야 합니다.\n",
    "    - 완전성: 질문의 모든 측면이 다뤄져야 합니다.\n",
    "    - 정확성: 제공된 정보가 정확하고 최신이어야 합니다.\n",
    "    - 명확성: 답변이 명확하고 이해하기 쉬워야 합니다.\n",
    "    - 구체성: 질문의 요구 사항에 맞는 상세한 답변이어야 합니다.\n",
    "\n",
    "[Scoring]\n",
    "    - 'yes': 답변이 질문을 효과적으로 해결한 경우.\n",
    "    - 'no': 답변이 질문을 충분히 해결하지 못하거나 중요한 요소가 부족한 경우.\n",
    "    - 답변이 완벽하지 않아도 핵심 질문을 해결하면 'yes'를 줄 수 있습니다.\n",
    "    - 부분적으로 맞지만 중요한 요소가 빠진 답변은 'no'로 평가합니다.\n",
    "\n",
    "Your evaluation plays a critical role in ensuring the quality and effectiveness of AI-generated responses. Strive for balanced and thoughtful assessments.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 답변 평가 프롬프트 템플릿 생성\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"[User question]\\n{question}\\n\\n[LLM generation]\\n{generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Answer Grader 파이프라인 구성\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "\n",
    "# 답변 평가 실행\n",
    "print(\"Question:\", question)\n",
    "print(\"Generation:\", generation)\n",
    "\n",
    "answer_score = answer_grader.invoke(\n",
    "    {\"question\": question, \"generation\": generation}\n",
    ")\n",
    "print(f\"답변 평가: {answer_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08568cab",
   "metadata": {},
   "source": [
    "### **6. Question Re-writer** \n",
    "\n",
    "- 질문을 **명확성과 간결성** 중심으로 개선하는 것이 주요 목표\n",
    "- 불필요한 정보 제거 시에도 **원래 의도 유지**가 핵심 지침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_question(question: str) -> str:\n",
    "    \"\"\"\n",
    "    주어진 질문을 벡터 저장소 검색에 최적화된 형태로 다시 작성합니다.\n",
    "\n",
    "    :param question: 원본 질문 문자열\n",
    "    :return: 다시 작성된 질문 문자열\n",
    "    \"\"\"\n",
    "    # LLM 모델 초기화\n",
    "    llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "    # 시스템 프롬프트 정의\n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert question re-writer. Your task is to convert input questions into optimized versions \n",
    "    for vectorstore retrieval. Analyze the input carefully and focus on capturing the underlying semantic \n",
    "    intent and meaning. Your goal is to create a question that will lead to more effective and relevant \n",
    "    document retrieval.\n",
    "\n",
    "    [Guidelines]\n",
    "        1. 질문에서 핵심 개념과 주요 대상을 식별하고 강조합니다.\n",
    "        2. 약어나 모호한 용어를 풀어서 사용합니다.\n",
    "        3. 관련 문서에 등장할 수 있는 동의어나 연관된 용어를 포함합니다.\n",
    "        4. 질문의 원래 의도와 범위를 유지합니다.\n",
    "        5. 복잡한 질문은 간단하고 집중된 하위 질문으로 나눕니다.\n",
    "\n",
    "    Remember, the goal is to improve retrieval effectiveness, not to change the fundamental meaning of the question.\n",
    "    \"\"\"\n",
    "\n",
    "    # 질문 다시 쓰기 프롬프트 템플릿 생성\n",
    "    re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"[Initial question]\\n{question}\\n\\n[Improved question]\\n\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 질문 다시 쓰기 체인 구성\n",
    "    question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "\n",
    "    # 질문 다시 쓰기 실행\n",
    "    rewritten_question = question_rewriter.invoke(\n",
    "        {\"question\": question}\n",
    "    )\n",
    "\n",
    "    return rewritten_question\n",
    "\n",
    "# 질문 다시 쓰기 테스트\n",
    "rewritten_question = rewrite_question(question)\n",
    "print(f\"원본 질문: {question}\")\n",
    "print(f\"다시 쓴 질문: {rewritten_question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cea4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 쓴 질문을 사용하여 벡터 저장소에서 문서 검색\n",
    "query = rewritten_question\n",
    "retrieved_docs = vector_db.similarity_search(query, k=2)\n",
    "print(len(retrieved_docs))\n",
    "print(\"===========================================================================\")\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(\"문서:\", doc.page_content)\n",
    "    print(\"---------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bed937",
   "metadata": {},
   "source": [
    "### **7. LangGraph로 그래프 구현** \n",
    "\n",
    "- **LangGraph** 구현은 기본적인 StateGraph를 활용\n",
    "- **Node와 Edge** 를 사용하여, 이전에 구현한 노드 함수를 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e721ccc",
   "metadata": {},
   "source": [
    "`(1) 그래프 State 생성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33830d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str                 # 사용자의 질문\n",
    "    generation: str               # LLM 생성 답변\n",
    "    documents: List[Document]     # 컨텍스트 문서 (검색된 문서)\n",
    "    num_generations: int          # 질문 or 답변 생성 횟수 (무한 루프 방지에 활용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd443517",
   "metadata": {},
   "source": [
    "`(2) Node 구성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 정의\n",
    "\n",
    "def retrieve(state: GraphState) -> GraphState:\n",
    "    \"\"\"문서를 검색하는 함수\"\"\"\n",
    "    print(\"--- 문서 검색 ---\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # 문서 검색 로직\n",
    "    documents = vector_db.similarity_search(question)\n",
    "    return {\"documents\": documents}      # 가장 마지막에 검색한 문서 객체들로 상태를 업데이트 \n",
    "\n",
    "def generate(state: GraphState) -> GraphState:\n",
    "    \"\"\"답변을 생성하는 함수\"\"\"\n",
    "    print(\"--- 답변 생성 ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # RAG를 이용한 답변 생성\n",
    "    generation = generator_answer(question, docs=documents)\n",
    "\n",
    "    # 생성 횟수 업데이트\n",
    "    num_generations = state.get(\"num_generations\", 0)\n",
    "    num_generations += 1\n",
    "    return {\"generation\": generation, \"num_generations\": num_generations}      # 답변, 생성횟수 업데이트 \n",
    "\n",
    "\n",
    "def grade_documents(state: GraphState) -> GraphState:\n",
    "    \"\"\"검색된 문서의 관련성을 평가하는 함수\"\"\"\n",
    "    print(\"--- 문서 관련성 평가 ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # 각 문서 평가\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---문서 관련성: 있음---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---문서 관련성: 없음---\")\n",
    "            \n",
    "    return {\"documents\": filtered_docs}       # 관련성 평가에 합격한 문서들만 저장 (override)\n",
    "\n",
    "\n",
    "\n",
    "def transform_query(state: GraphState) -> GraphState:\n",
    "    \"\"\"질문을 개선하는 함수\"\"\"\n",
    "    print(\"--- 질문 개선 ---\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # 질문 재작성\n",
    "    rewritten_question = rewrite_question(question)\n",
    "\n",
    "    # 생성 횟수 업데이트\n",
    "    num_generations = state.get(\"num_generations\", 0)\n",
    "    num_generations += 1\n",
    "    return {\"question\": rewritten_question, \"num_generations\": num_generations}      # 재작성한 질문을 저장, 생성횟수 업데이트 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b869c6",
   "metadata": {},
   "source": [
    "`(3) Edge 구성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state: GraphState) -> str:\n",
    "    \"\"\"답변 생성 여부를 결정하는 함수\"\"\"\n",
    "\n",
    "    num_generations = state.get(\"num_generations\", 0)\n",
    "    if num_generations > 5:\n",
    "        print(\"--- 결정: 생성 횟수 초과, 답변 생성 (-> generate)---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "    print(\"--- 평가된 문서 분석 ---\")\n",
    "    filtered_documents = state[\"documents\"]\n",
    "    \n",
    "    if not filtered_documents:\n",
    "        print(\"--- 결정: 모든 문서가 질문과 관련이 없음, 질문 개선 필요 (-> transform_query)---\")\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        print(\"--- 결정: 답변 생성 (-> generate)---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "\n",
    "def grade_generation(state: GraphState) -> str:\n",
    "    \"\"\"생성된 답변의 품질을 평가하는 함수\"\"\"\n",
    "\n",
    "    num_generations = state.get(\"num_generations\", 0)\n",
    "    if num_generations > 5:\n",
    "        print(\"--- 결정: 생성 횟수 초과, 종료 (-> END)---\")\n",
    "        return \"end\"\n",
    "    \n",
    "    # 1단계: 환각 여부 확인\n",
    "    print(\"--- 환각 여부 확인 ---\")\n",
    "    question, documents, generation = state[\"question\"], state[\"documents\"], state[\"generation\"]\n",
    "    \n",
    "    \n",
    "    hallucination_grade = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "\n",
    "    if hallucination_grade.binary_score == \"yes\":\n",
    "        print(\"--- 결정: No 환각 (답변이 컨텍스트에 근거함) ---\")\n",
    "\n",
    "        # 1단계 통과할 경우 -> 2단계: 질문-답변 관련성 평가 \n",
    "        print(\"---질문-답변 관련성 확인---\")\n",
    "        relevance_grade = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        if relevance_grade.binary_score == \"yes\":\n",
    "            print(\"--- 결정: 생성된 답변이 질문을 잘 다룸 (-> END) ---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"--- 결정: 생성된 답변이 질문을 제대로 다루지 않음 (-> transform_query) ---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        print(\"--- 결정: 생성된 답변이 문서에 근거하지 않음, 재시도 필요 (-> generate) ---\")\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbea70d",
   "metadata": {},
   "source": [
    "`(4) 그래프 연결`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619752cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 워크플로우 그래프 초기화\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# 노드 정의\n",
    "builder.add_node(\"retrieve\", retrieve)                # 문서 검색\n",
    "builder.add_node(\"grade_documents\", grade_documents)  # 문서 평가\n",
    "builder.add_node(\"generate\", generate)                # 답변 생성\n",
    "builder.add_node(\"transform_query\", transform_query)  # 질문 개선\n",
    "\n",
    "# 그래프 구축\n",
    "builder.add_edge(START, \"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# 조건부 엣지 추가: 문서 평가 후 결정\n",
    "builder.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "builder.add_edge(\"transform_query\", \"retrieve\")\n",
    "\n",
    "# 조건부 엣지 추가: 답변 생성 후 평가\n",
    "builder.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation,\n",
    "    {\n",
    "        \"not supported\": \"generate\",          # 환각이 발생한 경우 -> 답변을 다시 생성 \n",
    "        \"not useful\": \"transform_query\",      # 질문과 답변의 관련성이 부족한 경우 -> 쿼리 개선해서 다시 검색 \n",
    "        \"useful\": END, \n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b2ef2a",
   "metadata": {},
   "source": [
    "`(5) 그래프 실행`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e0c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"이 식당의 대표 메뉴는 무엇인가요? 주재료는 무엇인가요?\"}\n",
    "final_output = graph.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 답변 \n",
    "final_output[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d4ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"김치찌개 메뉴가 있나요?\"}\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # 노드 출력\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        pprint(f\"Value: {value}\", indent=2, width=80, depth=None)\n",
    "    print(\"\\n----------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9025b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 답변\n",
    "print(value[\"generation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph 활용 - 상태 그래프 구현\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing 설정`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
    "import os\n",
    "\n",
    "print(os.getenv(\"LANGSMITH_TRACING\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **StateGraph**\n",
    "\n",
    "- **StateGraph**는 상태 기반의 그래프 구조를 사용하여 **대화 흐름을 체계적으로 관리**\n",
    "\n",
    "- 예제: **기본 챗봇 시스템**\n",
    "  - 챗봇은 **StateGraph**를 통해 상태 기반 구조로 구현 (**노드**와 **엣지**로 구성)\n",
    "  - 챗봇의 실행 흐름은 **START**에서 시작하여 **END**로 종료되며, 엣지를 통해 노드 간 전환을 처리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 상태(State)`\n",
    "\n",
    "- **상태(State)** 는 그래프에서 처리하는 **데이터의 기본 구조**를 정의\n",
    "\n",
    "- 각 상태는 다른 상태에 의해 **override(덮어쓰기)** 될 수 있어 데이터를 유연하게 관리할 수 있음\n",
    "\n",
    "- 상태 관리를 통해 **체계적인 데이터 처리**와 **흐름 제어**가 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "# 상태 정의\n",
    "class State(TypedDict):\n",
    "    original_text: str  # 원본 텍스트\n",
    "    summary: str  # 요약본\n",
    "    final_summary: str  # 최종 요약본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TypedDict를 사용하여 그래프의 상태를 정의\n",
    "- 상태는 그래프 실행 중에 노드 간에 공유되는 데이터\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 노드(Node)`\n",
    "\n",
    "- **노드(Node)** 는 그래프 구조의 기본 구성 요소\n",
    "\n",
    "- 노드는 **독립적인 작업 단위**로 특정 함수를 실행\n",
    "\n",
    "- 각 노드는 다른 노드와 연결되어 **데이터 흐름**을 형성\n",
    "\n",
    "- 상태를 입력으로 받아 처리하고 업데이트된 상태를 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "\n",
    "# 요약 생성 노드\n",
    "def generate_summary(state: State):\n",
    "    \"\"\"원본 텍스트를 요약하는 노드\"\"\"\n",
    "    prompt = f\"\"\"다음 텍스트를 핵심 내용 중심으로 간단히 요약해주세요:\n",
    "\n",
    "    [텍스트]\n",
    "    {state['original_text']}\n",
    "\n",
    "    [요약]\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return {\"summary\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 그래프(Graph) 구성`\n",
    "\n",
    "- **그래프(Graph)** 는 여러 노드들을 **엣지(Edge)**로 연결한 집합체\n",
    "\n",
    "- 각 노드 간의 **연결 관계**가 전체 데이터 흐름을 결정\n",
    "\n",
    "- 그래프는 빌드가 완료된 후 **실행 가능한 상태**가 됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# StateGraph 객체 생성 (Workflow)\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"generate_summary\", generate_summary)\n",
    "\n",
    "# 시작(START)과 끝(END) 엣지 추가 : 시작 -> generate_summary -> 끝\n",
    "workflow.add_edge(START, \"generate_summary\")\n",
    "workflow.add_edge(\"generate_summary\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = workflow.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) invoke 실행`\n",
    "\n",
    "- **invoke** 방식은 그래프의 가장 **기본적인 실행 방법**으로, 단순하고 직관적인 처리를 제공\n",
    "\n",
    "- 실행 결과는 모든 처리가 완료된 후 **최종 결과값**만 반환\n",
    "\n",
    "- 전체 처리 과정이 완료될 때까지 **동기적으로 대기**하므로, 중간 상태를 확인할 수 없음\n",
    "\n",
    "- 간단한 처리나 최종 결과만 필요한 경우에 적합한 실행 방식\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시\n",
    "text = \"\"\"\n",
    "인공지능(AI)은 컴퓨터 과학의 한 분야로, 인간의 학습능력과 추론능력, 지각능력, \n",
    "자연언어의 이해능력 등을 컴퓨터 프로그램으로 실현한 기술이다. \n",
    "최근에는 기계학습과 딥러닝의 발전으로 다양한 분야에서 활용되고 있다.\n",
    "\"\"\"\n",
    "\n",
    "initial_state = {\n",
    "    \"original_text\": text,\n",
    "}\n",
    "\n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "for key, value in final_state.items():\n",
    "    print(f\"{key}\")\n",
    "    print(\"-\" * 50)\n",
    "    pprint(f\"{value}\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) 조건부 엣지(Edge)`\n",
    "\n",
    "- **엣지**는 노드 간의 **연결 경로**를 정의하며, 챗봇의 대화 흐름을 구성하는 핵심 요소\n",
    "\n",
    "- **조건부 엣지**를 통해 상황에 따라 다른 경로로 분기할 수 있어 **유연한 대화 구조**가 가능함\n",
    "\n",
    "- 사용자의 입력이나 상태에 따라 **동적으로 경로가 결정**되어 맥락에 맞는 응답을 제공\n",
    "\n",
    "- 조건부 엣지를 활용하면 상황에 따른 적절한 대화 흐름을 구현할 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "# 요약 품질 체크 노드 (조건부 엣지와 함께 사용)\n",
    "def check_summary_quality(state: State) -> Literal[\"needs_improvement\", \"good\"]:\n",
    "    \"\"\"요약의 품질을 체크하고 개선이 필요한지 판단하는 노드\"\"\"\n",
    "    prompt = f\"\"\"다음 요약의 품질을 평가해주세요. \n",
    "    요약이 명확하고 핵심을 잘 전달하면 'good'을, \n",
    "    개선이 필요하면 'needs_improvement'를 응답해주세요.\n",
    "    \n",
    "    요약본: {state['summary']}\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt).content.lower().strip()\n",
    "\n",
    "    if \"good\" in response:\n",
    "        print(\"---- Good Summary ----\")\n",
    "        return \"good\"\n",
    "    else:\n",
    "        print(\"---- Needs Improvement ----\")\n",
    "        return \"needs_improvement\"\n",
    "\n",
    "\n",
    "# 요약 개선 노드\n",
    "def improve_summary(state: State):\n",
    "    \"\"\"요약을 개선하고 다듬는 노드\"\"\"\n",
    "    prompt = f\"\"\"다음 요약을 더 명확하고 간결하게 개선해주세요:\n",
    "    \n",
    "    요약본: {state['summary']}\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return {\"final_summary\": response.content}\n",
    "\n",
    "\n",
    "# 요약 완료 노드\n",
    "def finalize_summary(state: State):\n",
    "    \"\"\"현재 요약을 최종 요약으로 설정하는 노드\"\"\"\n",
    "    return {\"final_summary\": state[\"summary\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **워크플로우 구성**:\n",
    "\n",
    "   - START → generate_summary → polish_summary → END 순서로 실행\n",
    "   - generate_summary 결과에 따라 조건부 분기\n",
    "   - 각 노드는 이전 노드의 출력을 입력으로 받아 처리\n",
    "\n",
    "1. **체인 실행**:\n",
    "   - 원본 텍스트를 초기 상태로 전달\n",
    "   - 최종적으로 다듬어진 요약을 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 구성\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"generate_summary\", generate_summary)\n",
    "workflow.add_node(\"improve_summary\", improve_summary)\n",
    "workflow.add_node(\"finalize_summary\", finalize_summary)\n",
    "\n",
    "# 조건부 엣지 추가를 위한 라우팅 설정\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_summary\",\n",
    "    check_summary_quality,\n",
    "    {\"needs_improvement\": \"improve_summary\", \"good\": \"finalize_summary\"},\n",
    ")\n",
    "\n",
    "# 기본 엣지 추가\n",
    "workflow.add_edge(START, \"generate_summary\")\n",
    "workflow.add_edge(\"improve_summary\", END)\n",
    "workflow.add_edge(\"finalize_summary\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = workflow.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) Stream 실행`\n",
    "\n",
    "- **stream** 방식은 그래프 실행의 **중간 과정**을 실시간으로 확인할 수 있어 투명한 처리가 가능\n",
    "\n",
    "- 각 노드의 실행 결과가 **순차적으로 스트리밍**되어 처리 흐름을 자세히 모니터링할 수 있음\n",
    "\n",
    "- 사용자에게 **진행 상황**을 즉각적으로 보여줄 수 있어 대화형 인터페이스에 적합\n",
    "\n",
    "- 실시간 피드백이 필요한 복잡한 처리나 사용자 상호작용이 중요한 경우에 이상적인 실행 방식\n",
    "\n",
    "- **stream_mode**: 스트리밍 실행 시 어떤 정보를 받을지 결정하는 중요한 옵션\n",
    "  - 단순 진행상황 표시 → \"values\"\n",
    "  - 디버깅/개발 → \"updates\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. \"values\" 모드 : 상태 값의 변경사항만 스트리밍\n",
    "for chunk in graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    print(chunk)\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. \"updates\" 모드 : 어떤 노드가 업데이트를 생성했는지 포함 (디버깅용)\n",
    "for chunk in graph.stream(initial_state, stream_mode=\"updates\"):\n",
    "    print(chunk)\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. \"all\" 모드 : 각 업데이트의 타입과 내용을 튜플로 반환 (가장 상세)\n",
    "for chunk_type, chunk_data in graph.stream(\n",
    "    initial_state, stream_mode=[\"values\", \"updates\"]\n",
    "):\n",
    "    print(f\"업데이트 타입: {chunk_type}\")\n",
    "    print(f\"데이터: {chunk_data}\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Command**\n",
    "\n",
    "- **Command 객체**는 LangGraph의 핵심 제어 도구로, 노드 함수의 **반환값**으로 사용\n",
    "\n",
    "- 상태 관리와 흐름 제어를 **동시에 수행**할 수 있어 효율적인 그래프 운영이 가능\n",
    "\n",
    "- 그래프의 **상태를 동적으로 업데이트**하면서 다음 실행할 노드를 지정할 수 있음\n",
    "  1.  **상태 업데이트:** 그래프의 상태(State)를 변경 (예: 새로운 정보를 추가하거나 기존 정보를 수정)\n",
    "  2.  **제어 흐름:** 다음에 실행할 노드를 지정 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **StateGraph 수정**\n",
    "\n",
    "1. `check_summary_quality` 함수를 제거하고 해당 로직을 `generate_summary` 노드에 통합\n",
    "\n",
    "2. 각 노드가 `Command` 객체를 반환하도록 수정\n",
    "\n",
    "   - `goto`: 다음에 실행할 노드 지정\n",
    "   - `update`: 상태 업데이트 내용 지정\n",
    "\n",
    "3. 조건부 엣지 대신 `Command`를 통한 라우팅을 사용\n",
    "\n",
    "   - 품질 평가에 따라 `generate_summary`에서 `improve_summary` 또는 `finalize_summary`로 라우팅\n",
    "   - `improve_summary`와 `finalize_summary`는 모두 END로 라우팅\n",
    "\n",
    "4. 엣지 설정을 단순화\n",
    "   - START에서 `generate_summary`로의 엣지만 명시적으로 정의\n",
    "   - 나머지 라우팅은 `Command`를 통해 처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 상태 정의\n",
    "class State(TypedDict):\n",
    "    original_text: str  # 원본 텍스트\n",
    "    summary: str  # 요약본\n",
    "    final_summary: str  # 최종 요약본\n",
    "\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "summary_llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "eval_llm = ChatOpenAI(model=\"gpt-4.1\")\n",
    "\n",
    "\n",
    "# 요약 생성 노드\n",
    "def generate_summary(\n",
    "    state: State,\n",
    ") -> Command[Literal[\"improve_summary\", \"finalize_summary\"]]:\n",
    "    \"\"\"원본 텍스트를 요약하고 품질을 평가하는 노드\"\"\"\n",
    "    # 요약 생성\n",
    "    summary_prompt = f\"\"\"다음 텍스트를 핵심 내용 중심으로 간단히 요약해주세요:\n",
    "\n",
    "    [텍스트]\n",
    "    {state['original_text']}\n",
    "\n",
    "    [요약]\n",
    "    \"\"\"\n",
    "    summary = summary_llm.invoke(summary_prompt).content\n",
    "\n",
    "    #     summary = \"\"\"인공지능은 컴퓨터 과학의 한 분야이며 인간의 능력을 구현한 것인데 \\\n",
    "    # 요즘에는 정말 다양한 분야에서 활용되고 있고 특히 기계학습이랑 딥러닝이 발전하면서 \\\n",
    "    # 더욱 활용도가 높아지고 있다고 합니다\"\"\"  # 테스트용\n",
    "\n",
    "    # 품질 평가\n",
    "    eval_prompt = f\"\"\"다음 요약의 품질을 평가해주세요. \n",
    "    요약이 명확하고 핵심을 잘 전달하면 'good'을, \n",
    "    개선이 필요하면 'needs_improvement'를 응답해주세요.\n",
    "    \n",
    "    요약본: {summary}\n",
    "    \"\"\"\n",
    "    quality = eval_llm.invoke(eval_prompt).content.lower().strip()\n",
    "\n",
    "    # 상태 업데이트와 함께 다음 노드로 라우팅\n",
    "    return Command(\n",
    "        goto=\"finalize_summary\" if \"good\" in quality else \"improve_summary\",\n",
    "        update={\"summary\": summary},\n",
    "    )\n",
    "\n",
    "\n",
    "# 요약 개선 노드\n",
    "def improve_summary(state: State) -> Command[Literal[END]]:\n",
    "    \"\"\"요약을 개선하고 다듬는 노드\"\"\"\n",
    "    prompt = f\"\"\"다음 요약을 더 명확하고 간결하게 개선해주세요:\n",
    "    \n",
    "    [기존 요약]\n",
    "    {state['summary']}\n",
    "\n",
    "    [개선 요약]\n",
    "    \"\"\"\n",
    "    improved_summary = llm.invoke(prompt).content\n",
    "\n",
    "    # 상태 업데이트와 함께 다음 노드로 라우팅\n",
    "    return Command(goto=END, update={\"final_summary\": improved_summary})\n",
    "\n",
    "\n",
    "# 최종 요약 설정 노드\n",
    "def finalize_summary(state: State) -> Command[Literal[END]]:\n",
    "    \"\"\"현재 요약을 최종 요약으로 설정하는 노드\"\"\"\n",
    "\n",
    "    # 상태 업데이트와 함께 다음 노드로 라우팅\n",
    "    return Command(goto=END, update={\"final_summary\": state[\"summary\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Command` vs. 조건부 엣지(Conditional Edges)**\n",
    "\n",
    "- **Command**는 상태 업데이트와 노드 이동을 **동시에 처리**할 때 사용되며, 특히 정보 전달이 필요한 복잡한 전환에 적합\n",
    "\n",
    "- **조건부 엣지**는 단순한 분기 처리에 사용되며, 상태 변경 없이 **조건에 따른 이동**만 수행\n",
    "\n",
    "- 두 방식의 **선택 기준**은 상태 업데이트 필요 여부에 따라 결정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워크플로우 구성\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"generate_summary\", generate_summary)\n",
    "workflow.add_node(\"improve_summary\", improve_summary)\n",
    "workflow.add_node(\"finalize_summary\", finalize_summary)\n",
    "\n",
    "# 기본 엣지 추가\n",
    "workflow.add_edge(START, \"generate_summary\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = workflow.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행 및 결과 확인\n",
    "text = \"\"\"\n",
    "인공지능(AI)은 컴퓨터 과학의 한 분야로, 인간의 학습능력과 추론능력, 지각능력,\n",
    "자연언어의 이해능력 등을 컴퓨터 프로그램으로 실현한 기술이다.\n",
    "최근에는 기계학습과 딥러닝의 발전으로 다양한 분야에서 활용되고 있다.\n",
    "\"\"\"\n",
    "\n",
    "initial_state = {\n",
    "    \"original_text\": text,\n",
    "}\n",
    "\n",
    "for chunk in graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    pprint(chunk)\n",
    "    print(\"=\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2217fa83",
      "metadata": {},
      "source": [
        "# **LangSmith**: LLM Observability\n",
        "\n",
        "- LangSmith는 **LLM 애플리케이션의 관찰성(Observability)**을 제공하는 도구임.\n",
        "\n",
        "- 개발자가 LLM 체인과 에이전트를 **효과적으로 디버깅**하고 모니터링할 수 있도록 지원함.\n",
        "\n",
        "- 주요 기능으로는 체인 실행 **로깅 및 추적**이 포함됨.\n",
        "\n",
        "- **프롬프트 디버깅**과 성능 측정 및 분석 기능을 제공함."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70dde1d7",
      "metadata": {},
      "source": [
        "### 1) LangSmith 계정 가입\n",
        "\n",
        "- langsmith 가입 필요 (https://www.langchain.com/langsmith)\n",
        "- 유료 (개인 개발자 대상 부분 무료)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bfd9328",
      "metadata": {
        "id": "8bfd9328"
      },
      "source": [
        "### 2) LangSmith 환경 설정\n",
        "\n",
        "\n",
        "- langsmith 가입 필요 (https://www.langchain.com/langsmith)\n",
        "- 유료 (개인 개발자 대상 부분 무료)\n",
        "\n",
        "- .env 파일에 환경 변수 설정\n",
        "    ```\n",
        "    LANGCHAIN_API_KEY=your_langsmith_api_key\n",
        "    LANGSMITH_TRACING=true\n",
        "    LANGCHAIN_PROJECT=your_project_name \n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ac3ddb",
      "metadata": {
        "id": "15ac3ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "true\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
        "import os\n",
        "\n",
        "print(os.getenv(\"LANGSMITH_TRACING\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "129b8eee",
      "metadata": {
        "id": "129b8eee"
      },
      "source": [
        "---\n",
        "\n",
        "# LCEL(LangChain Expression Language) \n",
        "\n",
        "- **LCEL**은 `|` 연산자를 사용해 컴포넌트들을 순차적으로 연결하는 선언적 체이닝을 지원합니다\n",
        "\n",
        "- **재사용성**이 높아 정의된 체인을 다른 체인의 컴포넌트로 활용할 수 있습니다\n",
        "\n",
        "- **다양한 실행 방식**(.invoke(), .batch(), .stream(), .astream())으로 동기/비동기 처리가 가능합니다\n",
        "\n",
        "- **배치 처리**시 자동 최적화를 통해 효율적인 작업 수행이 가능합니다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68074eb8",
      "metadata": {
        "id": "68074eb8"
      },
      "source": [
        "#### 1) **Prompt + LLM**\n",
        "\n",
        "* 기본 구조: `Prompt | LLM` 형태로, 파이프(|) 연산자를 사용해 프롬프트와 LLM을 순차적으로 연결합니다.\n",
        "\n",
        "* 데이터 흐름: 사용자 입력이 Prompt 템플릿을 통해 처리된 후, LLM에 전달되어 최종 응답이 생성됩니다.\n",
        "\n",
        "* 실행 순서: 파이프라인은 왼쪽에서 오른쪽으로 순차적으로 실행되며, 각 컴포넌트의 출력이 다음 컴포넌트의 입력으로 전달됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3722db67",
      "metadata": {
        "id": "3722db67"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# LLM model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4.1-mini-2025-04-14\",\n",
        "    temperature=0.3,\n",
        "    top_p=0.95,\n",
        ")\n",
        "\n",
        "# 모델에 프롬프트를 입력\n",
        "response = llm.invoke(\"탄소의 원자 번호는 무엇인가요?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9e87eef4",
      "metadata": {
        "id": "9e87eef4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='탄소의 원자 번호는 6입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 18, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-BlT1hhlszLgpzP6zqrua66lVbLYDo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7714c213-1549-4e8b-a3f2-24a0c5a0d2b1-0', usage_metadata={'input_tokens': 18, 'output_tokens': 11, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 객체 확인\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "47ce51f7",
      "metadata": {
        "id": "47ce51f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'탄소의 원자 번호는 6입니다.'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 객체의 텍스트를 확인\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "552cd7af",
      "metadata": {
        "id": "552cd7af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 11,\n",
              "  'prompt_tokens': 18,\n",
              "  'total_tokens': 29,\n",
              "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'reasoning_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0},\n",
              "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
              " 'model_name': 'gpt-4.1-mini-2025-04-14',\n",
              " 'system_fingerprint': 'fp_658b958c37',\n",
              " 'id': 'chatcmpl-BlT1hhlszLgpzP6zqrua66lVbLYDo',\n",
              " 'service_tier': 'default',\n",
              " 'finish_reason': 'stop',\n",
              " 'logprobs': None}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 객체의 메타데이터를 확인\n",
        "response.response_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef7d47a",
      "metadata": {},
      "source": [
        "![Langfuse Screenshot](https://raw.githubusercontent.com/tsdata/image_files/main/202505/langfuse_screenshot_0001.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0113cf90",
      "metadata": {
        "id": "0113cf90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "템플릿 변수:\n",
            "- 필수 변수: ['question', 'topic']\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 템플릿 문자열 정의\n",
        "template = \"\"\"\n",
        "당신은 {topic} 분야의 전문가입니다. {topic}에 관한 다음 질문에 답변해주세요.\n",
        "질문: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# PromptTemplate 객체 생성\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# 템플릿 사용 예시\n",
        "formatted_prompt = prompt.format(\n",
        "    topic=\"인공지능\", question=\"딥러닝과 머신러닝의 주요 차이점은 무엇인가요?\"\n",
        ")\n",
        "\n",
        "print(\"템플릿 변수:\")\n",
        "print(f\"- 필수 변수: {prompt.input_variables}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f4eadaf0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "생성된 프롬프트:\n",
            "\n",
            "당신은 인공지능 분야의 전문가입니다. 인공지능에 관한 다음 질문에 답변해주세요.\n",
            "질문: 딥러닝과 머신러닝의 주요 차이점은 무엇인가요?\n",
            "답변: \n"
          ]
        }
      ],
      "source": [
        "print(\"생성된 프롬프트:\")\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "25b245d7",
      "metadata": {
        "id": "25b245d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "당신은 {topic} 분야의 전문가입니다. {topic}에 관한 다음 질문에 답변해주세요.\n",
            "질문: {question}\n",
            "답변: \n"
          ]
        }
      ],
      "source": [
        "# prompt 객체의 템플릿을 확인\n",
        "print(prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c801f727",
      "metadata": {
        "id": "c801f727"
      },
      "outputs": [],
      "source": [
        "# chain을 구성\n",
        "chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b53e9def",
      "metadata": {
        "id": "b53e9def"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['question', 'topic'], input_types={}, partial_variables={}, template='\\n당신은 {topic} 분야의 전문가입니다. {topic}에 관한 다음 질문에 답변해주세요.\\n질문: {question}\\n답변: ')\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000023E985483E0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000023E9BE0CD40>, root_client=<openai.OpenAI object at 0x0000023E9BDCF6E0>, root_async_client=<openai.AsyncOpenAI object at 0x0000023E9BE0C230>, model_name='gpt-4.1-mini-2025-04-14', temperature=0.3, model_kwargs={}, openai_api_key=SecretStr('**********'), top_p=0.95)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# chain 객체 확인\n",
        "chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6d4f916f",
      "metadata": {
        "id": "6d4f916f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'properties': {'question': {'title': 'Question', 'type': 'string'},\n",
              "  'topic': {'title': 'Topic', 'type': 'string'}},\n",
              " 'required': ['question', 'topic'],\n",
              " 'title': 'PromptInput',\n",
              " 'type': 'object'}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# chain 객체의 입력 스키마를 확인\n",
        "chain.input_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6015e000",
      "metadata": {
        "id": "6015e000"
      },
      "outputs": [],
      "source": [
        "# chain 실행\n",
        "response = chain.invoke(\n",
        "    {\"topic\": \"화학(Chemistry)\", \"question\": \"탄소의 원자 번호는 무엇인가요?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fa75f9ee",
      "metadata": {
        "id": "fa75f9ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='탄소의 원자 번호는 6입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 54, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlTCLKZZgDIqO0lpauvMBC97EaHWm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--44b72a40-c821-406a-bffa-2b2ccac6f63d-0', usage_metadata={'input_tokens': 54, 'output_tokens': 11, 'total_tokens': 65, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 객체를 출력\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "fb0a3843",
      "metadata": {
        "id": "fb0a3843"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'탄소의 원자 번호는 6입니다.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 객체의 텍스트를 출력\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c6c5710c",
      "metadata": {
        "id": "c6c5710c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 11,\n",
              "  'prompt_tokens': 54,\n",
              "  'total_tokens': 65,\n",
              "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'reasoning_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0},\n",
              "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
              " 'model_name': 'gpt-4.1-mini-2025-04-14',\n",
              " 'system_fingerprint': 'fp_6f2eabb9a5',\n",
              " 'id': 'chatcmpl-BlTCLKZZgDIqO0lpauvMBC97EaHWm',\n",
              " 'service_tier': 'default',\n",
              " 'finish_reason': 'stop',\n",
              " 'logprobs': None}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 객체의 메타데이터를 출력\n",
        "response.response_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef365538",
      "metadata": {},
      "source": [
        "![Langfuse Screenshot](https://raw.githubusercontent.com/tsdata/image_files/main/202505/langfuse_screenshot_0002.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "983d4157",
      "metadata": {
        "id": "983d4157"
      },
      "source": [
        "#### **2) Prompt + LLM + Output Parser**\n",
        "\n",
        "* 데이터 파이프라인: `Prompt | LLM | OutputParser` 형태로 구성되어 LLM의 출력을 구조화된 형식으로 변환합니다.\n",
        "\n",
        "* Parser 종류: JSON, XML 등 다양한 형식의 파서를 지원하여 LLM 출력을 원하는 데이터 구조로 변환할 수 있습니다.\n",
        "\n",
        "* 유효성 검증: Parser가 출력 형식을 검증하여 잘못된 형식의 응답을 필터링하고 안정적인 데이터 처리를 보장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "7e6b7607",
      "metadata": {
        "id": "7e6b7607"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'탄소의 원자 번호는 6입니다.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### 문자열 출력 파서\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 출력 파서를 생성\n",
        "output_parser = StrOutputParser() # 문자열만 출력\n",
        "\n",
        "# 출력 파서를 실행\n",
        "output_parser.invoke(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "158608d9",
      "metadata": {
        "id": "158608d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'탄소의 원자 번호는 6입니다.'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 출력 파서를 chain에 추가\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "# chain을 실행\n",
        "response = chain.invoke(\n",
        "    {\"topic\": \"화학(Chemistry)\", \"question\": \"탄소의 원자 번호는 무엇인가요?\"}\n",
        ")\n",
        "\n",
        "# 응답 객체를 출력\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "1e95ba99",
      "metadata": {
        "id": "1e95ba99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'properties': {'question': {'title': 'Question', 'type': 'string'},\n",
              "  'topic': {'title': 'Topic', 'type': 'string'}},\n",
              " 'required': ['question', 'topic'],\n",
              " 'title': 'PromptInput',\n",
              " 'type': 'object'}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# input_schema (chain)\n",
        "chain.input_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ba0d6997",
      "metadata": {
        "id": "ba0d6997"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'properties': {'question': {'title': 'Question', 'type': 'string'},\n",
              "  'topic': {'title': 'Topic', 'type': 'string'}},\n",
              " 'required': ['question', 'topic'],\n",
              " 'title': 'PromptInput',\n",
              " 'type': 'object'}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# input_schema (prompt) \n",
        "# chain의 시작이 prompt여서 값이 동일해야 맞음\n",
        "prompt.input_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c9d7e7",
      "metadata": {},
      "source": [
        "![Langfuse Screenshot](https://raw.githubusercontent.com/tsdata/image_files/main/202505/langfuse_screenshot_0003.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4456bde9",
      "metadata": {
        "id": "4456bde9"
      },
      "source": [
        "---\n",
        "# **Runnable**\n",
        "\n",
        "* 실행 인터페이스: 모든 LangChain 컴포넌트는 Runnable 인터페이스를 구현하여 일관된 방식으로 실행됩니다.\n",
        "\n",
        "* 실행 메서드: `.invoke()`, `.batch()`, `.stream()`, `.astream()` 등 다양한 실행 방식을 제공합니다.\n",
        "\n",
        "* 호환성: 모든 Runnable 컴포넌트는 파이프(|) 연산자를 통해 연결 가능하며, 재사용이 용이합니다.\n",
        "\n",
        "* Runnable의 주요 유형:\n",
        "\n",
        "    * `RunnableSequence`: 여러 Runnable을 순차적으로 실행\n",
        "    * `RunnablePassthrough`: 입력을 그대로 다음 단계로 전달    \n",
        "    * `RunnableParallel`: 여러 Runnable을 병렬로 실행\n",
        "    * `RunnableLambda`: 파이썬 함수를 Runnable로 래핑하여 체인에서 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022d0cfd",
      "metadata": {},
      "source": [
        "#### 1) **RunnableSequence**\n",
        "\n",
        "- **RunnableSequence**는 컴포넌트들을 연결하여 순차적으로 데이터를 처리하는 체인입니다\n",
        "\n",
        "- `|` 연산자로 연결된 각 단계의 **출력이 다음 단계의 입력**으로 전달됩니다\n",
        "\n",
        "- **다양한 실행 방식**(동기/비동기, 배치/스트리밍)을 지원합니다\n",
        "\n",
        "- LLM 체인, 데이터 파이프라인, 자동화된 작업 등 **다단계 처리**에 활용됩니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ac7c9cd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableSequence\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# 컴포넌트 정의\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"'{text}'를 영어로 번역해주세요. 번역된 문장만을 출력해주세요.\"\n",
        ")\n",
        "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.3, top_p=0.95)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# RunnableSequence 생성 - 함수 사용\n",
        "translation_chain = RunnableSequence(\n",
        "    first=prompt, middle=[model], last=output_parser  # 리스트로 전달하는 점에 주의\n",
        ")\n",
        "\n",
        "# RunnableSequence 생성 - 연산자 사용\n",
        "# translation_chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae5ff8cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello\n"
          ]
        }
      ],
      "source": [
        "# 동기 실행\n",
        "result = translation_chain.invoke({\"text\": \"안녕하세요\"})\n",
        "print(result)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e93eb560",
      "metadata": {},
      "source": [
        "![Langfuse Screenshot](https://raw.githubusercontent.com/tsdata/image_files/main/202505/langfuse_screenshot_0004.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fb7e8bf",
      "metadata": {},
      "source": [
        "#### 2) **RunnableParallel**\n",
        "\n",
        "- **RunnableParallel**은 여러 컴포넌트를 딕셔너리 형태로 구성해 **동시 실행**합니다\n",
        "\n",
        "- 동일한 입력이 모든 병렬 컴포넌트에 전달되며, 결과는 **키-값 쌍**으로 반환됩니다\n",
        "\n",
        "- **데이터 변환**과 **파이프라인 구성**에 특화되어 있으며, 출력 형식을 다음 단계에 맞게 조정할 수 있습니다"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625baaa0",
      "metadata": {},
      "source": [
        "`(1) 질문 분석 체인`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "1f19926e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "분류 결과: 화학(Chemistry)\n"
          ]
        }
      ],
      "source": [
        "# 질문과 관련된 분야를 찾는 프롬프트\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 출력 파서 정의\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 질문 템플릿 정의\n",
        "question_template = \"\"\"\n",
        "다음 카테고리 중 하나로 입력을 분류하세요. 다른 불필요한 텍스트는 출력하지 마세요:\n",
        "- 화학(Chemistry)\n",
        "- 물리(Physics)\n",
        "- 생물(Biology)\n",
        "\n",
        "# 예시:\n",
        "Q: 사람의 염색체는 모두 몇개가 있나요?\n",
        "A: 생물(Biology)\n",
        "\n",
        "Q: {question}\n",
        "A: \"\"\"\n",
        "\n",
        "# 프롬프트 생성\n",
        "question_prompt = PromptTemplate.from_template(question_template)\n",
        "\n",
        "# 체인 구성\n",
        "question_chain = question_prompt | llm | output_parser\n",
        "\n",
        "# 체인 실행\n",
        "result = question_chain.invoke({\"question\": \"탄소의 원자 번호는 무엇인가요?\"})\n",
        "print(f\"분류 결과: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9afa45a8",
      "metadata": {},
      "source": [
        "`(2) 언어 감지 체인`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "f5ce2883",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력: What is the atomic number of carbon?\n",
            "분류 결과: English\n",
            "\n",
            "입력: 탄소의 원자 번호는 무엇인가요?\n",
            "분류 결과: Korean\n",
            "\n",
            "입력: ¿Cuál es el número atómico del carbono?\n",
            "분류 결과: Others\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 질문에 사용된 언어를 구분하는 프롬프트\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 출력 파서 정의\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 언어 분류 템플릿 정의\n",
        "language_template = \"\"\"\n",
        "입력된 텍스트의 언어를 다음 카테고리 중 하나로 분류하세요. 다른 불필요한 텍스트는 출력하지 마세요:\n",
        "- 영어(English)\n",
        "- 한국어(Korean)\n",
        "- 기타(Others)\n",
        "\n",
        "# 예시:\n",
        "Q: How many protons are in a carbon atom?\n",
        "A: English\n",
        "\n",
        "Q: 탄소의 원자 번호는 무엇인가요?\n",
        "A: Korean\n",
        "\n",
        "Q: ¿Cuál es el número atómico del carbono?\n",
        "A: Others\n",
        "\n",
        "입력: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# 프롬프트 생성\n",
        "language_prompt = PromptTemplate.from_template(language_template)\n",
        "\n",
        "# 체인 구성\n",
        "language_chain = language_prompt | llm | output_parser\n",
        "\n",
        "# 체인 실행 예시\n",
        "examples = [\n",
        "    \"What is the atomic number of carbon?\",\n",
        "    \"탄소의 원자 번호는 무엇인가요?\",\n",
        "    \"¿Cuál es el número atómico del carbono?\",\n",
        "]\n",
        "\n",
        "for example in examples:\n",
        "    result = language_chain.invoke({\"question\": example})\n",
        "    print(f\"입력: {example}\")\n",
        "    print(f\"분류 결과: {result}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c273a56e",
      "metadata": {},
      "source": [
        "`(3) RunnableParallel을 사용한 병렬 실행 체인`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "bf0b47c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "처리 결과:\n",
            "답변: 탄소의 원자 번호는 6입니다.\n"
          ]
        }
      ],
      "source": [
        "# 질문과 관련된 분야를 찾아서 질문에 대한 답변을 생성하는 프롬프트\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "# 답변 템플릿 정의\n",
        "answer_template = \"\"\"\n",
        "당신은 {topic} 분야의 전문가입니다. {topic}에 관한 질문에 {language}로 답변해주세요.\n",
        "질문: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# 프롬프트 및 체인 구성\n",
        "answer_prompt = PromptTemplate.from_template(answer_template)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 병렬 처리 체인 구성\n",
        "answer_chain = (\n",
        "    RunnableParallel(\n",
        "        {\n",
        "            \"topic\": question_chain,  # 주제 분류 체인\n",
        "            \"language\": language_chain,  # 언어 감지 체인\n",
        "            \"question\": itemgetter(\"question\"),  # 원본 질문 추출\n",
        "        }\n",
        "    )\n",
        "    | answer_prompt\n",
        "    | llm\n",
        "    | output_parser\n",
        ")\n",
        "\n",
        "# 체인 실행 예시\n",
        "result = answer_chain.invoke({\"question\": \"탄소의 원자 번호는 무엇인가요?\"})\n",
        "\n",
        "print(\"처리 결과:\")\n",
        "print(f\"답변: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad2f4dc",
      "metadata": {},
      "source": [
        "![Langfuse Screenshot](https://raw.githubusercontent.com/tsdata/image_files/main/202505/langfuse_screenshot_0005.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89ddb27f",
      "metadata": {},
      "source": [
        "#### 3) **RunnablePassthrough**\n",
        "\n",
        "- **RunnablePassthrough**는 입력값을 그대로 전달하여 원본 데이터를 보존합니다\n",
        "\n",
        "- **RunnableParallel**과 함께 사용되어 입력 데이터를 새로운 키로 매핑할 수 있습니다\n",
        "\n",
        "- **투명한 데이터 흐름**으로 파이프라인 디버깅과 구성이 용이합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11de1469",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "import re\n",
        "\n",
        "runnable = RunnableParallel(\n",
        "    passed=RunnablePassthrough(),\n",
        "    modified=lambda x: int(re.search(r\"\\d+\", x[\"query\"]).group()),\n",
        ")\n",
        "\n",
        "runnable.invoke({\"query\": \"탄소의 원자 번호는 6입니다.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "346a12dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "runnable = RunnableParallel(\n",
        "    passed=RunnablePassthrough(),\n",
        "    modified=lambda x: int(re.search(r\"\\d+\", x).group()),\n",
        ")\n",
        "\n",
        "runnable.invoke(\"탄소의 원자 번호는 6입니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e888c65",
      "metadata": {
        "id": "2e888c65"
      },
      "source": [
        "#### 4) **RunnableLambda**\n",
        "\n",
        "- **RunnableLambda**는 일반 함수를 Runnable 객체로 변환하는 래퍼 컴포넌트입니다\n",
        "\n",
        "- 체인에 **커스텀 로직**을 쉽게 통합할 수 있어 데이터 전처리, 후처리에 유용합니다\n",
        "\n",
        "- `|` 연산자로 다른 컴포넌트들과 연결해 **복잡한 처리 흐름**을 구성할 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7f8d92f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "\n",
        "# 텍스트에서 숫자를 추출하는 함수\n",
        "def extract_number(query):\n",
        "    return int(re.search(r\"\\d+\", query).group())\n",
        "\n",
        "\n",
        "# RunnablePassthrough로 입력을 그대로 전달하고, RunnableLambda로 숫자 추출 함수 실행\n",
        "runnable = RunnablePassthrough() | RunnableLambda(extract_number)\n",
        "\n",
        "# 입력 텍스트에서 6을 추출\n",
        "result = runnable.invoke(\"탄소의 원자 번호는 6입니다.\")\n",
        "print(result)  # 출력: 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6704894c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.schema.runnable import RunnableLambda\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "# 데이터 전처리 함수 정의\n",
        "def preprocess_text(text: str) -> str:\n",
        "    \"\"\"입력 텍스트를 소문자로 변환하고 양쪽 공백을 제거합니다.\"\"\"\n",
        "    return text.strip().lower()\n",
        "\n",
        "\n",
        "# 후처리 함수 정의\n",
        "def postprocess_response(response: str) -> dict:\n",
        "    \"\"\"응답 텍스트를 대문자로 변환하고 길이를 계산합니다.\"\"\"\n",
        "    response_text = response.content\n",
        "    return {\"processed_response\": response_text.upper(), \"length\": len(response_text)}\n",
        "\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"다음 주제에 대해 영어 한 문장으로 설명해주세요: {topic}\"\n",
        ")\n",
        "\n",
        "# 처리 파이프라인 구성\n",
        "chain = (\n",
        "    RunnableLambda(preprocess_text)  # 입력 전처리\n",
        "    | prompt  # 프롬프트 포맷팅\n",
        "    | llm  # LLM 추론\n",
        "    | RunnableLambda(postprocess_response)  # 출력 후처리\n",
        ")\n",
        "\n",
        "# 체인 실행\n",
        "result = chain.invoke(\"  Artificial Intelligence  \")\n",
        "print(f\"처리된 응답: {result['processed_response']}\")\n",
        "print(f\"응답 길이: {result['length']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af924b54",
      "metadata": {},
      "source": [
        "![Langfuse Screenshot](https://raw.githubusercontent.com/tsdata/image_files/main/202505/langfuse_screenshot_0006.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "367d46b8",
      "metadata": {},
      "source": [
        "---\n",
        "# [실습]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5b260a",
      "metadata": {},
      "source": [
        "- **다음과 같은 요구사항을 LCEL로 구현합니다**\n",
        "   1. 사용자 입력을 받아 내용을 요약하기\n",
        "   2. 요약된 내용을 기반으로 감정 분석하기 (긍정, 부정, 중립)\n",
        "   3. 요약된 문장과 감정 분석 결과를 출력하기 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e424f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 프롬프트 템플릿 정의\n",
        "summarize_prompt = None\n",
        "\n",
        "sentiment_prompt = None\n",
        "\n",
        "# 문자열 출력 파서\n",
        "output_parser = None\n",
        "\n",
        "# 체인 구성\n",
        "model = None\n",
        "\n",
        "# 요약 체인\n",
        "summarize_chain = None\n",
        "\n",
        "# 감정 분석 체인\n",
        "sentiment_chain = None\n",
        "\n",
        "# 전체 체인\n",
        "chain = None\n",
        "\n",
        "# 사용 예시\n",
        "text = \"\"\"오늘 아침 일어나서 시험 준비를 위해 마지막으로 복습을 했다. \n",
        "시험장에 들어가서 문제를 풀 때는 긴장했지만, 평소에 열심히 공부했던 내용들이 잘 기억났다.\n",
        "시험 시간이 끝나고 답안지를 제출할 때는 자신감이 있었다.\n",
        "결과를 확인했을 때 만점을 받았다는 것을 알게 되었고, 그 순간 정말 기뻤다.\n",
        "지난 몇 주 동안 밤늦게까지 공부했던 노력이 결실을 맺은 것 같아 뿌듯했다.\n",
        "선생님께서도 칭찬해 주셔서 더욱 기쁘고 보람찼다.\n",
        "이번 경험을 통해 노력하면 반드시 좋은 결과가 따른다는 것을 다시 한번 깨달았다.\"\"\"\n",
        "\n",
        "result = None"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

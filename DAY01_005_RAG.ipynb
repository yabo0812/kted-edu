{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f191d1cf",
   "metadata": {},
   "source": [
    "#  RAG 체인 구성\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641ec21",
   "metadata": {},
   "source": [
    "# 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be5eb8",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d8712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5989430",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69732dd",
   "metadata": {},
   "source": [
    "# 다양한 문서 형식 처리하기\n",
    "\n",
    "- 역할: Document Loader는 다양한 소스에서 문서를 로드\n",
    "- 구현: \n",
    "    - Document Loader는 BaseLoader 인터페이스를 통해서 구현\n",
    "    - `.load()` 또는 `.lazy_load()` 메서드를 통해 동일한 방식으로 호출 \n",
    "    - 대용량 데이터셋의 경우 메모리 효율을 위해 `.lazy_load()`를 사용하는 것을 권장 \n",
    "- 종류:\n",
    "    - PDF 파일 로더\n",
    "    - 웹 페이지 로더 \n",
    "    - CSV 데이터 로더\n",
    "    - 디렉토리 로더\n",
    "    - HTML 데이터 로더\n",
    "    - JSON 데이터 로더\n",
    "    - Markdown 데이터 로더\n",
    "    - Microsoft Office 데이터 로더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ca1af2",
   "metadata": {},
   "source": [
    "### 1. **웹 문서 로더**\n",
    "\n",
    "- uv add bs4 langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 기본적인 텍스트 추출\n",
    "web_loader = WebBaseLoader(\n",
    "    web_paths=[\n",
    "        \"https://python.langchain.com/\", \n",
    "        \"https://js.langchain.com/\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# 동기 로딩\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "len(web_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f173ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cdeb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(web_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645da45b",
   "metadata": {},
   "source": [
    "### 2. **CSV 파일 로더**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75179f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# 기본 파일 로드\n",
    "csv_loader = CSVLoader(\"./data/kbo_teams_2023.csv\")\n",
    "csv_docs = csv_loader.load()\n",
    "\n",
    "print(\"문서의 수:\", len(csv_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 메타데이터: \\n\", csv_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 내용: \\n\", csv_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 소스 컬럼 지정\n",
    "\n",
    "csv_loader = CSVLoader(\n",
    "    file_path=\"./data/kbo_teams_2023.csv\",\n",
    "    source_column=\"Team\"  # 이 컬럼의 값이 메타데이터의 source로 사용됨\n",
    ")\n",
    "\n",
    "csv_docs = csv_loader.load()\n",
    "\n",
    "print(\"문서의 수:\", len(csv_docs))\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 메타데이터: \\n\", csv_docs[0].metadata)\n",
    "print(\"-\" * 50)\n",
    "print(\"처음 문서의 내용: \\n\", csv_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d28ef",
   "metadata": {},
   "source": [
    "### 3. **PDF 파일 로더**\n",
    "\n",
    "- uv add langchain_community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 로더 초기화 (근로기준법 문서)\n",
    "pdf_loader = PyPDFLoader('./data/labor_law.pdf')\n",
    "\n",
    "# 동기 로딩\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb33946",
   "metadata": {},
   "source": [
    "# 텍스트 분할(Text Splitting) \n",
    "\n",
    "- 대규모 텍스트 문서를 처리할 때 매우 중요한 전처리 단계\n",
    "- 고려사항:\n",
    "    1. 문서의 구조와 형식\n",
    "    2. 원하는 청크 크기\n",
    "    3. 문맥 보존의 중요도\n",
    "    4. 처리 속도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a007e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'첫 번째 문서: {pdf_docs[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = pdf_docs[0].page_content\n",
    "print(f'첫 번째 문서의 텍스트 길이: {len(long_text)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a5ec79",
   "metadata": {},
   "source": [
    "### 1. **CharacterTextSplitter**\n",
    "- 가장 기본적인 분할 방식\n",
    "- 문자 수를 기준으로 텍스트를 분할\n",
    "- 단순하지만 문맥을 고려하지 않는다는 단점이 있음\n",
    "\n",
    "- 설치: pip install langchain_text_splitters 또는 uv add langchain_text_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter \n",
    "\n",
    "# 텍스트 분할기 초기화 (기본 설정값 적용 )\n",
    "text_splitter = CharacterTextSplitter(\n",
    "\n",
    "    # CharacterTextSplitter의 기본 설정값\n",
    "    separator = \"\\n\\n\",         # 청크 구분자: 두 개의 개행문자\n",
    "    is_separator_regex = False,  # 구분자가 정규식인지 여부\n",
    "\n",
    "    # TextSplitter의 기본 설정값\n",
    "    chunk_size = 1000,          # 청크 길이\n",
    "    chunk_overlap = 200,        # 청크 중첩\n",
    "    length_function = len,      # 길이 함수 (문자열 길이)\n",
    "    keep_separator = False,     # 구분자 유지 여부\n",
    "    add_start_index = False,   # 시작 인덱스 추가 여부\n",
    "    strip_whitespace = True,   # 공백 제거 여부\n",
    ")\n",
    "\n",
    "# 텍스트 분할 - split_text() 메서드 사용\n",
    "texts = text_splitter.split_text(long_text)\n",
    "\n",
    "# 분할된 텍스트 개수 출력\n",
    "print(f'분할된 텍스트 개수: {len(texts)}')\n",
    "\n",
    "# 첫 번째 분할된 텍스트 출력\n",
    "print(f'첫 번째 분할된 텍스트: {texts[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 문장 구분자를 개행문자로 설정\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",        # 청크 구분자: 개행문자\n",
    "    chunk_size = 1000,       # 청크 길이\n",
    "    chunk_overlap = 200      # 청크 중첩\n",
    ")\n",
    "\n",
    "# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할\n",
    "chunks = text_splitter.split_documents([pdf_docs[0]])   # 첫 번째 문서만 분할\n",
    "\n",
    "# 분할된 텍스트 개수 출력\n",
    "print(f'분할된 텍스트 개수: {len(chunks)}')\n",
    "\n",
    "# 각 청크의 텍스트 길이 출력\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f'청크 {i+1}의 텍스트 길이: {len(chunk.page_content)}')\n",
    "\n",
    "# 첫 번째 청크의 텍스트 출력\n",
    "print(f'첫 번째 청크의 텍스트: {chunks[0].page_content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7466eb",
   "metadata": {},
   "source": [
    "### 2. **RecursiveCharacterTextSplitter**\n",
    "\n",
    "- 재귀적으로 텍스트를 분할\n",
    "- 구분자를 순차적으로 적용하여 큰 청크에서 시작하여 점진적으로 더 작은 단위로 분할\n",
    "- 문맥을 더 잘 보존할 수 있음  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f67f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 재귀적 텍스트 분할기 초기화\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,             # 청크 크기  \n",
    "    chunk_overlap=200,           # 청크 중 중복되는 부분 크기\n",
    "    length_function=len,         # 글자 수를 기준으로 분할\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # 구분자 - 재귀적으로 순차적으로 적용 \n",
    ")\n",
    "\n",
    "# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할\n",
    "chunks = text_splitter.split_documents(pdf_docs)\n",
    "print(f\"생성된 텍스트 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "# 각 청크의 시작 부분과 끝 부분 확인 - 5개 청크만 출력\n",
    "for chunk in chunks[:5]:\n",
    "    print(chunk.page_content[:200])\n",
    "    print(\"-\" * 100)\n",
    "    print(chunk.page_content[-200:])\n",
    "    print(\"=\" * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0ecd1d",
   "metadata": {},
   "source": [
    "### 3. **정규표현식 사용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 문장을 구분하여 분할 - 정규표현식 사용 (문장 구분자: 마침표, 느낌표, 물음표 다음에 공백이 오는 경우)\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=r'(?<=[.!?])\\s+',  # 각 Document 객체의 page_content 속성을 문장으로 분할\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    is_separator_regex=True,      # 구분자가 정규식인지 여부: True\n",
    "    keep_separator=True,          # 구분자 유지 여부: True\n",
    ")\n",
    "\n",
    "# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할\n",
    "chunks = text_splitter.split_documents(pdf_docs)  # 모든 문서를 분할\n",
    "print(f\"생성된 텍스트 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "# 각 청크의 시작 부분과 끝 부분 확인 - 5개 청크만 출력\n",
    "for chunk in chunks[:5]:\n",
    "    print(chunk.page_content[:200])\n",
    "    print(\"...\")\n",
    "    print(chunk.page_content[-200:])\n",
    "    print(\"=\" * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac17b61",
   "metadata": {},
   "source": [
    "`(4) 유사도 기반 검색`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4764ba",
   "metadata": {},
   "source": [
    "### 4. **토큰 수를 기반으로 분할**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2721f",
   "metadata": {},
   "source": [
    "`(1) tiktoken`  \n",
    "- OpenAI에서 만든 BPE Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a3f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 문서 객체의 텍스트 길이\n",
    "len(pdf_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58081f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# TikToken 인코더를 사용하여 재귀적 텍스트 분할기 초기화\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", \n",
    "    # model_name=\"gpt-4.1-mini\",\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할\n",
    "chunks = text_splitter.split_documents([pdf_docs[0]])  # 첫 번째 문서만 분할\n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "\n",
    "# 각 청크의 시작 부분과 끝 부분 확인\n",
    "for chunk in chunks[:5]:\n",
    "    print(chunk.page_content[:50])\n",
    "    print(\"-\" * 50)\n",
    "    print(chunk.page_content[-50:])\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7bff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "# tokenizer = tiktoken.encoding_for_model(\"gpt-4.1-mini\")\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "\n",
    "    # 각 청크를 토큰화\n",
    "    tokens = tokenizer.encode(chunk.page_content)\n",
    "    # 각 청크의 단어 수 확인\n",
    "    print(len(tokens))\n",
    "    # 각 청크의 토큰화 결과 확인 (첫 10개 토큰만 출력)\n",
    "    print(tokens[:10])\n",
    "    # 토큰 ID를 실제 토큰(문자열)로 변환해서 출력\n",
    "    token_strings = [tokenizer.decode([token]) for token in tokens[:10]]\n",
    "    print(token_strings)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5956daaa",
   "metadata": {},
   "source": [
    "`(2) Hugging Face 토크나이저`  \n",
    "- Hugging Face tokenizer 모델의 토큰 수를 기준으로 분할\n",
    "- uv add langchain_huggingface sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d51cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5abee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 인코딩 - 문장을 토큰(ID)으로 변환\n",
    "tokens = tokenizer.encode(\"안녕하세요. 반갑습니다.\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a76e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰을 출력 (토큰 ID를 실제 토큰(문자열)로 변환)\n",
    "print(tokenizer.convert_ids_to_tokens(tokens)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfbaec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코딩 - 토큰을 문자열로 변환\n",
    "print(tokenizer.decode(tokens, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c468edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Huggingface 토크나이저를 사용하여 재귀적 텍스트 분할기 초기화\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할\n",
    "chunks = text_splitter.split_documents([pdf_docs[0]]) # 첫 번째 문서만 분할\n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "\n",
    "    # 각 청크를 토큰화\n",
    "    tokens = tokenizer.encode(chunk.page_content)\n",
    "    # 각 청크의 단어 수 확인\n",
    "    print(len(tokens))\n",
    "    # 각 청크의 토큰화 결과 확인 (첫 10개 토큰만 출력)\n",
    "    print(tokens[:10])\n",
    "    # 토큰 ID를 실제 토큰(문자열)로 변환해서 출력\n",
    "    token_strings = tokenizer.convert_ids_to_tokens(tokens[:10]) \n",
    "    print(token_strings)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0bbc2e",
   "metadata": {},
   "source": [
    "### 5. **Semantic Chunking**\n",
    "\n",
    "- **SemanticChunker**는 텍스트를 의미 단위로 **분할**하는 특수한 텍스트 분할도구 \n",
    "\n",
    "- 단순 길이 기반이 아닌 **의미 기반**으로 텍스트를 청크화하는데 효과적\n",
    "\n",
    "- **breakpoint_threshold_type**: Text Splitting의 다양한 임계값(Threshold) 설정 방식 (통계적 기법) \n",
    "\n",
    "    - **Gradient** 방식: 임베딩 벡터 간의 **기울기 변화**를 기준으로 텍스트를 분할\n",
    "    - **Percentile** 방식: 임베딩 거리의 **백분위수**를 기준으로 분할 지점을 결정\n",
    "    - **Standard Deviation** 방식: 임베딩 거리의 **표준편차**를 활용하여 유의미한 변화점을 찾아서 분할\n",
    "    - **Interquartile** 방식: 임베딩 거리의 **사분위수 범위**를 기준으로 이상치를 감지하여 분할\n",
    "\n",
    "- 설치: pip install langchain_experimental 또는 uv add langchain_experimental\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker \n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 임베딩 모델을 사용하여 SemanticChunker를 초기화 \n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"),         # OpenAI 임베딩 사용\n",
    "    breakpoint_threshold_type=\"gradient\",  # 임계값 타입 설정 (gradient, percentile, standard_deviation, interquartile)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956587ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents([pdf_docs[0]])\n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "print()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "\n",
    "    # 각 청크를 토큰화\n",
    "    tokens = tokenizer.encode(chunk.page_content)\n",
    "    # 각 청크의 단어 수 확인\n",
    "    print(len(tokens))\n",
    "    # 각 청크의 내용을 확인\n",
    "    print(chunk.page_content[:100])\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943d4bb",
   "metadata": {},
   "source": [
    "# 문서 임베딩(Document Embedding)\n",
    "\n",
    "- 개념: \n",
    "    - 텍스트를 벡터(숫자 배열)로 변환하는 과정\n",
    "    - 문서의 의미적 특성을 수치화하여 컴퓨터가 이해하고 처리할 수 있는 형태로 변환 \n",
    "\n",
    "- 목적:\n",
    "    - 텍스트 간 유사도 계산 가능\n",
    "    - 벡터 데이터베이스 저장 및 검색\n",
    "    - 의미 기반 문서 검색 구현\n",
    "\n",
    "- LangChain의 임베딩 모델 종류:\n",
    "    - OpenAI 임베딩\n",
    "    - HuggingFace 임베딩 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1028fb3c",
   "metadata": {},
   "source": [
    "### 1. **OpenAI**\n",
    "\n",
    "- LangChain에서 가장 널리 사용되는 임베딩 모델 중 하나\n",
    "\n",
    "- 주요 특징:\n",
    "    1. 고품질의 임베딩 생성\n",
    "    2. 다양한 언어 지원 (다국어 지원)\n",
    "    3. 일관된 성능\n",
    "    4. 손쉬운 통합\n",
    "\n",
    "- 사용시 주의사항:\n",
    "    1. API 키 설정이 필요 (환경 변수 OPENAI_API_KEY)\n",
    "    2. API 사용량에 따른 비용 발생\n",
    "    3. 긴 텍스트는 자동으로 분할되지 않으므로 필요시 TextSplitter를 사용\n",
    "\n",
    "\n",
    "- 모델별 특징\n",
    "    ```\n",
    "    모델                    페이지/달러    MTEB 성능     최대입력\n",
    "    text-embedding-3-small  62,500       62.3%       8191\n",
    "    text-embedding-3-large   9,615       64.6%       8191\n",
    "    text-embedding-ada-002  12,500       61.0%       8191\n",
    "    ```\n",
    "\n",
    "- 임베딩 벡터 특성\n",
    "    1. small: 1536 차원\n",
    "    1. large: 3072 차원\n",
    "    1. dimensions 파라미터로 차원 축소 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d24267",
   "metadata": {},
   "source": [
    "`(1) embedding 모델`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e021e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAIEmbeddings 모델 생성\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",  # 사용할 모델 이름\n",
    "    dimensions=None, # 원하는 임베딩 차원 수를 지정 가능 (기본값: None)\n",
    "    )\n",
    "\n",
    "# 임베딩 객체 출력\n",
    "embeddings_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1296c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델의 컨텍스트 길이 확인\n",
    "embeddings_model.embedding_ctx_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3cf77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAIEmbeddings 모델 생성할 때 임베딩 차원을 지정하는 예시\n",
    "embeddings_openai = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",  # 사용할 모델 이름\n",
    "    dimensions=1024, # 원하는 임베딩 차원 수를 지정 가능 (기본값: None)\n",
    "    )\n",
    "\n",
    "# 임베딩 모델의 임베딩 차원 확인 \n",
    "embeddings_openai.dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed077e",
   "metadata": {},
   "source": [
    "`(2) embed_documents 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979cefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 컬렉션\n",
    "documents = [\n",
    "    \"인공지능은 컴퓨터 과학의 한 분야입니다.\",\n",
    "    \"머신러닝은 인공지능의 하위 분야입니다.\",\n",
    "    \"딥러닝은 머신러닝의 한 종류입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.\",\n",
    "    \"컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 방법을 연구합니다.\"\n",
    "]\n",
    "\n",
    "# 문서 임베딩\n",
    "document_embeddings_openai = embeddings_openai.embed_documents(documents)\n",
    "\n",
    "# 임베딩 결과 출력\n",
    "print(f\"임베딩 벡터의 개수: {len(document_embeddings_openai)}\")\n",
    "print(f\"임베딩 벡터의 차원: {len(document_embeddings_openai[0])}\")\n",
    "print(document_embeddings_openai[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adef264",
   "metadata": {},
   "source": [
    "`(3) embed_query 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668fd5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_query_openai = embeddings_openai.embed_query(\"인공지능이란 무엇인가요?\")\n",
    "\n",
    "# 쿼리 임베딩 결과 출력\n",
    "print(f\"쿼리 임베딩 벡터의 차원: {len(embedded_query_openai)}\")\n",
    "print(embedded_query_openai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63d0f4",
   "metadata": {},
   "source": [
    "`(4) 유사도 기반 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7029f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 쿼리와 가장 유사한 문서 찾기 함수\n",
    "def find_most_similar(\n",
    "        query: str, \n",
    "        doc_embeddings: np.ndarray,\n",
    "        embeddings_model=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        ) -> tuple[str, float]:\n",
    "    \n",
    "    # 쿼리 임베딩: OpenAI 임베딩 사용 \n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "\n",
    "    # 가장 유사한 문서 인덱스 찾기\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "\n",
    "    # 가장 유사한 문서와 유사도 반환: 문서, 유사도\n",
    "    return documents[most_similar_idx], similarities[most_similar_idx]\n",
    "\n",
    "# 예제 쿼리\n",
    "queries = [\n",
    "    \"인공지능이란 무엇인가요?\",\n",
    "    \"딥러닝과 머신러닝의 관계는 어떻게 되나요?\",\n",
    "    \"컴퓨터가 이미지를 이해하는 방법은?\"\n",
    "]\n",
    "\n",
    "# 각 쿼리에 대해 가장 유사한 문서 찾기\n",
    "for query in queries:\n",
    "    most_similar_doc, similarity = find_most_similar(\n",
    "        query, \n",
    "        document_embeddings_openai, \n",
    "        embeddings_model=embeddings_openai\n",
    "        )\n",
    "    print(f\"쿼리: {query}\")\n",
    "    print(f\"가장 유사한 문서: {most_similar_doc}\")\n",
    "    print(f\"유사도: {similarity:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c841a4",
   "metadata": {},
   "source": [
    "### 2. **Huggingface**\n",
    "\n",
    "- LangChain에서 오픈소스 기반의 대표적인 임베딩 모델\n",
    "\n",
    "- 주요 특징:\n",
    "    1. 로컬 환경에서 실행 가능\n",
    "    2. 다양한 사전학습 모델 지원\n",
    "    3. 커스텀 모델 학습 및 적용 가능\n",
    "    4. 무료 사용 가능 (API 비용 없음)\n",
    "\n",
    "- 사용시 주의사항:\n",
    "    1. 로컬 컴퓨팅 자원 필요 (CPU/GPU)\n",
    "    2. 초기 모델 다운로드 시간 소요\n",
    "    3. 메모리 사용량 고려 필요\n",
    "    4. transformers 라이브러리 설치 필요\n",
    "\n",
    "- 대표적인 임베딩 모델:\n",
    "    ```\n",
    "    모델                            차원      언어             특징      \n",
    "    all-MiniLM-L6-v2               384     다국어     빠른 속도, 적은 메모리\n",
    "    all-mpnet-base-v2              768     다국어     높은 성능, 중간 크기\n",
    "    multilingual-e5-large         1024     다국어     최고 성능, 큰 메모리\n",
    "    ```\n",
    "\n",
    "- 임베딩 벡터 특성:\n",
    "    1. 모델별로 다양한 차원 제공 (128 ~ 1024)\n",
    "    2. sentence-transformers 기반 구현\n",
    "    3. BERT 계열 모델 구조 사용\n",
    "    4. 코사인 유사도 기반 검색 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484e59a6",
   "metadata": {},
   "source": [
    "`(1) embedding 모델`\n",
    "\n",
    "- langchain_huggingface 설치 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bae91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings  \n",
    "\n",
    "# Hugging Face의 임베딩 모델 생성\n",
    "embeddings_bgem3 = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",          # 사용할 모델 이름 - BAAI BGE-m3 모델 (한국어 성능 우수)\n",
    "    # model_kwargs={'device': 'cuda'}  # GPU 사용시\n",
    "    # model_kwargs={'device': 'mps'}   # Mac M1 사용시\n",
    ")\n",
    "\n",
    "# 임베딩 객체 출력\n",
    "embeddings_bgem3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a5304f",
   "metadata": {},
   "source": [
    "`(2) embed_documents 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3645498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 임베딩\n",
    "document_embeddings_bgem3 = embeddings_bgem3.embed_documents(documents)\n",
    "\n",
    "# 임베딩 결과 출력\n",
    "print(f\"임베딩 벡터의 개수: {len(document_embeddings_bgem3)}\")\n",
    "print(f\"임베딩 벡터의 차원: {len(document_embeddings_bgem3[0])}\")\n",
    "print(document_embeddings_bgem3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447c8889",
   "metadata": {},
   "source": [
    "`(3) embed_query 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc1b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_query = embeddings_bgem3.embed_query(\"인공지능이란 무엇인가요?\")\n",
    "\n",
    "# 쿼리 임베딩 결과 출력\n",
    "print(f\"쿼리 임베딩 벡터의 차원: {len(embedded_query)}\")\n",
    "print(embedded_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62990788",
   "metadata": {},
   "source": [
    "`(4) 유사도 기반 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 쿼리\n",
    "queries = [\n",
    "    \"인공지능이란 무엇인가요?\",\n",
    "    \"딥러닝과 머신러닝의 관계는 어떻게 되나요?\",\n",
    "    \"컴퓨터가 이미지를 이해하는 방법은?\"\n",
    "]\n",
    "\n",
    "# 각 쿼리에 대해 가장 유사한 문서 찾기\n",
    "for query in queries:\n",
    "    most_similar_doc, similarity = find_most_similar(query, document_embeddings_bgem3, embeddings_model=embeddings_bgem3) \n",
    "    print(f\"쿼리: {query}\")\n",
    "    print(f\"가장 유사한 문서: {most_similar_doc}\")\n",
    "    print(f\"유사도: {similarity:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aeea6b",
   "metadata": {},
   "source": [
    "### 3. **Ollama**\n",
    "\n",
    "- LangChain에서 로컬 실행에 최적화된 경량 임베딩 모델\n",
    "\n",
    "- 주요 특징:\n",
    "    1. 완전한 로컬 실행 환경 제공\n",
    "    2. 빠른 추론 속도\n",
    "    3. 간단한 설치 및 실행 과정\n",
    "    4. Docker 기반 손쉬운 배포\n",
    "\n",
    "- 사용시 주의사항:\n",
    "    1. Ollama 서버 실행 필요\n",
    "    2. 모델별 시스템 요구사항 확인\n",
    "    3. API 엔드포인트 설정 필요\n",
    "    4. 동시 요청 처리량 고려\n",
    "\n",
    "- 대표적인 임베딩 모델:\n",
    "    ```\n",
    "    모델                차원       언어        특징\n",
    "    llama2              4096      영어       범용성 높은 기본 모델\n",
    "    nomic-embed-text    768       영어       경량화된 고성능 모델\n",
    "    codellama          2048       다국어     코드 특화 임베딩\n",
    "    ```\n",
    "\n",
    "- 임베딩 벡터 특성:\n",
    "    1. 모델별 고정 차원 사용\n",
    "    2. 최적화된 양자화 지원\n",
    "    3. 배치 처리 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b36e5a",
   "metadata": {},
   "source": [
    "`(1) embedding 모델`\n",
    "\n",
    "- langchain_ollama 설치 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings \n",
    "\n",
    "# OllamaEmbeddings 모델 생성\n",
    "# embeddings_ollama = OllamaEmbeddings(\n",
    "#     model=\"nomic-embed-text\",          # 사용할 모델 이름\n",
    "#     base_url=\"http://localhost:11434\"  # Ollama 서버 주소\n",
    "# )\n",
    "embeddings_ollama = OllamaEmbeddings(model=\"bge-m3\")\n",
    "\n",
    "# 임베딩 객체 출력\n",
    "embeddings_ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b54cb",
   "metadata": {},
   "source": [
    "`(2) embed_documents 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 컬렉션\n",
    "documents = [\n",
    "    \"인공지능은 컴퓨터 과학의 한 분야입니다.\",\n",
    "    \"머신러닝은 인공지능의 하위 분야입니다.\",\n",
    "    \"딥러닝은 머신러닝의 한 종류입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.\",\n",
    "    \"컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 방법을 연구합니다.\"\n",
    "]\n",
    "\n",
    "# 문서 임베딩\n",
    "document_embeddings_ollama = embeddings_ollama.embed_documents(documents)\n",
    "\n",
    "# 임베딩 결과 출력\n",
    "print(f\"임베딩 벡터의 개수: {len(document_embeddings_ollama)}\")\n",
    "print(f\"임베딩 벡터의 차원: {len(document_embeddings_ollama[0])}\")\n",
    "print(document_embeddings_ollama[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e637cb4",
   "metadata": {},
   "source": [
    "`(3) embed_query 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54504e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_query = embeddings_ollama.embed_query(\"인공지능이란 무엇인가요?\")\n",
    "\n",
    "# 쿼리 임베딩 결과 출력\n",
    "print(f\"쿼리 임베딩 벡터의 차원: {len(embedded_query)}\")\n",
    "print(embedded_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88021a49",
   "metadata": {},
   "source": [
    "`(4) 유사도 기반 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a671a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 쿼리\n",
    "queries = [\n",
    "    \"인공지능이란 무엇인가요?\",\n",
    "    \"딥러닝과 머신러닝의 관계는 어떻게 되나요?\",\n",
    "    \"컴퓨터가 이미지를 이해하는 방법은?\"\n",
    "]\n",
    "\n",
    "# 각 쿼리에 대해 가장 유사한 문서 찾기\n",
    "for query in queries:\n",
    "    most_similar_doc, similarity = find_most_similar(query, document_embeddings_ollama, embeddings_model=embeddings_ollama) \n",
    "    print(f\"쿼리: {query}\")\n",
    "    print(f\"가장 유사한 문서: {most_similar_doc}\")\n",
    "    print(f\"유사도: {similarity:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8edee46",
   "metadata": {},
   "source": [
    "# 벡터 저장소 (Vector Store)\n",
    "\n",
    "- 개념:\n",
    "    - 벡터화된 데이터를 효율적으로 저장하고 검색하기 위한 특수 데이터베이스 시스템\n",
    "    - 텍스트나 이미지 등의 비정형 데이터를 고차원 벡터 공간에 매핑하여 저장\n",
    "    - 유사도 기반 검색을 통해 의미적으로 가까운 데이터를 빠르게 검색 가능 \n",
    "\n",
    "- LangChain의 벡터 저장소 종류:\n",
    "    - **Chroma**: 경량화된 임베딩 데이터베이스로 로컬 개발에 적합\n",
    "    - **FAISS**: Facebook AI가 개발한 고성능 유사도 검색 라이브러리\n",
    "    - **Pinecone**: 완전 관리형 벡터 데이터베이스 서비스\n",
    "    - Milvus: 분산 벡터 데이터베이스로 대규모 데이터 처리에 적합\n",
    "    - PostgreSQL: pgvector 확장을 통해 벡터 저장 및 검색 기능을 제공\n",
    "\n",
    "- 주요 기능:\n",
    "    - 벡터 색인화: 효율적인 검색을 위한 데이터 구조화를 수행\n",
    "    - 근접 이웃 검색: 주어진 쿼리와 가장 유사한 벡터들을 검색 \n",
    "    - 메타데이터 관리: 벡터와 관련된 부가 정보를 함께 저장하고 검색\n",
    "\n",
    "- 사용 사례:\n",
    "    - 시맨틱 문서 검색: 문서의 의미를 이해하여 검색\n",
    "    - 추천 시스템: 유사한 아이템을 추천\n",
    "    - 중복 데이터 감지: 유사한 콘텐츠를 검색 \n",
    "    - 질의응답 시스템: 관련 문서에서 답변을 생성하는데 필요한 근거를 검색 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8fed68",
   "metadata": {},
   "source": [
    "### **Chroma**\n",
    "\n",
    "- 사용자 편의성이 우수한 오픈소스 벡터 저장소\n",
    "- `langchain-chroma` 패키지 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7da6e",
   "metadata": {},
   "source": [
    "`(1) 벡터 저장소 초기화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 로더 초기화 (근로기준법 문서)\n",
    "pdf_loader = PyPDFLoader('./data/labor_law.pdf')\n",
    "\n",
    "# 동기 로딩\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')\n",
    "\n",
    "len(pdf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc0d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# TikToken 인코더를 사용하여 재귀적 텍스트 분할기 초기화 (토큰 수 기준 분할)\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", \n",
    "    chunk_size=500, \n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "# split_documents() 메서드 사용 : Document 객체를 여러 개의 작은 청크 문서로 분할\n",
    "chunks = text_splitter.split_documents(pdf_docs) \n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")\n",
    "\n",
    "# 각 청크의 시작 부분과 끝 부분 확인\n",
    "for chunk in chunks[:5]:\n",
    "    print(f\"{chunk.page_content[:100]}...{chunk.page_content[-100:]}\")\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 생성\n",
    "embeddings_openai = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",  # 사용할 모델 이름)\n",
    ")\n",
    "\n",
    "# Chroma 벡터 저장소 생성하기\n",
    "chroma_db = Chroma.from_documents(  \n",
    "    documents=chunks,\n",
    "    embedding=embeddings_openai,    # OpenAI 임베딩 사용\n",
    "    collection_name=\"labor_law\",    # 컬렉션 이름\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_metadata = {'hnsw:space': 'cosine'}, # l2, ip, cosine 중에서 선택 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa705465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 개수 확인\n",
    "chroma_db._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368e198",
   "metadata": {},
   "source": [
    "`(2) 벡터 저장소 로드`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 저장된 벡터 저장소를 가져오기\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"labor_law\",\n",
    "    embedding_function=embeddings_openai,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 개수 확인\n",
    "chroma_db._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aefca3",
   "metadata": {},
   "source": [
    "`(3) 문서 검색`  \n",
    "- 유사도 검색\n",
    "    - 주어진 쿼리와 가장 유사한 문서를 반환\n",
    "    -  k=5는 상위 5개의 결과를 반환하도록 지정\n",
    "    - filter를 사용하여 특정 출처의 문서만 검색 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c36347",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"'탄력 근로에 대해서 설명해주세요\"\n",
    "results = chroma_db.similarity_search(\n",
    "    query,\n",
    "    k=5,\n",
    "    filter={\"source\": \"./data/labor_law.pdf\"}\n",
    ")\n",
    "\n",
    "print(\"유사도 검색 결과:\")\n",
    "for doc in results:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cfc931",
   "metadata": {},
   "source": [
    "- 유사도 점수가 포함된 검색\n",
    "    - 유사도 점수를 함께 반환\n",
    "    - 점수가 낮을수록 더 유사한 것을 의미 (거리 기준으로 점수가 산정되기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f05840",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"'탄력 근로에 대해서 설명해주세요\"\n",
    "results = chroma_db.similarity_search_with_score(\n",
    "    query,\n",
    "    k=5,\n",
    ")\n",
    "\n",
    "print(\"점수가 포함된 유사도 검색 결과:\\n\")\n",
    "for doc, score in results:\n",
    "    print(f\"- 점수: {score:.4f}\")\n",
    "    print(f\"  내용: {doc.page_content}\")\n",
    "    print(f\" 메타데이터: {doc.metadata}\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1114cf",
   "metadata": {},
   "source": [
    "# 벡터 저장소 기반 RAG 검색기 (Retriever)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd1b80",
   "metadata": {},
   "source": [
    "`(1) Top K`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978859b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 2},\n",
    ")\n",
    "\n",
    "query = \"탄력 근로에 대해서 설명해주세요\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"-{i}-\\n{doc.page_content}\\n[출처: {doc.metadata['source']}]\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ee428",
   "metadata": {},
   "source": [
    "`(2) 임계값 지정`\n",
    "- Similarity score threshold (기준 스코어 이상인 문서를 대상으로 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8987f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type='similarity_score_threshold',       # cosine 유사도\n",
    "    search_kwargs={'score_threshold': 0.3, 'k':5},  # 0.3 이상인 문서를 추출\n",
    ")\n",
    "\n",
    "query = \"탄력 근로에 대해서 설명해주세요\"\n",
    "\n",
    "# 쿼리와 유사한 문서 검색\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    score = cosine_similarity(\n",
    "        [embeddings_openai.embed_query(query)], \n",
    "        [embeddings_openai.embed_query(doc.page_content)]\n",
    "        )[0][0]\n",
    "    print(f\"-{i}-\\n{doc.page_content}\\n[유사도: {score}]\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d4655",
   "metadata": {},
   "source": [
    "`(3) MMR(Maximal Marginal Relevance) 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ccc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMR - 다양성 고려 (lambda_mult 작을수록 더 다양하게 추출)\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={\n",
    "        'k': 3,                 # 검색할 문서의 수\n",
    "        'fetch_k': 8,           # mmr 알고리즘에 전달할 문서의 수 (fetch_k > k)\n",
    "        'lambda_mult': 0.5,     # 다양성을 고려하는 정도 (1은 최소 다양성, 0은 최대 다양성을 의미. 기본값은 0.5)\n",
    "        },\n",
    ")\n",
    "\n",
    "\n",
    "query = \"탄력 근로에 대해서 설명해주세요\"\n",
    "\n",
    "# 쿼리와 유사한 문서 검색\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    score = cosine_similarity(\n",
    "        [embeddings_openai.embed_query(query)], \n",
    "        [embeddings_openai.embed_query(doc.page_content)]\n",
    "        )[0][0]\n",
    "    print(f\"-{i}-\\n{doc.page_content}\\n[유사도: {score}]\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc95823",
   "metadata": {},
   "source": [
    "# Naive RAG 구현 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d70691e",
   "metadata": {},
   "source": [
    "`(1) 벡터 저장소 로드`\n",
    "- `Chroma` 벡터 저장소를 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b684474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 생성\n",
    "embeddings_openai = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",  # 사용할 모델 이름\n",
    "    )\n",
    "\n",
    "# 저장된 벡터 저장소를 가져오기\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"labor_law\",\n",
    "    embedding_function=embeddings_openai,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "# 문서 개수 확인\n",
    "print(f\"저장된 문서 수: {chroma_db._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b2f7d",
   "metadata": {},
   "source": [
    "`(2) 검색기(Retriever) 초기화`\n",
    "\n",
    "- mmr 검색을 사용하는 Retriever 사용\n",
    "- 다양성을 높이는 설정을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmr 검색기 생성\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={\n",
    "        'k': 5,                  # 검색할 문서의 수\n",
    "        'fetch_k': 10,           # mmr 알고리즘에 전달할 문서의 수 (fetch_k > k)\n",
    "        'lambda_mult': 0.3,      # 다양성을 고려하는 정도 (1은 최소 다양성, 0은 최대 다양성을 의미. 기본값은 0.5)\n",
    "        },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36743877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 테스트 \n",
    "query = \"탄력 근로에 대해서 설명해주세요\"\n",
    "\n",
    "# 쿼리와 유사한 문서 검색\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"-{i}-\\n{doc.page_content}\\n[출처: {doc.metadata['source']}]\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024d5d9",
   "metadata": {},
   "source": [
    "`(3) RAG 프롬프트 구성`\n",
    "\n",
    "- 작성 기준: \n",
    "    - LangChain의 ChatPromptTemplate 클래스 사용\n",
    "    - 변수 처리는 {context}, {question} 형식 사용\n",
    "    - 답변은 한글로 출력되도록 프롬프트 작성\n",
    "    \n",
    "- 아래 템플릿 코드를 기반으로 다음 내용을 참고하여 작성합니다. \n",
    "\n",
    "    1. 프롬프트 구성요소:\n",
    "        - 작업 지침\n",
    "        - 컨텍스트 영역\n",
    "        - 질문 영역\n",
    "        - 답변 형식 가이드\n",
    "\n",
    "    2. 작업 지침:\n",
    "        - 컨텍스트 기반 답변 원칙\n",
    "        - 외부 지식 사용 제한\n",
    "        - 불확실성 처리 방법\n",
    "        - 답변 불가능한 경우의 처리 방법\n",
    "\n",
    "    3. 답변 형식:\n",
    "        - 핵심 답변 섹션\n",
    "        - 근거 제시 섹션\n",
    "        - 추가 설명 섹션 (필요시)\n",
    "\n",
    "    4. 제약사항 반영:\n",
    "        - 답변은 사실에 기반해야 함\n",
    "        - 추측이나 가정을 최소화해야 함\n",
    "        - 명확한 근거 제시가 필요함\n",
    "        - 구조화된 형태로 작성되어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 템플릿 (기본 예시)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context.\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\n",
    "[Question] \n",
    "{question}\n",
    "\n",
    "[Answer]\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 템플릿 출력\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 템플릿 (커스텀 예시)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"주어진 컨텍스트를 기반으로 질문에 답변하시오.\n",
    "\n",
    "[지침]\n",
    "- 컨텍스트에 있는 정보만을 사용하여 답변할 것\n",
    "- 외부 지식이나 정보를 사용하지 말 것\n",
    "- 컨텍스트에서 답을 찾을 수 없는 경우 \"주어진 정보만으로는 답변하기 어렵습니다.\"라고 응답할 것\n",
    "- 불확실한 경우 명확히 그 불확실성을 표현할 것\n",
    "- 답변은 논리적이고 구조화된 형태로 제공할 것\n",
    "- 답변은 한국어를 사용할 것 \n",
    "\n",
    "[컨텍스트]\n",
    "{context}\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[답변 형식]\n",
    "1. 핵심 답변: (질문에 대한 직접적인 답변)\n",
    "2. 근거: (컨텍스트에서 발견된 관련 정보)\n",
    "3. 추가 설명: (필요한 경우 부연 설명 제공)\n",
    "\n",
    "[답변]\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 템플릿 출력\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f5cf5",
   "metadata": {},
   "source": [
    "`(4) RAG 체인 구성`\n",
    "- LangChain의 LCEL 문법을 사용\n",
    "- 검색 결과를 프롬프트의 'context'로 전달하고,\n",
    "- 사용자가 입력한 질문을 그래도 프롬프트의 'question'에 전달\n",
    "- LLM 설정:\n",
    "    - ChatOpenAI 사용 ('gpt-4.1-mini' 모델)\n",
    "    - temperature: 답변의 일관성을 가져가는 설정값을 사용 \n",
    "    - 기타 필요한 설정 \n",
    "- 출력 파서: 문자열 부분만 출력되도록 구성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4121f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 설정\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "# 문서 포맷팅\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([f\"{doc.page_content}\" for doc in docs])\n",
    "\n",
    "# RAG 체인 생성\n",
    "rag_chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": retriever | format_docs, \n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 체인 실행\n",
    "query = \"탄력 근로에 대해서 설명해주세요\"\n",
    "output = rag_chain.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"답변:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a614b56a",
   "metadata": {},
   "source": [
    "![LangServe Screenshot](https://raw.githubusercontent.com/tsdata/image_files/main/202505/rag_screenshot_0001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca2de1",
   "metadata": {},
   "source": [
    "`(5) LangServe 서버 구성`\n",
    "- app/rag.py 파일을 생성하여 RAG 체인과 관련된 코드를 작성함.\n",
    "\n",
    "    ```python\n",
    "    # app/rag.py\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    from langchain_core.runnables import RunnablePassthrough\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    from langchain_chroma import Chroma\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "    # 환경변수 로드\n",
    "    load_dotenv()\n",
    "\n",
    "\n",
    "    ######################\n",
    "    #  RAG 체인 구성\n",
    "    ######################\n",
    "\n",
    "    # OpenAI 임베딩 모델 생성\n",
    "    embeddings_openai = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-small\",  # 사용할 모델 이름\n",
    "        )\n",
    "\n",
    "    # 저장된 벡터 저장소를 가져오기\n",
    "    chroma_db = Chroma(\n",
    "        collection_name=\"labor_law\",\n",
    "        embedding_function=embeddings_openai,\n",
    "        persist_directory=\"./chroma_db\",\n",
    "    )\n",
    "\n",
    "    print(\"Chroma DB loaded\")\n",
    "    print(chroma_db._collection.count())  # 벡터 저장소에 있는 문서 수 출력\n",
    "\n",
    "    # 검색기 초기화å\n",
    "    retriever = chroma_db.as_retriever(\n",
    "        search_type='mmr',\n",
    "        search_kwargs={\n",
    "            'k': 5,                  # 검색할 문서의 수\n",
    "            'fetch_k': 10,           # mmr 알고리즘에 전달할 문서의 수 (fetch_k > k)\n",
    "            'lambda_mult': 0.3,      # 다양성을 고려하는 정도 (1은 최소 다양성, 0은 최대 다양성을 의미. 기본값은 0.5)\n",
    "            },\n",
    "    )\n",
    "\n",
    "    # Prompt 템플릿 생성\n",
    "    template = \"\"\"주어진 컨텍스트를 기반으로 질문에 답변하시오.\n",
    "\n",
    "    [지침]\n",
    "    - 컨텍스트에 있는 정보만을 사용하여 답변할 것\n",
    "    - 외부 지식이나 정보를 사용하지 말 것\n",
    "    - 컨텍스트에서 답을 찾을 수 없는 경우 \"주어진 정보만으로는 답변하기 어렵습니다.\"라고 응답할 것\n",
    "    - 불확실한 경우 명확히 그 불확실성을 표현할 것\n",
    "    - 답변은 논리적이고 구조화된 형태로 제공할 것\n",
    "    - 답변은 한국어를 사용할 것 \n",
    "\n",
    "    [컨텍스트]\n",
    "    {context}\n",
    "\n",
    "    [질문]\n",
    "    {question}\n",
    "\n",
    "    [답변 형식]\n",
    "    1. 핵심 답변: (질문에 대한 직접적인 답변)\n",
    "    2. 근거: (컨텍스트에서 발견된 관련 정보)\n",
    "    3. 추가 설명: (필요한 경우 부연 설명 제공)\n",
    "\n",
    "    [답변]\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # LLM 설정\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    # 문서 포맷팅\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join([f\"{doc.page_content}\" for doc in docs])\n",
    "\n",
    "    # RAG 체인 생성\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    ```\n",
    "\n",
    "\n",
    "- server.py 파일에 새로운 엔드포인트를 추가하여 RAG 체인을 호출하도록 설정함.\n",
    "\n",
    "    ```python\n",
    "    # app/server.py\n",
    "    from fastapi import FastAPI\n",
    "    from dotenv import load_dotenv\n",
    "    from app.rag import rag_chain\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langserve import add_routes\n",
    "\n",
    "    # 환경변수 로드\n",
    "    load_dotenv()\n",
    "\n",
    "    # FastAPI 서버를 설정\n",
    "    app = FastAPI(\n",
    "        title=\"LangChain Server\",\n",
    "        version=\"1.0\",\n",
    "        description=\"Spin up a simple api server using Langchain's Runnable interfaces\",\n",
    "    )\n",
    "\n",
    "    # 라우팅 설정\n",
    "    add_routes(\n",
    "        app,\n",
    "        ChatOpenAI(model=\"gpt-4.1-mini\"),\n",
    "        path=\"/openai\",   # OpenAI 모델에 대한 경로\n",
    "    )\n",
    "\n",
    "    add_routes(\n",
    "        app,\n",
    "        rag_chain,\n",
    "        path=\"/rag\",  # RAG 체인에 대한 경로\n",
    "    )\n",
    "\n",
    "    # FastAPI 서버 실행\n",
    "    if __name__ == \"__main__\":\n",
    "        import uvicorn\n",
    "\n",
    "        uvicorn.run(app, host=\"localhost\", port=8000)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f4f28",
   "metadata": {},
   "source": [
    "![LangServe Screenshot](https://raw.githubusercontent.com/tsdata/image_files/main/202505/rag_screenshot_0002.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

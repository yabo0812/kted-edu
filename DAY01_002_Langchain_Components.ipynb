{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LangChain의 개념과 주요 컴포넌트 이해\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain이란 \n",
    "\n",
    "핵심 내용:\n",
    "- **LangChain**은 LLM 기반 애플리케이션 개발을 위한 프레임워크\n",
    "\n",
    "- **Chain**은 작업을 순차적으로 실행하는 파이프라인 구조를 제공\n",
    "\n",
    "- **Agent**는 자율적 의사결정이 가능한 실행 단위\n",
    "\n",
    "결론:\n",
    "- LangChain은 Chain과 Agent라는 두 가지 핵심 기능을 통해 LLM 애플리케이션 개발을 효율적으로 지원\n",
    "\n",
    "\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"https://python.langchain.com/svg/langchain_stack_112024_dark.svg\" \n",
    "            alt=\"langchain_stack\" \n",
    "            width=\"600\" \n",
    "            style=\"border: 0;\">\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain 컴포넌트 \n",
    "\n",
    "- LangChain **주요 컴포넌트**: LLM/ChatModel, Prompt, Memory, Tool, Document Loader, Text Splitter, Embedding, Vectorstore\n",
    "\n",
    "- **언어 처리 기능**은 LLM/ChatModel이 중심이 되며, Prompt와 Memory로 대화를 관리\n",
    "\n",
    "- **문서 처리와 검색**은 Document Loader, Text Splitter, Embedding, Vectorstore가 담당\n",
    "\n",
    "- **모듈성**이 핵심 특징으로, 독립적인 컴포넌트들을 조합해 RAG와 같은 복잡한 시스템을 구현 가능 \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경 변수 로드\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 모델 (Models)\n",
    "- LLM, ChatModel 등으로 구분\n",
    "- OpenAI, Anthropic, Google 등 다양한 모델을 지원\n",
    "- 텍스트 생성, 대화, 요약 등의 작업을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI 모델을 사용하여 대화 생성\n",
    "model = ChatOpenAI(model=\"gpt-4.1-2025-04-14\")\n",
    "\n",
    "# 모델에 메시지를 보내고 응답을 받기\n",
    "response = model.invoke(\"안녕하세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 무엇을 도와드릴까요? 😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 10, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'id': 'chatcmpl-BlVJ6mjfdsREiPdDKRmf62ObkdYEV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5f30b6e7-67d6-46fb-8c3e-c427948b5b73-0', usage_metadata={'input_tokens': 10, 'output_tokens': 12, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 응답 객체(AIMessage): 메시지(content)와 메타데이터(response_metadata 등)를 포함\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변:  안녕하세요! 무엇을 도와드릴까요? 😊\n"
     ]
    }
   ],
   "source": [
    "# 응답 객체의 메시지 내용 출력\n",
    "print(\"답변: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타데이터:  {'token_usage': {'completion_tokens': 12, 'prompt_tokens': 10, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'id': 'chatcmpl-BlVJ6mjfdsREiPdDKRmf62ObkdYEV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "# 응답 객체의 메타데이터 출력\n",
    "print(\"메타데이터: \", response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 메시지 (Messages)\n",
    "- Chat Model에서 사용할 수 있는 통합된 메시지 형식을 제공\n",
    "- 각 모델 제공자의 특정 메시지 형식을 신경 쓰지 않고도 다양한 채팅 모델을 활용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. HumanMessage`\n",
    "- 사용자 역할에 해당 (user, human 등)\n",
    "- 사용자의 입력을 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변:  \"Glory\"를 한국어로 번역하면 \"영광\"입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 사용자 메시지 생성\n",
    "human_message = HumanMessage(content=\"Glory를 한국어로 번역해주세요.\")\n",
    "\n",
    "# 번역 요청 및 응답 받기\n",
    "response = model.invoke([human_message])  # 메시지 리스트로 전달\n",
    "\n",
    "# 답변 출력\n",
    "print(\"답변: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Glory\"를 한국어로 번역하면 \"영광\"입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 17, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-BlRD9hqjNiA7P9hDzdXhQz2ba7z4V', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e652adee-939b-46aa-887e-1818160e0147-0', usage_metadata={'input_tokens': 17, 'output_tokens': 17, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자열을 입력하면, 자동으로 HumanMessage로 변환하여 요청\n",
    "model.invoke(\"Glory를 한국어로 번역해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. AIMessage`\n",
    "- AI 모델의 응답을 표현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Glory\"를 한국어로 번역하면 \"영광\"입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 17, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-BlRD8SywBQp8sDT1KPLAm14K4eFkJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c50ee79b-df74-4c8d-87fb-0e89a92da7ec-0', usage_metadata={'input_tokens': 17, 'output_tokens': 17, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI 모델의 응답 객체를 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Glory\"를 한국어로 번역하면 \"영광\"입니다.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 응답 텍스트 부분을 출력\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 17,\n",
       " 'output_tokens': 17,\n",
       " 'total_tokens': 34,\n",
       " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       " 'output_token_details': {'audio': 0, 'reasoning': 0}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰 사용량 출력\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. SystemMessage`\n",
    "- 시스템 역할에 해당 (system, developer 등)\n",
    "- AI 모델의 동작과 제약사항을 정의하는데 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='당신은 영어를 한국어로 번역하는 AI 어시스턴트입니다.', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# 시스템 메시지 생성\n",
    "system_msg = SystemMessage(\n",
    "    content=\"당신은 영어를 한국어로 번역하는 AI 어시스턴트입니다.\"\n",
    ")\n",
    "\n",
    "# 메시지 객체 확인\n",
    "system_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변:  \"Glory\"의 한국어 번역은 \"영광\"입니다.\n"
     ]
    }
   ],
   "source": [
    "# 번역 요청 (HumanMessage)과 시스템 메시지(SystemMessage)를 함께 사용\n",
    "human_message = HumanMessage(content=\"Glory\")\n",
    "messages = [system_msg, human_message]\n",
    "\n",
    "# 모델에 메시지를 보내고 응답 받기\n",
    "response = model.invoke(messages)\n",
    "\n",
    "# 답변 출력\n",
    "print(\"답변: \", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 프롬프트 템플릿 (Prompt Template)\n",
    "- 프롬프트 템플릿을 통해 일관된 입력 형식을 제공\n",
    "    1. 사용자의 입력과 파라미터를 언어 모델이 이해할 수 있는 형태로 변환하는 도구\n",
    "    2. 언어 모델에게 전달할 지시문을 만드는 틀\n",
    "- 변수를 포함한 동적 프롬프트 생성이 가능\n",
    "    1. 모든 템플릿은 딕셔너리 형태의 입력을 받아서 처리\n",
    "    2. 출력은 PromptValue 형태로 반환되며, 이는 문자열이나 메시지 리스트로 변환 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. 문자열 프롬프트 템플릿 (String PromptTemplate)`\n",
    "- 가장 기본적인 형태\n",
    "- 단일 문자열을 형식화하는데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='고양이에 대한 이야기를 해줘')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 템플릿 생성\n",
    "# \"{topic}에 대한 이야기를 해줘\"라는 템플릿을 사용하여\n",
    "# topic이라는 변수를 포함하는 프롬프트를 생성\n",
    "template = PromptTemplate.from_template(\"{topic}에 대한 이야기를 해줘\")\n",
    "\n",
    "# 템플릿 사용\n",
    "# \"고양이\"라는 주제를 사용하여 프롬프트 생성\n",
    "# invoke 메서드를 통해 템플릿에 값을 전달\n",
    "prompt = template.invoke({\"topic\": \"고양이\"})\n",
    "\n",
    "# 템플릿 출력\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. 채팅 프롬프트 템플릿 (ChatPromptTemplate)`\n",
    "- 여러 메시지를 포함하는 대화형 템플릿을 만들 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='당신은 도움이 되는 비서입니다', additional_kwargs={}, response_metadata={}), HumanMessage(content='인공지능에 대해 설명해주세요', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 채팅 템플릿 생성\n",
    "# 여기서는 시스템 메시지와 사용자 메시지를 포함하여 정의\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 도움이 되는 비서입니다\"),\n",
    "        (\"user\", \"{subject}에 대해 설명해주세요\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 템플릿 사용\n",
    "prompt = template.invoke({\"subject\": \"인공지능\"})\n",
    "\n",
    "# 출력\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. 메시지 플레이스홀더 (MessagesPlaceholder)`\n",
    "- 기존 메시지 목록을 템플릿의 특정 위치에 삽입할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 도움이 되는 비서입니다', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='안녕하세요! 제 이름은 스티브입니다.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='제 이름을 기억하나요?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 메시지 플레이스홀더가 있는 템플릿\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 도움이 되는 비서입니다\"),\n",
    "        MessagesPlaceholder(\n",
    "            \"chat_history\"\n",
    "        ),  # 채팅 기록을 플레이스홀더로 사용 (예: 이전 대화 내용) -> 이 위치에 메시지 목록을 추가할 수 있음\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 템플릿 사용\n",
    "prompt = template.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"안녕하세요! 제 이름은 스티브입니다.\"),\n",
    "            AIMessage(content=\"안녕하세요! 무엇을 도와드릴까요?\"),\n",
    "            HumanMessage(content=\"제 이름을 기억하나요?\"),\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# 출력\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 출력 파서 (Output Parser)\n",
    "1. **역할과 기능**\n",
    "    - 모델의 텍스트 출력을 구조화된 데이터로 변환\n",
    "    - 채팅 모델과 LLM의 출력을 정규화\n",
    "    - 다운스트림 작업을 위한 데이터 형식 변환\n",
    "\n",
    "2. **사용 시 고려사항**\n",
    "    - OpenAI function calling과 같은 기능이 있는 경우, 해당 기능을 우선 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) StrOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 서울은 대한민국의 수도이자 가장 큰 도시로, 다양한 특징을 가지고 있습니다. 주요 특징을 요약하면 다음과 같습니다:\n",
      "\n",
      "1. **역사와 전통**\n",
      "   - 600년 이상의 역사를 지닌 도시로 조선시대(1392~1910)부터 수도였습니다.\n",
      "   - 경복궁, 창덕궁, 덕수궁 등 유서 깊은 궁궐들이 도심에 남아 있습니다.\n",
      "\n",
      "2. **현대와 첨단**\n",
      "   - 세계적인 규모의 고층 빌딩, 강남, 여의도와 같은 비즈니스 지역, 삼성, SK, 현대 등 글로벌 대기업 본사가 밀집해 있습니다.\n",
      "   - 세계 최고 수준의 인터넷 인프라와 교통 시스템(지하철, 버스)을 자랑합니다.\n",
      "\n",
      "3. **인구와 규모**\n",
      "   - 인구 약 960만 명(2024년 기준)이 거주하는 한국 최대 도시입니다.\n",
      "   - 주변 경기 지역과 함께 ‘수도권’이라 불리며 인구 2천5백만 명이 살아가는 거대한 도시권을 형성합니다.\n",
      "\n",
      "4. **문화와 라이프스타일**\n",
      "   - 한류(K-pop, 드라마, 영화) 문화의 중심지로, 다양한 공연, 미술관, 박물관이 활발히 운영됩니다.\n",
      "   - 전통과 현대가 공존하는 도시로, 인사동, 북촌 한옥마을과 같은 전통 거리와, 홍대, 강남, 이태원 등 현대적이고 트렌디한 지역이 공존합니다.\n",
      "\n",
      "5. **관광명소**\n",
      "   - 남산타워, 한강공원, 동대문디자인플라자(DDP), 롯데월드타워 등 다양한 랜드마크가 있습니다.\n",
      "   - 쇼핑, 미식, 야경 등 다양한 즐길 거리가 풍부합니다.\n",
      "\n",
      "6. **자연과 조경**\n",
      "   - 도심 한가운데를 흐르는 한강과, 북한산, 남산 등 다양한 산과 자연공원이 있어, 시민들이 쉽게 자연을 즐길 수 있습니다.\n",
      "\n",
      "7. **교육, 의료**\n",
      "   - 서울대학교, 연세대학교, 고려대학교 등 명문 대학이 위치해 있고, 의료 시스템도 발달해 있습니다.\n",
      "\n",
      "종합적으로, 서울은 역사와 현대, 전통과 혁신이 조화를 이루는 다채로운 도시로 국제적인 위상을 가진 대도시입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 기본적인 문자열 파서 사용\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate.from_template(\"도시 {city}의 특징을 알려주세요\")\n",
    "\n",
    "# 모델 정의\n",
    "model = ChatOpenAI(model=\"gpt-4.1-2025-04-14\")\n",
    "\n",
    "# 체인 구성\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# 체인 실행\n",
    "result = chain.invoke({\"city\": \"서울\"})\n",
    "\n",
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 구조화된 출력 (with_structured_output 메소드)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "\n",
    "# Pydantic 클래스로 출력 구조를 정의\n",
    "\n",
    "\n",
    "class CityInfo(BaseModel):\n",
    "\n",
    "    name: str = Field(description=\"도시 이름\")\n",
    "\n",
    "    description: str = Field(description=\"도시의 특징\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='미국, 이란 핵시설 공습 정당화하며 협상 의지 재확인' content=\"도널드 트럼프 행정부는 2025년 6월 21일 이란 핵시설에 대한 공습을 이란의 핵무기 개발을 막기 위한 필수 조치로 정당화했다. 미국은 이란의 정권 교체를 원하지 않으며 협상할 준비가 되어 있다고 밝혔다. J.D. 밴스 부통령은 이란과의 전쟁이나 정권 교체를 원하지 않으며, 이란이 핵무기 프로그램을 해체하는 '똑똑한 길'을 선택하길 바란다고 말했다. 피트 헤그세스 국방부 장관은 이번 작전이 제한적이며 전면전이 아니라고 강조했다. 마코 루비오 국무부 장관은 이란이 원한다면 즉시 협상할 준비가 되어 있다고 밝혔다. 한편, 미국 내에서는 이번 공습에 대한 우려와 비판도 존재하며, 트럼프 대통령은 공습을 비판한 공화당 톰 매시 하원의원을 강하게 비난했다.\" names='도널드 트럼프, J.D. 밴스, 피트 헤그세스, 마코 루비오, 톰 매시, 짐 하임스' office='연합뉴스'\n",
      "--------------------\n",
      "미국, 이란 핵시설 공습 정당화하며 협상 의지 재확인\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 1. 출력 스키마 정의\n",
    "class NewsInfo(BaseModel):\n",
    "    title: str = Field(description=\"뉴스 제목\")\n",
    "    content: str = Field(description=\"뉴스 본문\")\n",
    "    names: str = Field(description=\"기자 이름\")\n",
    "    office: str = Field(description=\"신문사\")\n",
    "\n",
    "\n",
    "# 2. 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate.from_template(\"뉴스에서 관련 정보를 추출해주세요 뉴스: {news}\")\n",
    "\n",
    "# 3. 모델 생성 및 구조화된 출력 바인딩\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini-2025-04-14\", temperature=0)\n",
    "structured_model = model.with_structured_output(NewsInfo)\n",
    "\n",
    "# 4. 프롬프트와 모델 체인 연결\n",
    "chain = prompt | structured_model\n",
    "\n",
    "# 5. 체인 실행\n",
    "result = chain.invoke(\n",
    "    {\n",
    "        \"news\": \"연합뉴스 구독중PICK 안내\\\n",
    "[美 이란 공격] 美정부 '이란, 진정성 보이지않아 타격…내일이라도 협상준비돼'\\\n",
    "입력2025.06.23. 오전 4:36  수정2025.06.23. 오전 4:37 기사원문\\\n",
    "김동현 기자\\\n",
    "여론전 속 '전쟁 수렁' 우려 차단…'이란의 정권교체나 전면전 원하지 않아'\\\n",
    "'美의 억제력 회복, 전세계에 보여줬다…미국이 말할 때 세계는 귀 기울여야'\\\n",
    "트럼프, 공습 비판한 공화당 매시 하원 의원 맹비난…'한심한 패배자'\\\n",
    "이란 공습 담화하는 트럼프 미국 대통령\\\n",
    "(워싱턴 AP=연합뉴스) 도널드 트럼프 미국 대통령이 2025년 6월 21일(현지시간) 백악관에서 미군의 이란 핵시설 공습과 관련해 대국민 담화를 하고 있다. 트럼프 대통령 뒤로 왼쪽부터 J.D. 밴스 부통령, 마코 루비오 국무부 장관, 피트 헤그세스 국방부 장관이 서 있다. 2025.6.22\\\n",
    "(워싱턴=연합뉴스) 김동현 특파원 = 미국 도널드 트럼프 행정부는 22일(현지시간) 이란 핵시설을 겨냥한 전날의 공습은 이란의 핵무기 개발을 막는 데 필요했다면서 그 당위성을 주장했다.\\\n",
    "또 미국은 이란의 정권 교체를 원하지 않고 협상할 의지가 있다는 입장을 재차 강조하면서 미국이 과거 이라크와 아프가니스탄 같은 중동 전쟁의 수렁에 빠질 수 있다는 국내 우려를 차단하려고 노력했다.\\\n",
    "J.D. 밴스 부통령은 이날 ABC뉴스 인터뷰에서 이란과의 전쟁이나 이란의 정권 교체를 원하는 게 아니라면서 '우리는 이란의 핵 프로그램과 전쟁하고 있다'고 규정했다.\\\n",
    "그는 이란이 핵무기 프로그램을 해체하는 '똑똑한 길'을 선택하기를 바란다면서 '만약 이란이 우리 장병들을 공격하거나 핵무기를 만들려고 계속 시도하기로 결정한다면 우리는 압도적인 무력으로 대응할 것'이라고 경고했다.\\\n",
    "그는 미국이 중동에서 또 다른 장기 분쟁에 휘말릴 수 있다는 우려에 대해서는 '우리는 이란의 핵 프로그램을 파괴하기 위해 매우 좁고 제한적인 접근을 택했다'면서 '대통령은 그 누구보다 더 군사 분쟁의 장기화를 걱정하고 있다'고 설명했다.\\\n",
    "이란 공습 당시 백악관 상황실에 있는 트럼프 미국 대통령\\\n",
    "[AP 연합뉴스 자료사진. 재판매 및 DB 금지]\\\n",
    "피트 헤그세스 국방부 장관도 이날 브리핑에서 '이란 병력이나 이란 국민을 겨냥하지 않았다'면서 이번 작전이 전면전이 아니라 이란의 핵시설만을 겨냥한 제한적인 공습이라고 강조했다.\\\n",
    "헤그세스 장관은 '공개 및 비공개 메시지를 여러 채널을 통해 이란에 직접 전달하면서 이란이 (대화) 테이블로 올 모든 기회를 주고 있다. 이란은 미국의 입장과 평화를 허용하기 위해 그들이 구체적으로 어떤 조치를 해야 하는지 정확히 알고 있으며 우리는 이란이 그렇게 하기를 바란다'고 말했다.\\\n",
    "마코 루비오 국무부 장관은 이날 폭스뉴스 인터뷰에서 이란의 정권 교체가 목적이 아니라고 설명하고서 미국은 이란이 원하면 내일이라도 바로 협상할 준비가 됐다고 밝혔다.\\\n",
    "다만 그는 '이란이 계속해서 핵무기 보유국이 되고자 한다면 난 그게 정권을 위태롭게 할 것이라 정말로 생각한다'고 말해 어떤 경우에도 이란의 핵무기 개발을 허용할 수 없다는 입장을 분명히 했다.\\\n",
    "루비오 장관은 이란이 그간 미국과의 협상에서 '트럼프 대통령을 가지고 놀려고 했다'면서 이란이 핵무기를 포기하겠다는 진정성을 보이지 않아 핵시설을 타격할 수밖에 없었다고 설명했다.\\\n",
    "트럼프 행정부 고위당국자들은 이번 공습을 통해 이란뿐만 아니라 미국의 다른 적들에게도 미국을 거스르지 말라는 경고 메시지를 전하고자 한다는 점을 분명히 했다.\\\n",
    "헤그세스 장관은 '미국의 억제력을 되찾았다는 것을 세계에 보여줬다'면서 '이 대통령이 말할 때 세계는 귀 기울여야 한다'고 주문했다.\\\n",
    "루비오 장관은 이란처럼 행동해서는 안 된다는 사실을 세계가 깨달았을 것이라며 '트럼프 대통령은 자기가 무엇을 할 것인지 말해주고 실제로 하는 대통령이며 그런 점이 이란 정권을 포함한 많은 사람에게 충격적이라고 생각한다'고 말했다.\\\n",
    "미국 공화당의 매시 하원의원\\\n",
    "[AFP 연합뉴스 자료사진. 재판매 및 DB 금지]\\\n",
    "이런 가운데 정치권에서는 미국이 이란과 매우 비싸고 긴 전쟁을 치르게 될 수 있다는 우려가 민주당과 공화당 일각에서 계속 제기되고 있다.\\\n",
    "하원 정보위원회의 민주당 간사인 짐 하임스 하원의원은 ABC 인터뷰에서 '대통령이 엄청난 도박을 했다'며 '중동 지역에서 우리가 군사적으로 개입한 역사를 보면 최상의 시나리오대로 끝나는 적이 거의 절대 없다. 실제로는 보통 최악의 시나리오에 가까운 것으로 끝난다'고 말했다.\\\n",
    "공화당 내에서 이례적으로 이번 공습을 비판한 톰 매시 하원의원은 CBS뉴스 인터뷰에서 트럼프 대통령이 미국을 우선하겠다고 약속했지만 미국을 직접적으로 위협하지 않는 이란과 싸우고 있다면서 '우리는 이 모든 전쟁 때문에 지쳤다'고 밝혔다.\\\n",
    "매시 의원은 지난 17일 민주당 의원들과 함께 트럼프 대통령이 이란을 공격하기 전 의회의 승인을 받도록 하는 '전쟁 권한 결의안'을 발의했으며 대통령이 단독으로 결정한 이번 공습을 위헌이라고 비판한 바 있다.\\\n",
    "트럼프 대통령은 이날 사회관계망서비스(SNS) 트루스소셜에 장문의 글을 올려 매시 의원을 맹비난했다.\\\n",
    "트럼프 대통령은 '그는 자기가 마가(MAGA·트럼프 핵심 지지층)라고 말하기를 좋아하지만, 마가가 아니다. 실제로 마가는 그를 원하지 않고 그를 모르며 그를 존중하지 않는다'면서 '마가는 이 한심한 패배자인 톰 매시를 역병처럼 멀리해야 한다'고 적었다.\\\n",
    "이어 '매시는 약하고 무능하며 어떤 게 아무리 좋다고 해도 자기 앞에 놓인 사실상 모든 것에 '아니요'라고 투표한다. 그는 우리의 위대한 군대와 군대가 상징하는 모든 것에 무례하며, 심지어 우리 군대가 완전하고 전적으로 승리한 어제의 공격에서 보여준 탁월함과 용맹도 인정하지 않는다'고 비판했다.\\\n",
    "bluekey@yna.co.kr\\\n",
    "김동현(bluekey@yna.co.kr)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 6. 결과 출력 (CityInfo 객체)\n",
    "print(result)\n",
    "print(\"-\" * 20)\n",
    "print(result.title)\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 메모리 (Memory)\n",
    "- 대화 기록을 저장하고 관리\n",
    "- 컨텍스트 유지를 위한 다양한 메모리 타입을 제공\n",
    "- 대화 요약, 버퍼링 등의 기능을 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# 메모리 기반 히스토리 구현\n",
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    \"\"\"메모리 기반 채팅 메시지 히스토리\"\"\"\n",
    "\n",
    "    # 메시지 목록\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "\n",
    "    # 메시지 추가\n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        self.messages.extend(messages)\n",
    "\n",
    "    # 메시지 목록 초기화\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "\n",
    "\n",
    "# 세션 저장소\n",
    "store = {}\n",
    "\n",
    "\n",
    "# 세션 ID로 히스토리 가져오기\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    \"\"\"세션 ID에 해당하는 채팅 메시지 히스토리를 반환합니다.\"\"\"\n",
    "\n",
    "    # 세션 ID가 저장소에 없으면 새 InMemoryHistory 객체 생성\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "\n",
    "    # 해당 세션 ID의 히스토리 반환\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채팅 모델과 프롬프트 설정\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 {subject}에 능숙한 비서입니다\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | ChatOpenAI(model=\"gpt-4.1-mini-2025-04-14\")\n",
    "\n",
    "# 히스토리 관리 추가\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,  # 실행 체인\n",
    "    get_session_history,  # 세션 ID에 해당하는 히스토리 가져오는 함수\n",
    "    input_messages_key=\"question\",  # 입력 메시지 키\n",
    "    history_messages_key=\"history\",  # 히스토리 메시지 키\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1+2는 3입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 31, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlSlciZmKyvncDv1OnTLcP7sPk7rr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--6a45ba24-1821-42c9-a90c-876e65127bf6-0' usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행\n",
    "response = chain_with_history.invoke(\n",
    "    {\"subject\": \"수학\", \"question\": \"1+2는 얼마인가요?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}},\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='1+2는 얼마인가요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='1+2는 3입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 31, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlSlciZmKyvncDv1OnTLcP7sPk7rr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6a45ba24-1821-42c9-a90c-876e65127bf6-0', usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세션 ID로 히스토리 가져오기\n",
    "get_session_history(\"user1\").messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1+2는 3이고, 여기에 숫자 2를 곱하면 3 × 2 = 6입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 61, 'total_tokens': 89, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlSm0BXvyXJSIfZx8RGF3kPzarWeo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--c6d1cd6f-71e6-4157-be09-03662cb84785-0' usage_metadata={'input_tokens': 61, 'output_tokens': 28, 'total_tokens': 89, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 히스토리 이용해서 대화 진행\n",
    "response = chain_with_history.invoke(\n",
    "    {\"subject\": \"수학\", \"question\": \"여기에 숫자 2를 곱하면 얼마인가요?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}},\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='1+2는 얼마인가요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='1+2는 3입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 31, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlSlciZmKyvncDv1OnTLcP7sPk7rr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6a45ba24-1821-42c9-a90c-876e65127bf6-0', usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='여기에 숫자 2를 곱하면 얼마인가요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='1+2는 3이고, 여기에 숫자 2를 곱하면 3 × 2 = 6입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 61, 'total_tokens': 89, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlSm0BXvyXJSIfZx8RGF3kPzarWeo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c6d1cd6f-71e6-4157-be09-03662cb84785-0', usage_metadata={'input_tokens': 61, 'output_tokens': 28, 'total_tokens': 89, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세션 ID로 히스토리 가져오기\n",
    "get_session_history(\"user1\").messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 에이전트 (Agent)\n",
    "- 자율적 의사결정이 가능한 실행 단위\n",
    "- LangChain에서는 Agent 클래스를 통해 에이전트 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# 프롬프트 템플릿 생성 - ReAct 에이전트에 필요한 변수들 포함\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 친절한 수학 선생님입니다.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"agent_scratchpad\"\n",
    "        ),  # 에이전트가 도구 호출 결과를 기록할 플레이스홀더\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 도구 정의\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"두 숫자를 더하는 도구\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def subtract(a: float, b: float) -> float:\n",
    "    \"\"\"두 숫자를 빼는 도구\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "# 도구 목록 생성\n",
    "tools = [add, subtract]\n",
    "\n",
    "# 에이전트 생성 (도구 호출)\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=ChatOpenAI(model=\"gpt-4.1-mini\"), tools=tools, prompt=prompt\n",
    ")\n",
    "\n",
    "# 에이전트 실행 도구 정의\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,  # 도구 호출 에이전트\n",
    "    tools=tools,  # 도구 목록\n",
    "    verbose=True,  # 상세 로그 출력\n",
    ")\n",
    "\n",
    "# 에이전트 실행\n",
    "agent_executor.invoke({\"input\": \"100과 200을 더하면 얼마인가요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## [실습]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 다음 조건을 만족하는 새로운 ChatPromptTemplate을 만드세요.\n",
    "   - 시스템 메시지: \"당신은 친절한 과학 선생님입니다\"\n",
    "   - 대화 기록을 포함\n",
    "   - 사용자 질문을 받을 수 있는 형식\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. StrOutputParser를 사용하여 다음을 구현해보세요.\n",
    "   - 앞의 프롬프트 템플릿을 사용하여 체인 구성 및 실행\n",
    "   - \"섭씨온도와 화씨온도 관계\"를 설명해 달라고 요청하는 프롬프트 작성 \n",
    "   - 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 성능 평가\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing 설정`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
    "import os\n",
    "\n",
    "print(os.getenv(\"LANGSMITH_TRACING\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## RAG 시스템 성능 평가\n",
    "\n",
    "- **RAG 기술의 핵심**: 외부 지식 검색과 LLM 결합으로 응답 품질 향상\n",
    "\n",
    "- **평가 기준**: LLM-as-judge 방식으로 사실성, 관련성, 충실도, 유용성 평가\n",
    "\n",
    "- **체계적인 A/B 테스트**: 각 컴포넌트별 성능 비교 및 영향도 분석으로 최적 구성 도출\n",
    "\n",
    "- **평가 방법론**: 오프라인(참조답변 기반), 온라인(실시간), 페어와이즈(비교) 평가 구분\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/tsdata/image_files/main/202505/rag_evaluation.png\" alt=\"rag\" align=\"center\" border=\"0\"  width=\"1000\" height=auto>\n",
    "</center>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **평가 대상(Evaluation Target)**\n",
    "\n",
    "- **검색(Retrieval)** 단계:\n",
    "\n",
    "  1. 관련 문서와 쿼리 간의 연관성(Relevance)을 통해 검색된 문서가 쿼리의 정보 요구를 얼마나 잘 충족하는지 평가\n",
    "  1. 관련 문서와 후보 문서 간의 정확성(Accuracy)을 통해 시스템이 적절한 문서를 식별하는 능력을 측정\n",
    "\n",
    "- **생성(Generation)** 단계:\n",
    "\n",
    "  1. 응답과 쿼리의 연관성(Relavance)\n",
    "  1. 응답과 관련 문서 간의 충실도(Faithfulness)\n",
    "  1. 응답과 샘플 응답 간의 정확성(Correctness)\n",
    "\n",
    "- 추가 고려사항:\n",
    "  - **핵심 성능 지표**: Latency(응답 속도), Diversity(검색 다양성), Noise Robustness(잡음 내구성)\n",
    "  - **안전성 평가**: Negative Rejection(불충분 정보 거부), Counterfactual Robustness(오정보 식별)\n",
    "  - **사용자 경험**: Readability(가독성), Toxicity(유해성), Perplexity(복잡성) 등 추가 고려\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/tsdata/image_files/main/202505/rag_evaluation_target.png\"  alt=\"rag\" align=\"center\" border=\"0\"  width=\"800\" height=auto>\n",
    "</center>\n",
    "\n",
    "[출처] https://arxiv.org/abs/2405.07437\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **평가 데이터셋 구축(Evaluation Dataset)**\n",
    "\n",
    "- **데이터셋 구성 방식**: LLM 기반 새로운 데이터셋 생성 (Synthetic Data)\n",
    "\n",
    "- **맞춤형 데이터셋** 구축으로 RAG 시스템의 실용성 평가 강화\n",
    "\n",
    "- [실습] : **Ragas** (https://docs.ragas.io/en/stable/) 활용\n",
    "\n",
    "  - **RAG 시스템 평가**를 위한 오픈소스 프레임워크\n",
    "  - **주요 지표**: Faithfulness, Answer Relevancy, Context Relevancy 등 평가\n",
    "  - **실용성**: 자동화된 평가 파이프라인 구축 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) LangChain 문서 준비`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean data:\n",
      "[Document(metadata={'source': '../data\\\\리비안_KR.md'}, page_content='Rivian Automotive, Inc.는 2009년에 설립된 미국의 전기 자동차 제조업체, 자동차 기술 및 야외 레크리에이션 회사입니다.\\n\\n**주요 정보:**\\n\\n- **회사 유형:** 상장\\n- **거래소:** NASDAQ: RIVN\\n- **설립:** 2009년 6월, 플로리다 주 록ledge\\n- **설립자:** R. J. 스캐린지\\n- **본사:** 미국 캘리포니아 주 어바인\\n- **서비스 지역:** 북미\\n- **주요 인물:** R. J. 스캐린지 (CEO)\\n- **제품:** 전기 자동차, 배터리\\n- **생산량 (2023):** 57,232대\\n- **서비스:** 전기 자동차 충전, 자동차 보험\\n- **수익 (2023):** 44억 3천만 미국 달러\\n- **순이익 (2023):** -54억 미국 달러\\n- **총 자산 (2023):** 168억 미국 달러\\n- **총 자본 (2023):** 91억 4천만 미국 달러\\n- **직원 수 (2023년 12월):** 16,790명\\n- **웹사이트:** rivian.com\\n\\n**개요**\\n\\nRivian은 \"스케이트보드\" 플랫폼(R1T 및 R1S 모델)을 기반으로 한 전기 스포츠 유틸리티 차량(SUV), 픽업 트럭 및 전기 배달 밴(Rivian EDV)을 생산합니다. R1T 배송은 2021년 말에 시작되었습니다. 회사는 2022년에 미국에서 충전 네트워크를 시작하여 2024년에 다른 차량에도 개방했습니다. 생산 공장은 일리노이 주 노멀에 있으며, 다른 시설은 미국, 캐나다, 영국 및 세르비아의 여러 주에 있습니다.\\n\\n**역사**\\n\\n**초창기 (2009–15):**\\n\\n- 2009년 R. J. 스캐린지가 Mainstream Motors로 설립.\\n- 2011년 Rivian Automotive로 사명 변경.\\n- 처음에는 스포츠카 프로토타입(R1)에 집중했지만 전기 및 자율 주행 차량으로 전환.\\n\\n**생산 준비 (2016–20):**\\n\\n- 2017년 일리노이 주 노멀에 있는 이전 Mitsubishi Motors 제조 공장을 1,600만 달러에 인수.\\n- 2017년 12월, 첫 두 제품인 R1T (픽업 트럭)와 R1S (SUV)를 공개.\\n- 생산은 2020년에 시작될 예정.\\n\\n**첫 모델 배송; IPO; 감원 및 확장 (2021–24):**\\n\\n- R1T 배송은 2021년 9월에 시작되어 Rivian은 완전 전기 픽업을 소비자 시장에 출시한 최초의 자동차 제조업체가 됨.\\n- 2021년 11월, Rivian은 IPO를 통해 135억 달러를 조달하여 상장 회사가 됨.\\n- Ford와 Rivian은 전기 자동차 공동 개발 계획을 취소.\\n- 2022년 3월, Rivian은 부품 비용으로 인해 R1T 및 R1S의 가격 인상을 발표했으며, 이후 소급 적용에 대해 사과.\\n- 2022년 7월, Rivian은 6%의 인력 감축을 발표.\\n- 2022년 9월, 유럽에서 전기 밴을 생산하기 위해 Mercedes-Benz Group과 합작 투자를 발표했지만 나중에 취소됨.\\n- 2022년 10월, 느슨한 토크 볼트로 인해 13,000대의 차량을 자발적으로 리콜.\\n- 2023년 6월, Tesla의 북미 충전 시스템(NACS) 채택을 발표.\\n- 2023년 6월, \"A Better Route Planner\"(ABRP) EV 경로 계획 앱을 개발한 Iternio 인수.\\n- 2023년 10월, Amazon과의 독점 계약을 종료하여 Rivian이 다른 상업 고객에게 공급할 수 있도록 허용.\\n- 2024년 2월, 급여 직원 10% 감축 발표.\\n- 2024년 3월, 더 작은 가격대의 R2 SUV 및 R3 공개.\\n\\n**Volkswagen과의 파트너십 (2024)**\\n\\n- 2024년 6월, Volkswagen Group은 전기 아키텍처 및 소프트웨어 기술 개발을 목표로 Rivian에 최대 50억 달러를 투자할 의향을 발표.\\n\\n**차량**\\n\\n- **R1T:** 4개의 전기 모터가 장착된 픽업 트럭. 배터리 크기는 105 kWh에서 180 kWh까지 다양함.\\n- **R1S:** 첫 번째 Rivian 플랫폼의 스포츠 유틸리티 차량(SUV) 버전.\\n- **Electric Delivery Van (EDV):** 상업용 전기 밴으로, 주로 Amazon용으로 설계되어 사용됨.\\n- **R2:** 더 작고 저렴한 SUV로, 새로운 플랫폼에서 2026년 초에 출시될 예정.\\n- **R3:** 출시 예정인 전기 소형 SUV.\\n\\n**EV 충전**\\n\\nRivian은 미국과 캐나다 전역에 공공 충전소 네트워크를 개발하고 있습니다. Rivian은 2021년에 Waypoint 충전기 설치를 시작했지만 2023년 4월에 Rivian Adventure Network가 Rivian 이외의 차량에도 개방될 것이라고 발표되었습니다. Rivian은 또한 2025년 모델 연도부터 북미에서 차량에 북미 충전 시스템(NACS)을 채택할 예정입니다.\\n\\n**시설**\\n\\n- **Irvine, California:** 차량 엔지니어링 및 설계에 중점을 둔 본사.\\n- **Normal, Illinois:** 차량 부품을 생산하고 조립을 수행하는 제조 공장.\\n- **Plymouth, Michigan:** 차량 엔지니어링, 프로토타입 제작, 공급망 및 회계에 중점을 둡니다.\\n- **Palo Alto, California:** 소프트웨어 개발 및 엔지니어링에 중점을 둡니다.\\n- Carson, California 및 Woking, England에 추가 사무실이 있습니다.\\n- 애틀랜타 동쪽에 있는 새로운 50억 달러 규모의 배터리 및 조립 공장은 보류 중입니다.\\n\\n**재정**\\n\\nRivian의 재무 성과는 상당한 수익 성장과 상당한 순손실로 특징지어집니다.\\n\\n| 연도 | 수익 (백만 USD) | 순이익 (백만 USD) | 총 자산 (백만 USD) |\\n| ---- | --------------- | ----------------- | ------------------ |\\n| 2020 | 0               | -1,018            | 4,602              |\\n| 2021 | 55              | -4,688            | 22,294             |\\n| 2022 | 1,658           | -6,752            | 17,876             |\\n| 2023 | 4,434           | -5,432            | 16,778             |\\n\\n**최대 주주**\\n\\n2023년 12월 현재 최대 주주는 Amazon, T. Rowe Price International, The Vanguard Group, BlackRock 및 Fidelity Investments였습니다.\\n\\n**협력**\\n\\nRivian은 Alex Honnold, the Honnold Foundation, Casa Pueblo, Ewan McGregor, Charley Boorman, Yakima 및 MAXTRAX와 파트너십을 맺었습니다.\\n\\n**소송**\\n\\n- 2020년 7월, Tesla는 Rivian이 독점 정보를 훔치고 직원을 빼갔다고 주장하며 소송을 제기했습니다.\\n- 2021년 3월, Illinois Automobile Dealers Association은 Rivian과 Lucid Motors가 소비자에게 직접 판매했다는 이유로 소송을 제기했습니다.\\n- 2021년 11월, 전 VP Laura Schwab은 차별 혐의로 소송을 제기하고 차량 가격 책정 및 안전 표준에 대한 우려를 제기했습니다.\\n'),\n",
      " Document(metadata={'source': '../data\\\\테슬라_KR.md'}, page_content='Tesla, Inc.는 미국의 다국적 자동차 및 청정 에너지 회사입니다. 이 회사는 전기 자동차(BEV), 고정형 배터리 에너지 저장 장치, 태양 전지판, 태양광 지붕널 및 관련 제품/서비스를 설계, 제조 및 판매합니다. 2003년 7월 Martin Eberhard와 Marc Tarpenning이 Tesla Motors로 설립했으며, Nikola Tesla를 기리기 위해 명명되었습니다. Elon Musk는 2004년 Tesla의 초기 자금 조달을 주도하여 2008년에 회장 겸 CEO가 되었습니다.\\n\\nTesla의 차량 생산은 2008년 Roadster로 시작하여 Model S (2012), Model X (2015), Model 3 (2017), Model Y (2020), Semi (2022) 및 Cybertruck (2023)으로 이어졌습니다. 이 회사는 세계에서 가장 가치 있는 회사 중 하나이며 2020년 7월 이후 가장 가치 있는 자동차 제조업체입니다. Tesla는 2021~2022년, 그리고 2024년에 다시 한 번 한때 1조 달러의 가치를 달성했습니다. 2023년에는 배터리 전기 자동차 시장에서 가장 큰 점유율(19.9%)을 차지했으며 Forbes Global 2000에서 69위에 랭크되었습니다.\\n\\nTesla는 내부 고발자 보복, 근로자 권리 침해, 안전 결함, 홍보 부족, Musk의 논란의 여지가 있는 발언과 관련된 소송, 정부 조사 및 비판에 직면했습니다.\\n\\n## 역사\\n\\n### 창립 (2003–2004)\\n\\nTesla Motors, Inc.는 2003년 7월 1일에 Martin Eberhard와 Marc Tarpenning에 의해 설립되었으며, 각각 CEO와 CFO를 역임했습니다. Ian Wright는 얼마 지나지 않아 합류했습니다. 2004년 2월, Elon Musk는 750만 달러의 시리즈 A 자금 조달을 주도하여 회장 겸 최대 주주가 되었습니다. J. B. Straubel은 2004년 5월 CTO로 합류했습니다. 다섯 명 모두 공동 설립자로 인정받고 있습니다.\\n\\n### Roadster (2005–2009)\\n\\nElon Musk는 주류 차량으로 확장하기 전에 프리미엄 스포츠카로 시작하는 전략에 초점을 맞춰 적극적인 역할을 수행했습니다. 후속 자금 조달에는 Valor Equity Partners (2006)와 Sergey Brin, Larry Page, Jeff Skoll과 같은 기업가의 투자가 포함되었습니다.\\n\\n2007년 8월, Eberhard는 CEO에서 물러나라는 요청을 받았고, Tarpenning은 2008년 1월에 이어졌습니다. Michael Marks는 Ze\\'ev Drori가 인수하기 전에 임시 CEO를 역임했으며, Musk는 2008년 10월에 인수했습니다. Eberhard는 2009년 6월 Musk를 상대로 소송을 제기했지만 나중에 기각되었습니다.\\n\\nRoadster 생산은 2008년에 시작되었습니다. 2009년 1월까지 Tesla는 1억 8,700만 달러를 모금하고 147대의 자동차를 인도했습니다. 2009년 6월, Tesla는 미국 에너지부로부터 4억 6,500만 달러의 대출을 받았으며, 2013년 5월에 이자와 함께 상환했습니다.\\n\\n### IPO, Model S 및 Model X (2010–2015)\\n\\n2010년 5월, Tesla는 캘리포니아 주 프리몬트의 NUMMI 공장을 Toyota로부터 인수했습니다. 이 회사는 2010년 6월 NASDAQ에 상장하여 2억 2,600만 달러를 조달했습니다.\\n\\nTesla는 2012년 6월 Model S 고급 세단을 출시했습니다. Model S는 여러 자동차 상을 받았으며 노르웨이(2013년 9월)와 전 세계(2015년 및 2016년)에서 가장 많이 팔린 전기 자동차가 되었습니다. Tesla는 2013년 7월 NASDAQ-100에 합류했습니다.\\n\\n2014년, Tesla는 운전자 지원 시스템인 Autopilot을 발표했습니다. Tesla는 2015년 4월 Powerwall 및 Powerpack과 함께 에너지 저장 시장에 진출하여 일주일 만에 8억 달러의 주문을 받았습니다. Model X SUV는 2015년 9월에 출시되었습니다.\\n\\n### SolarCity 및 Model 3 (2016–2018)\\n\\nTesla는 2016년 11월 SolarCity를 26억 달러에 인수하여 Tesla Energy를 설립했습니다. 2017년 2월, Tesla Motors는 사명을 Tesla, Inc.로 변경했습니다.\\n\\nModel 3 세단은 2016년 4월에 공개되어 일주일 만에 325,000건 이상의 예약이 접수되었습니다. \"생산 지옥\"으로 묘사된 생산 문제로 인해 지연이 발생했습니다. 2018년 말까지 Model 3는 세계에서 가장 많이 팔린 전기 자동차(2018-2021)가 되었습니다. 2018년 8월, Musk는 Tesla를 비상장으로 전환할 계획을 발표했지만 실현되지 않았고 논란과 SEC의 증권 사기 혐의로 이어졌습니다.\\n\\n### 글로벌 확장 및 Model Y (2019–현재)\\n\\n2019년 7월부터 2020년 6월까지 Tesla는 4분기 연속 흑자를 보고했으며 S&P 500에 추가되었습니다. 2020년에는 주가가 크게 상승했으며 시가 총액은 다음 9개의 대형 자동차 제조업체를 합친 것보다 많았습니다.\\n\\nModel Y 중형 크로스오버 SUV는 2019년 3월에 소개되었으며 배송은 2020년 3월에 시작되었습니다. Tesla는 Gigafactory Shanghai (2019), Gigafactory Berlin (2020) 및 Gigafactory Texas (2020)로 생산 능력을 확장했습니다.\\n\\n2023년 3월, Tesla는 잠재적인 관세 영향으로 인해 지연된 Gigafactory Mexico에 대한 계획을 발표했습니다. COVID-19 팬데믹 초기에 Tesla는 2020년 3월에 프리몬트 공장을 폐쇄하고 지방 당국과의 분쟁 후 2020년 5월 11일에 재개장했습니다. Tesla는 2021년 12월에 법적 본사를 Gigafactory Texas로 이전했지만 Megafactory (2022)와 Palo Alto의 글로벌 엔지니어링 본사(2023)로 캘리포니아에서의 입지를 확장했습니다.\\n\\n2021년 초, Tesla는 Bitcoin에 15억 달러를 투자하고 환경 문제로 인해 중단하기 전에 잠시 결제 수단으로 허용했습니다. 2022년 7월까지 Tesla는 Bitcoin 보유량의 약 75%를 매각했습니다. 2023년 5월과 2024년 2월 사이에 북미 EV 제조업체는 Tesla의 북미 충전 표준으로 전환할 계획을 발표했습니다.\\n\\n2023년 11월, Tesla는 Cybertruck 배송을 시작했습니다. 2024년 4월, 회사는 직원 10% 감축을 발표하고 6월에 법인 설립지를 델라웨어에서 텍사스로 이전했습니다. 2024년 10월, Tesla는 미래의 차량 호출 서비스인 Tesla Network를 위해 Cybercab 및 Robovan의 컨셉 버전을 공개했습니다.\\n\\n2024년 12월, 델라웨어 법원은 부적절한 이사회 승인을 이유로 Elon Musk의 560억 달러 급여 패키지를 거부했습니다.\\n\\n## 자동차 제품 및 서비스\\n\\n2024년 11월 현재 Tesla는 Model S, Model X, Model 3, Model Y, Semi 및 Cybertruck의 6가지 차량 모델을 제공합니다. 다음은 Tesla 모델 목록입니다.\\n\\n| Tesla 모델 |          |       |                  |\\n| :--------- | :------- | :---- | :--------------- |\\n| 이름       | 제조년도 | 좌석  | 참고             |\\n| Roadster   | 2008     | 2     | 2012년에 단종    |\\n| Model S    | 2012     | 5/7   |                  |\\n| Model X    | 2015     | 5/6/7 |                  |\\n| Model 3    | 2017     | 5     |                  |\\n| Model Y    | 2020     | 5/7   |                  |\\n| Semi       | 2022     | 2     |                  |\\n| Cybertruck | 2023     | 5     |                  |\\n| Roadster 2 |          | 2/4   | 2025년 출시 예정 |\\n| Cybercab   |          | 2     | 2026년 출시 예정 |\\n| Robovan    |          | 20    | 명시된 기간 없음 |\\n\\n### 사용 가능한 제품\\n\\n- **Model S:** 리프트백 차체 스타일과 듀얼 모터, 전륜 구동 레이아웃을 갖춘 풀사이즈 고급차. Model S 개발은 2007년 이전에 시작되었으며 배송은 2012년 6월에 시작되었습니다.\\n- **Model X:** 듀얼 모터 또는 트리 모터, 전륜 구동 레이아웃을 갖춘 5인승, 6인승 및 7인승 구성으로 제공되는 중형 고급 크로스오버 SUV. 뒷좌석 승객 문은 관절형 \"팔콘 윙\" 디자인으로 수직으로 열립니다. Model X 프로토타입은 2012년 2월에 처음 공개되었으며 배송은 2015년 9월에 시작되었습니다.\\n- **Model 3:** 패스트백 차체 스타일과 듀얼 모터, 전륜 구동 레이아웃 또는 후륜 모터, 후륜 구동 레이아웃을 갖춘 중형차. 이 차량은 고급 Model S 세단보다 저렴하도록 설계되었습니다. Model 3 프로토타입은 2016년에 처음 공개되었으며 일주일 만에 325,000건 이상의 유료 예약이 접수되었습니다.\\n- **Model Y:** 싱글 모터, 후륜 구동 또는 듀얼 모터, 전륜 구동 레이아웃을 갖춘 5인승 및 7인승 구성으로 제공되는 중형 크로스오버 SUV. 이 차량은 고급 Model X SUV보다 저렴하도록 설계되었습니다. Model Y 프로토타입은 2019년 3월에 처음 공개되었으며 배송은 2020년 3월에 시작되었습니다.\\n- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다.\\n- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다.\\n\\n### 발표된 제품\\n\\n- **Roadster (2세대):** 2017년에 공개되었으며 620마일(1,000km)의 주행 거리와 고성능 사양을 갖춘 것으로 알려져 있습니다. 2025년에 생산 예정입니다.\\n- **Tesla 차세대 차량:** 2025년 상반기에 배송될 것으로 예상되는 발표된 배터리 전기 플랫폼.\\n- **Cybercab:** 출시 예정인 2인승 배터리 전기 자율 주행차.\\n- **Robovan:** 미래 개발을 위해 계획된 전기 자율 밴.\\n\\n### 단종\\n\\n- **Tesla Roadster:** 2008년부터 2012년까지 생산된 2인승 스포츠카.\\n\\n### 연결 서비스\\n\\nTesla 자동차에는 내비게이션을 위한 \"표준 연결\"이 함께 제공됩니다. \"프리미엄 연결\"은 구독료로 실시간 교통 정보, 위성 지도, 인터넷 검색 및 미디어 스트리밍을 추가합니다.\\n\\n### 차량 서비스\\n\\nTesla는 원격 진단 및 수리를 우선시하여 모바일 기술자를 파견하거나 필요한 경우 고객을 서비스 센터로 안내합니다. 이 회사는 전 세계에 소매점, 갤러리, 서비스, 배송 및 차체 수리점을 운영하고 있습니다. Tesla는 차량 서비스에서 이익을 얻지 않는 것을 목표로 합니다. 2019년 초에 연간 유지 보수 요구 사항이 제거되었고 대신 브레이크액, 에어컨, 타이어 및 에어 필터를 주기적으로 서비스할 것을 권장합니다.\\n\\n### 충전 서비스\\n\\n- **Supercharger 네트워크:** Tesla의 고전압 DC 급속 충전 네트워크로, 2012년에 도입되었습니다.\\n- **Destination 충전 위치 네트워크:** 호텔, 레스토랑 및 쇼핑 센터에 있는 더 느린 충전기.\\n\\n### 보험 서비스\\n\\nTesla는 Tesla Insurance Services, Inc.를 통해 미국에서 차량 보험을 제공하고 차량 데이터를 사용하여 개인 맞춤 가격을 제공합니다.\\n\\n## 에너지 제품\\n\\nTesla Energy는 태양 에너지 생성 시스템과 배터리 에너지 저장 제품을 개발, 구축, 판매 및 설치합니다. 제품에는 태양 전지판, Solar Roof, Solar Inverter, Powerwall 및 Megapack이 포함됩니다. 이 회사는 대규모 고객을 위한 자동화된 전력 거래, 수요 예측 및 제품 제어를 위한 온라인 플랫폼을 운영하고 있습니다.\\n\\n## 비즈니스 전략\\n\\nTesla의 전략은 배터리 비용을 줄이기 위해 고가, 소량 차량으로 시작한 다음 더 저렴하고 대량 차량을 제공하는 것입니다. Tesla는 자동차의 하드웨어를 지속적으로 업데이트하고 웹사이트와 회사 소유 매장을 통해 직접 차량을 판매합니다. Tesla는 수직적으로 통합되어 많은 구성 요소를 자체 개발합니다. Tesla는 일반적으로 지속 가능한 에너지 채택을 촉진하기 위해 경쟁 업체가 자사 기술을 라이선스하도록 허용합니다.\\n\\n## 기술\\n\\n### 배터리\\n\\nTesla는 CATL, LG Energy Solution 및 Panasonic에서 공급받은 원통형 및 각형 배터리 셀을 사용하고 있으며 자체 배터리를 생산할 수 있는 능력을 구축하고 있습니다.\\n\\n### 소프트웨어\\n\\nTesla는 무선 업데이트를 사용하여 강력한 온보드 컴퓨터를 통해 기능을 추가하거나 문제를 해결합니다.\\n\\n### 모터\\n\\nTesla는 유도 모터와 동기 릴럭턴스 모터(SynRM) 특성을 가진 내부 영구 자석(IPM) 모터를 만듭니다.\\n\\n### 북미 충전 표준\\n\\n북미 충전 표준(NACS)은 Tesla에서 개발한 전기 자동차 충전 커넥터 시스템입니다.\\n\\n### Autopilot 및 완전 자율 주행\\n\\nTesla Autopilot은 Tesla에서 개발한 고급 운전자 지원 시스템(ADAS)으로, 부분적인 차량 자동화를 의미합니다.\\n\\n### 로봇 공학\\n\\nTesla는 대형 주조 기계(Giga Press)를 사용하여 대형 단일 피스 하체를 만듭니다. 이 회사는 2022년부터 Optimus라는 휴머노이드 로봇을 개발해 왔습니다.\\n\\n## 시설\\n\\nTesla는 소매점, 갤러리 및 서비스 센터를 포함하여 전 세계에 대규모 공장과 소규모 시설을 운영하고 있습니다.\\n\\n**Tesla에서 운영하는 주요 시설**\\n\\n| 개장 | 이름                | 도시                    | 국가 | 직원 수 | 제품                               |\\n| :--- | :------------------ | :---------------------- | :--- | :------ | :--------------------------------- |\\n| 2010 | Tesla 프리몬트 공장 | 캘리포니아 주 프리몬트  | 미국 | 22,000  | Model S, Model X, Model 3, Model Y |\\n| 2016 | Gigafactory 네바다  | 네바다 주 스토리 카운티 | 미국 | 7,000   | 배터리, Powerwall, Semi            |\\n| 2017 | Gigafactory 뉴욕    | 뉴욕 주 버팔로          | 미국 | 1,500   | Solar Roof, Supercharger           |\\n| 2019 | Gigafactory 상하이  | 상하이                  | 중국 | 20,000  | Model 3, Model Y, Supercharger     |\\n| 2022 | Gigafactory 베를린  | 그륀하이데              | 독일 | 10,000  | Model Y                            |\\n| 2022 | Gigafactory 텍사스  | 텍사스 주 오스틴        | 미국 | 12,000  | Model Y, Cybertruck                |\\n\\n## 파트너\\n\\nTesla는 Panasonic과 파트너십을 맺고 있으며 리튬 공급에 대한 장기 계약을 맺고 있습니다. 이전 파트너로는 Daimler와 Toyota가 있습니다.\\n\\n## 소송 및 논란\\n\\nTesla는 성희롱, 노동 분쟁, 사기 혐의, 대리점 분쟁, 지적 재산권, 환경 위반, 재산 피해, 인종 차별, COVID-19 팬데믹 대응 및 수리 권리와 관련된 소송 및 논란에 직면했습니다.\\n\\n## 비판\\n\\nTesla는 데이터 개인 정보 보호, 공매도자, 지연, 차량 제품 문제, 화재, Autopilot 충돌, 소프트웨어 해킹, 가상 제동 및 주행 거리 성능과 관련된 비판에 직면했습니다.\\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "def load_text_files(txt_files):\n",
    "    data = []\n",
    "\n",
    "    for text_file in txt_files:\n",
    "        loader = TextLoader(text_file, encoding=\"utf-8\")\n",
    "        data += loader.load()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "korean_txt_files = glob(os.path.join(\"../data\", \"*_KR.md\"))\n",
    "korean_data = load_text_files(korean_txt_files)\n",
    "\n",
    "print(\"Korean data:\")\n",
    "pprint(korean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 문서 수: 39\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': '../data\\\\리비안_KR.md'}\n",
      "('Rivian Automotive, Inc.는 2009년에 설립된 미국의 전기 자동차 제조업체, 자동차 기술 및 야외 레크리에이션 '\n",
      " '회사입니다.\\n'\n",
      " '\\n'\n",
      " '**주요 정보:**')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': '../data\\\\리비안_KR.md'}\n",
      "('- **회사 유형:** 상장\\n'\n",
      " '- **거래소:** NASDAQ: RIVN\\n'\n",
      " '- **설립:** 2009년 6월, 플로리다 주 록ledge\\n'\n",
      " '- **설립자:** R. J. 스캐린지\\n'\n",
      " '- **본사:** 미국 캘리포니아 주 어바인\\n'\n",
      " '- **서비스 지역:** 북미\\n'\n",
      " '- **주요 인물:** R. J. 스캐린지 (CEO)\\n'\n",
      " '- **제품:** 전기 자동차, 배터리\\n'\n",
      " '- **생산량 (2023):** 57,232대\\n'\n",
      " '- **서비스:** 전기 자동차 충전, 자동차 보험\\n'\n",
      " '- **수익 (2023):** 44억 3천만 미국 달러\\n'\n",
      " '- **순이익 (2023):** -54억 미국 달러\\n'\n",
      " '- **총 자산 (2023):** 168억 미국 달러')\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 문장을 구분하여 분할 - 정규표현식 사용 (문장 구분자: 마침표, 느낌표, 물음표 다음에 공백이 오는 경우)\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",  # TikToken 인코더 이름\n",
    "    separators=[\"\\n\\n\", \"\\n\", r\"(?<=[.!?])\\s+\"],  # 구분자\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0,\n",
    "    is_separator_regex=True,  # 구분자가 정규식인지 여부\n",
    "    keep_separator=True,  # 구분자 유지 여부\n",
    ")\n",
    "\n",
    "korean_docs = text_splitter.split_documents(korean_data)\n",
    "\n",
    "print(\"한국어 문서 수:\", len(korean_docs))\n",
    "print(\"-\" * 100)\n",
    "print(korean_docs[0].metadata)\n",
    "pprint(korean_docs[0].page_content)\n",
    "print(\"-\" * 100)\n",
    "print(korean_docs[1].metadata)\n",
    "pprint(korean_docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 Document 개수: 39\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI Embeddings 모델을 로드\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Chroma 벡터 저장소 생성하기\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=korean_docs,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"db_korean_cosine\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"},  # l2, ip, cosine 중에서 선택\n",
    ")\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"저장된 Document 개수: {len(vector_store.get()['ids'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) LLM 설정`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# LLM과 임베딩 모델 초기화\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\", temperature=0.2))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(\n",
    "    OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Test Data 생성`\n",
    "\n",
    "- uv add rapidfuzz 설치 필요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.persona import Persona\n",
    "\n",
    "# 페르소나 정의 (다양한 관점에서 질문 생성)\n",
    "personas = [\n",
    "    Persona(\n",
    "        name=\"graduate_researcher\",  # 박사과정 연구원: 심도 있는 분석적 질문\n",
    "        role_description=\"미국 전기차 시장을 연구하는 한국인 박사과정 연구원으로, 전기차 정책과 시장 동향에 대해 깊이 있는 분석을 하고 있습니다. 한국어만을 사용합니다.\",\n",
    "    ),\n",
    "    Persona(\n",
    "        name=\"masters_student\",  # 석사과정 학생: 개념 이해를 위한 질문\n",
    "        role_description=\"전기차 산업을 공부하는 한국인 석사과정 학생으로, 미국 전기차 시장의 기초적인 개념과 트렌드를 이해하려 노력하고 있습니다. 한국어만을 사용합니다.\",\n",
    "    ),\n",
    "    Persona(\n",
    "        name=\"industry_analyst\",  # 산업 분석가: 실무 중심적 질문\n",
    "        role_description=\"한국 자동차 회사에서 미국 전기차 시장을 분석하는 주니어 연구원으로, 실무적인 시장 데이터와 경쟁사 동향에 관심이 많습니다. 한국어만을 사용합니다.\",\n",
    "    ),\n",
    "    Persona(\n",
    "        name=\"undergraduate_student\",  # 학부생: 기초적인 학습 질문\n",
    "        role_description=\"자동차 공학을 전공하는 한국인 학부생으로, 미국 전기차 기술과 시장에 대해 기본적인 지식을 습득하고자 합니다. 한국어만을 사용합니다.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  35%|███▌      | 12/34 [01:02<04:06, 11.22s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29763, Requested 469. Please try again in 464ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying SummaryExtractor:  59%|█████▉    | 20/34 [01:31<00:39,  2.84s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying SummaryExtractor:  62%|██████▏   | 21/34 [01:44<01:08,  5.28s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 404. Please try again in 808ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying SummaryExtractor:  65%|██████▍   | 22/34 [01:51<01:09,  5.76s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 365. Please try again in 730ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying SummaryExtractor:  68%|██████▊   | 23/34 [01:58<01:06,  6.04s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying SummaryExtractor:  76%|███████▋  | 26/34 [02:33<01:13,  9.24s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29893, Requested 454. Please try again in 694ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying SummaryExtractor:  79%|███████▉  | 27/34 [02:45<01:11, 10.22s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29926, Requested 418. Please try again in 688ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying SummaryExtractor:  82%|████████▏ | 28/34 [02:52<00:55,  9.33s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29859, Requested 448. Please try again in 614ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying SummaryExtractor:  85%|████████▌ | 29/34 [02:57<00:39,  7.84s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 480. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying SummaryExtractor:  88%|████████▊ | 30/34 [03:03<00:29,  7.41s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying SummaryExtractor:  91%|█████████ | 31/34 [03:14<00:25,  8.41s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29909, Requested 491. Please try again in 800ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying SummaryExtractor:  94%|█████████▍| 32/34 [03:20<00:15,  7.86s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29727, Requested 467. Please try again in 388ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying SummaryExtractor:  97%|█████████▋| 33/34 [03:50<00:14, 14.36s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 446. Please try again in 892ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying CustomNodeFilter:   0%|          | 0/39 [00:00<?, ?it/s]         Node 51828162-f2e2-4185-847f-ede18ccf894e does not have a summary. Skipping filtering.\n",
      "Node ec0f2d3c-aca1-48dc-899c-4717cf3fb8c2 does not have a summary. Skipping filtering.\n",
      "Node ef04b5d6-785c-4849-9f87-cff1136bdaf1 does not have a summary. Skipping filtering.\n",
      "Node a16820a4-1cfa-4654-b3b4-f850b1ae9cb2 does not have a summary. Skipping filtering.\n",
      "Node 7926b6e6-197d-41b5-80fd-b8f4add67f96 does not have a summary. Skipping filtering.\n",
      "Node ebdce744-970b-4cf7-8a53-cb62a82eb8e2 does not have a summary. Skipping filtering.\n",
      "Node 0e85d317-1952-4364-a2f3-6f39ae631bd5 does not have a summary. Skipping filtering.\n",
      "Node 09879a79-4e09-47c3-843a-2c796a20c923 does not have a summary. Skipping filtering.\n",
      "Node 61487d05-452c-4ee0-8e13-014cb8714745 does not have a summary. Skipping filtering.\n",
      "Node 43e183e2-7a7c-490c-8fe6-0ca417d86cc8 does not have a summary. Skipping filtering.\n",
      "Node acbbecf0-bfa2-46d4-a268-0979d348c587 does not have a summary. Skipping filtering.\n",
      "Node 5d279d6d-b9ec-4c36-a5c7-63ef48c4ecc4 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  28%|██▊       | 11/39 [00:07<00:18,  1.55it/s]Node c42e8bc9-34cd-4a7f-a7ae-6f73794d800b does not have a summary. Skipping filtering.\n",
      "Node 7da9129f-afbd-404d-8731-b626fe652deb does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  44%|████▎     | 17/39 [00:29<00:47,  2.15s/it]Node 831ba8b4-73e7-4714-8c25-e794aacdb63f does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  51%|█████▏    | 20/39 [00:43<00:54,  2.85s/it]Node 9383b022-67a4-4b73-aba7-6caf16f9fd92 does not have a summary. Skipping filtering.\n",
      "Node 7af507a4-196a-47d2-9dd8-5de5a3cdd263 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  54%|█████▍    | 21/39 [00:45<00:49,  2.72s/it]Node 6164452b-a5de-4e6b-90a1-44905231f63a does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  67%|██████▋   | 26/39 [00:53<00:28,  2.20s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 643. Please try again in 1.286s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying CustomNodeFilter:  72%|███████▏  | 28/39 [01:26<01:10,  6.42s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 649. Please try again in 1.298s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying CustomNodeFilter:  74%|███████▍  | 29/39 [02:07<02:03, 12.35s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29694, Requested 587. Please try again in 562ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying CustomNodeFilter:  77%|███████▋  | 30/39 [02:08<01:30, 10.07s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying CustomNodeFilter:  79%|███████▉  | 31/39 [02:12<01:09,  8.74s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 602. Please try again in 1.204s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying CustomNodeFilter:  82%|████████▏ | 32/39 [02:31<01:18, 11.15s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29605, Requested 723. Please try again in 656ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying CustomNodeFilter:  85%|████████▍ | 33/39 [02:34<00:54,  9.14s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 683. Please try again in 1.366s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying CustomNodeFilter:  90%|████████▉ | 35/39 [02:56<00:41, 10.46s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying CustomNodeFilter:  92%|█████████▏| 36/39 [03:06<00:30, 10.19s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying CustomNodeFilter:  95%|█████████▍| 37/39 [03:07<00:15,  7.71s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying CustomNodeFilter:  97%|█████████▋| 38/39 [03:20<00:09,  9.25s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 713. Please try again in 1.426s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   1%|          | 1/112 [00:07<13:09,  7.11s/it]unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "unable to apply transformation: node.property('summary') must be a string, found '<class 'NoneType'>'\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  39%|███▉      | 44/112 [01:05<07:15,  6.40s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 411. Please try again in 822ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  42%|████▏     | 47/112 [01:42<08:50,  8.17s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 401. Please try again in 802ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  45%|████▍     | 50/112 [01:47<04:23,  4.25s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  50%|█████     | 56/112 [02:06<03:43,  3.99s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29713, Requested 464. Please try again in 354ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  51%|█████     | 57/112 [02:07<02:48,  3.06s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  53%|█████▎    | 59/112 [02:08<01:44,  1.98s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29765, Requested 449. Please try again in 428ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  54%|█████▍    | 61/112 [02:11<01:17,  1.52s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29987, Requested 420. Please try again in 814ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  56%|█████▋    | 63/112 [02:22<03:01,  3.70s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29742, Requested 452. Please try again in 388ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  57%|█████▋    | 64/112 [02:24<02:30,  3.14s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  62%|██████▏   | 69/112 [02:39<02:39,  3.70s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 461. Please try again in 922ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  62%|██████▎   | 70/112 [02:44<02:54,  4.16s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29756, Requested 402. Please try again in 316ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  63%|██████▎   | 71/112 [02:57<04:31,  6.61s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29948, Requested 383. Please try again in 662ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  67%|██████▋   | 75/112 [03:36<05:58,  9.70s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  70%|██████▉   | 78/112 [04:07<05:00,  8.82s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  72%|███████▏  | 81/112 [04:23<03:22,  6.53s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 481. Please try again in 962ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  74%|███████▍  | 83/112 [04:23<01:38,  3.39s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  76%|███████▌  | 85/112 [04:27<01:07,  2.49s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  79%|███████▉  | 89/112 [04:35<01:01,  2.67s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29755, Requested 416. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  81%|████████▏ | 91/112 [04:38<00:42,  2.03s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29827, Requested 376. Please try again in 406ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  82%|████████▏ | 92/112 [04:42<00:48,  2.45s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  85%|████████▍ | 95/112 [04:58<01:04,  3.82s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 29838, Requested 371. Please try again in 418ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  86%|████████▌ | 96/112 [04:58<00:43,  2.74s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  88%|████████▊ | 98/112 [04:59<00:24,  1.72s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  92%|█████████▏| 103/112 [05:30<00:54,  6.04s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  97%|█████████▋| 109/112 [06:30<00:24,  8.16s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 439. Please try again in 878ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  98%|█████████▊| 110/112 [06:32<00:12,  6.14s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 441. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]                 unable to apply transformation: Node ef04b5d6-785c-4849-9f87-cff1136bdaf1 has no summary_embedding\n",
      "unable to apply transformation: Node 51828162-f2e2-4185-847f-ede18ccf894e or ec0f2d3c-aca1-48dc-899c-4717cf3fb8c2 has no entities\n",
      "Generating Scenarios:   0%|          | 0/1 [04:17<?, ?it/s]                                   \n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 624. Please try again in 1.248s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m generator = TestsetGenerator(\n\u001b[32m      5\u001b[39m     llm=generator_llm, embedding_model=generator_embeddings, persona_list=personas\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 합성 데이터 생성\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m dataset = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkorean_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\testset\\synthesizers\\generate.py:188\u001b[39m, in \u001b[36mTestsetGenerator.generate_with_langchain_docs\u001b[39m\u001b[34m(self, documents, testset_size, transforms, transforms_llm, transforms_embedding_model, query_distribution, run_config, callbacks, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    185\u001b[39m apply_transforms(kg, transforms)\n\u001b[32m    186\u001b[39m \u001b[38;5;28mself\u001b[39m.knowledge_graph = kg\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\testset\\synthesizers\\generate.py:413\u001b[39m, in \u001b[36mTestsetGenerator.generate\u001b[39m\u001b[34m(self, testset_size, query_distribution, num_personas, run_config, batch_size, callbacks, token_usage_parser, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    412\u001b[39m     scenario_generation_rm.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    415\u001b[39m     scenario_generation_rm.on_chain_end(\n\u001b[32m    416\u001b[39m         outputs={\u001b[33m\"\u001b[39m\u001b[33mscenario_sample_list\u001b[39m\u001b[33m\"\u001b[39m: scenario_sample_list}\n\u001b[32m    417\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\testset\\synthesizers\\generate.py:410\u001b[39m, in \u001b[36mTestsetGenerator.generate\u001b[39m\u001b[34m(self, testset_size, query_distribution, num_personas, run_config, batch_size, callbacks, token_usage_parser, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    401\u001b[39m     exec.submit(\n\u001b[32m    402\u001b[39m         scenario.generate_scenarios,\n\u001b[32m    403\u001b[39m         n=splits[i],\n\u001b[32m   (...)\u001b[39m\u001b[32m    406\u001b[39m         callbacks=scenario_generation_grp,\n\u001b[32m    407\u001b[39m     )\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     scenario_sample_list: t.List[t.List[BaseScenario]] = \u001b[43mexec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    412\u001b[39m     scenario_generation_rm.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\executor.py:213\u001b[39m, in \u001b[36mExecutor.results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m             nest_asyncio.apply()\n\u001b[32m    211\u001b[39m             \u001b[38;5;28mself\u001b[39m._nest_asyncio_applied = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m sorted_results = \u001b[38;5;28msorted\u001b[39m(results, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m])\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\asyncio\\futures.py:202\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\asyncio\\tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\executor.py:141\u001b[39m, in \u001b[36mExecutor._process_jobs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pbar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[32m    137\u001b[39m         total=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.jobs),\n\u001b[32m    138\u001b[39m         desc=\u001b[38;5;28mself\u001b[39m.desc,\n\u001b[32m    139\u001b[39m         disable=\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.show_progress,\n\u001b[32m    140\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m internal_pbar:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_coroutines(\n\u001b[32m    142\u001b[39m             \u001b[38;5;28mself\u001b[39m.jobs, internal_pbar, results, max_workers\n\u001b[32m    143\u001b[39m         )\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_coroutines(\n\u001b[32m    146\u001b[39m         \u001b[38;5;28mself\u001b[39m.jobs, \u001b[38;5;28mself\u001b[39m.pbar, results, max_workers\n\u001b[32m    147\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\executor.py:191\u001b[39m, in \u001b[36mExecutor._process_coroutines\u001b[39m\u001b[34m(self, jobs, pbar, results, max_workers)\u001b[39m\n\u001b[32m    189\u001b[39m coroutines = [afunc(*args, **kwargs) \u001b[38;5;28;01mfor\u001b[39;00m afunc, args, kwargs, _ \u001b[38;5;129;01min\u001b[39;00m jobs]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m as_completed(coroutines, max_workers):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    192\u001b[39m     results.append(result)\n\u001b[32m    193\u001b[39m     pbar.update(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\asyncio\\tasks.py:631\u001b[39m, in \u001b[36mas_completed.<locals>._wait_for_one\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# Dummy value from _on_timeout().\u001b[39;00m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.TimeoutError\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\asyncio\\futures.py:202\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\asyncio\\tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\executor.py:48\u001b[39m, in \u001b[36mas_completed.<locals>.sema_coro\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msema_coro\u001b[39m(coro):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\executor.py:100\u001b[39m, in \u001b[36mExecutor.wrap_callable_with_index.<locals>.wrapped_callable_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raise_exceptions:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    102\u001b[39m         exec_name = \u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\executor.py:96\u001b[39m, in \u001b[36mExecutor.wrap_callable_with_index.<locals>.wrapped_callable_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_callable_async\u001b[39m(\n\u001b[32m     93\u001b[39m     *args, **kwargs\n\u001b[32m     94\u001b[39m ) -> t.Tuple[\u001b[38;5;28mint\u001b[39m, t.Callable | \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(*args, **kwargs)\n\u001b[32m     97\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m counter, result\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\testset\\synthesizers\\base.py:94\u001b[39m, in \u001b[36mBaseSynthesizer.generate_scenarios\u001b[39m\u001b[34m(self, n, knowledge_graph, persona_list, callbacks)\u001b[39m\n\u001b[32m     88\u001b[39m callbacks = callbacks \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m     89\u001b[39m scenario_generation_rm, scenario_generation_group = new_group(\n\u001b[32m     90\u001b[39m     name=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m     91\u001b[39m     inputs={\u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n, \u001b[33m\"\u001b[39m\u001b[33mknowledge_graph\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(knowledge_graph)},\n\u001b[32m     92\u001b[39m     callbacks=callbacks,\n\u001b[32m     93\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m scenarios = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_scenarios(\n\u001b[32m     95\u001b[39m     n, knowledge_graph, persona_list, scenario_generation_group\n\u001b[32m     96\u001b[39m )\n\u001b[32m     97\u001b[39m scenario_generation_rm.on_chain_end(outputs={\u001b[33m\"\u001b[39m\u001b[33mscenarios\u001b[39m\u001b[33m\"\u001b[39m: scenarios})\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m scenarios\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\testset\\synthesizers\\single_hop\\specific.py:107\u001b[39m, in \u001b[36mSingleHopSpecificQuerySynthesizer._generate_scenarios\u001b[39m\u001b[34m(self, n, knowledge_graph, persona_list, callbacks)\u001b[39m\n\u001b[32m    105\u001b[39m themes = node.properties.get(\u001b[38;5;28mself\u001b[39m.property_name, [\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    106\u001b[39m prompt_input = ThemesPersonasInput(themes=themes, personas=persona_list)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m persona_concepts = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.theme_persona_matching_prompt.generate(\n\u001b[32m    108\u001b[39m     data=prompt_input, llm=\u001b[38;5;28mself\u001b[39m.llm, callbacks=callbacks\n\u001b[32m    109\u001b[39m )\n\u001b[32m    110\u001b[39m base_scenarios = \u001b[38;5;28mself\u001b[39m.prepare_combinations(\n\u001b[32m    111\u001b[39m     node,\n\u001b[32m    112\u001b[39m     themes,\n\u001b[32m    113\u001b[39m     personas=persona_list,\n\u001b[32m    114\u001b[39m     persona_concepts=persona_concepts.mapping,\n\u001b[32m    115\u001b[39m )\n\u001b[32m    116\u001b[39m scenarios.extend(\u001b[38;5;28mself\u001b[39m.sample_combinations(base_scenarios, samples_per_node))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\prompt\\pydantic_prompt.py:129\u001b[39m, in \u001b[36mPydanticPrompt.generate\u001b[39m\u001b[34m(self, llm, data, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    126\u001b[39m callbacks = callbacks \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# this is just a special case of generate_multiple\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m output_single = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_multiple(\n\u001b[32m    130\u001b[39m     llm=llm,\n\u001b[32m    131\u001b[39m     data=data,\n\u001b[32m    132\u001b[39m     n=\u001b[32m1\u001b[39m,\n\u001b[32m    133\u001b[39m     temperature=temperature,\n\u001b[32m    134\u001b[39m     stop=stop,\n\u001b[32m    135\u001b[39m     callbacks=callbacks,\n\u001b[32m    136\u001b[39m     retries_left=retries_left,\n\u001b[32m    137\u001b[39m )\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output_single[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\prompt\\pydantic_prompt.py:190\u001b[39m, in \u001b[36mPydanticPrompt.generate_multiple\u001b[39m\u001b[34m(self, llm, data, n, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    183\u001b[39m prompt_rm, prompt_cb = new_group(\n\u001b[32m    184\u001b[39m     name=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    185\u001b[39m     inputs={\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m: processed_data},\n\u001b[32m    186\u001b[39m     callbacks=callbacks,\n\u001b[32m    187\u001b[39m     metadata={\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: ChainType.RAGAS_PROMPT},\n\u001b[32m    188\u001b[39m )\n\u001b[32m    189\u001b[39m prompt_value = PromptValue(text=\u001b[38;5;28mself\u001b[39m.to_string(processed_data))\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m resp = \u001b[38;5;28;01mawait\u001b[39;00m llm.generate(\n\u001b[32m    191\u001b[39m     prompt_value,\n\u001b[32m    192\u001b[39m     n=n,\n\u001b[32m    193\u001b[39m     temperature=temperature,\n\u001b[32m    194\u001b[39m     stop=stop,\n\u001b[32m    195\u001b[39m     callbacks=prompt_cb,\n\u001b[32m    196\u001b[39m )\n\u001b[32m    198\u001b[39m output_models = []\n\u001b[32m    199\u001b[39m parser = RagasOutputParser(pydantic_object=\u001b[38;5;28mself\u001b[39m.output_model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py:109\u001b[39m, in \u001b[36mBaseRagasLLM.generate\u001b[39m\u001b[34m(self, prompt, n, temperature, stop, callbacks)\u001b[39m\n\u001b[32m    104\u001b[39m     temperature = \u001b[38;5;28mself\u001b[39m.get_temperature(n)\n\u001b[32m    106\u001b[39m agenerate_text_with_retry = add_async_retry(\n\u001b[32m    107\u001b[39m     \u001b[38;5;28mself\u001b[39m.agenerate_text, \u001b[38;5;28mself\u001b[39m.run_config\n\u001b[32m    108\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m agenerate_text_with_retry(\n\u001b[32m    110\u001b[39m     prompt=prompt,\n\u001b[32m    111\u001b[39m     n=n,\n\u001b[32m    112\u001b[39m     temperature=temperature,\n\u001b[32m    113\u001b[39m     stop=stop,\n\u001b[32m    114\u001b[39m     callbacks=callbacks,\n\u001b[32m    115\u001b[39m )\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# check there are no max_token issues\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_finished(result):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:189\u001b[39m, in \u001b[36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    188\u001b[39m async_wrapped.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m copy(fn, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:111\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    109\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:153\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    151\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\tenacity\\_utils.py:99\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:114\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    116\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py:254\u001b[39m, in \u001b[36mLangchainLLMWrapper.agenerate_text\u001b[39m\u001b[34m(self, prompt, n, temperature, stop, callbacks)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.langchain_llm, \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mself\u001b[39m.langchain_llm.n = n  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.langchain_llm.agenerate_prompt(\n\u001b[32m    255\u001b[39m         prompts=[prompt],\n\u001b[32m    256\u001b[39m         stop=stop,\n\u001b[32m    257\u001b[39m         callbacks=callbacks,\n\u001b[32m    258\u001b[39m     )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    260\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.langchain_llm.agenerate_prompt(\n\u001b[32m    261\u001b[39m         prompts=[prompt] * n,\n\u001b[32m    262\u001b[39m         stop=stop,\n\u001b[32m    263\u001b[39m         callbacks=callbacks,\n\u001b[32m    264\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:968\u001b[39m, in \u001b[36mBaseChatModel.agenerate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magenerate_prompt\u001b[39m(\n\u001b[32m    961\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    965\u001b[39m     **kwargs: Any,\n\u001b[32m    966\u001b[39m ) -> LLMResult:\n\u001b[32m    967\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m968\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate(\n\u001b[32m    969\u001b[39m         prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n\u001b[32m    970\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:926\u001b[39m, in \u001b[36mBaseChatModel.agenerate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    913\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[32m    914\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    915\u001b[39m             *[\n\u001b[32m    916\u001b[39m                 run_manager.on_llm_end(\n\u001b[32m   (...)\u001b[39m\u001b[32m    924\u001b[39m             ]\n\u001b[32m    925\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[32m0\u001b[39m]\n\u001b[32m    927\u001b[39m flattened_outputs = [\n\u001b[32m    928\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[list-item, union-attr]\u001b[39;00m\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m    930\u001b[39m ]\n\u001b[32m    931\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m._combine_llm_outputs([res.llm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\asyncio\\tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1094\u001b[39m, in \u001b[36mBaseChatModel._agenerate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1092\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._agenerate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(\n\u001b[32m   1095\u001b[39m         messages, stop=stop, run_manager=run_manager, **kwargs\n\u001b[32m   1096\u001b[39m     )\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1098\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1281\u001b[39m, in \u001b[36mBaseChatOpenAI._agenerate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1279\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m   1280\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1281\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_client.create(**payload)\n\u001b[32m   1282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m._create_chat_result, response, generation_info\n\u001b[32m   1284\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:2028\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1985\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1986\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1987\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2025\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   2026\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m   2027\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2028\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2029\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2030\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2031\u001b[39m             {\n\u001b[32m   2032\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2033\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2034\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2035\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2036\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2037\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2038\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2039\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2040\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2041\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2042\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2043\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2044\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2045\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2046\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2047\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2048\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2049\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2050\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2051\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2052\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2053\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2054\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2055\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2056\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2057\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2058\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2059\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2060\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2061\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2062\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2063\u001b[39m             },\n\u001b[32m   2064\u001b[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2065\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2066\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2067\u001b[39m         ),\n\u001b[32m   2068\u001b[39m         options=make_request_options(\n\u001b[32m   2069\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2070\u001b[39m         ),\n\u001b[32m   2071\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   2072\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2073\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2074\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1784\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1770\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1772\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1779\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1780\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1781\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1782\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1783\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1584\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1581\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1583\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1584\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1586\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1588\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-BUKxCvFx9eMpKEDf3d67YmYZ on tokens per min (TPM): Limit 30000, Used 30000, Requested 624. Please try again in 1.248s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "# TestsetGenerator 생성\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm, embedding_model=generator_embeddings, persona_list=personas\n",
    ")\n",
    "\n",
    "# 합성 데이터 생성\n",
    "dataset = generator.generate_with_langchain_docs(korean_docs, testset_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "dataset.to_pandas().to_csv(\"./data/ragas_testset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **평가 지표(Evaluation Metric)**\n",
    "\n",
    "#### 1) **검색(Retrieval) 평가**\n",
    "\n",
    "- **Non-Rank Based Metrics**: Accuracy, Precision, Recall@k 등을 통해 관련성의 이진적 평가를 수행\n",
    "\n",
    "- **Rank-Based Metrics**: MRR(Mean Reciprocal Rank), MAP(Mean Average Precision)를 통해 검색 결과의 순위를 고려한 평가를 수행\n",
    "\n",
    "- **RAG 특화 지표**: 기존 검색 평가 방식의 한계를 보완하는 LLM-as-judge 방식 도입\n",
    "\n",
    "- **포괄적 평가**: 정확도, 관련성, 다양성, 강건성을 통합적으로 측정\n",
    "\n",
    "#### 2) **생성(Generation) 평가**\n",
    "\n",
    "- **전통적 평가**: ROUGE(요약), BLEU(번역), BertScore(의미 유사도) 지표 활용\n",
    "\n",
    "- **LLM 기반 평가**: 응집성, 관련성, 유창성을 종합적으로 판단하는 새로운 접근법 도입 (전통적인 참조 비교가 어려운 상황에서 유용)\n",
    "\n",
    "- **다차원 평가**: 품질, 일관성, 사실성, 가독성, 사용자 만족도를 포괄적 측정\n",
    "\n",
    "- **상세 프롬프트**와 **사용자 선호도** 기준으로 생성 텍스트 품질 평가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) RAG 체인 - 평가 대상`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla는 2003년 7월 1일에 Martin Eberhard와 Marc Tarpenning에 의해 설립되었습니다.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 벡터 저장소 검색기 생성\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# RAG 체인\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# 템플릿 생성\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "def format_docs(relevant_docs):\n",
    "    return \"\\n\".join(doc.page_content for doc in relevant_docs)\n",
    "\n",
    "\n",
    "query = \"Tesla는 언제 누가 만들었나?\"\n",
    "\n",
    "relevant_docs = retriever.invoke(query)\n",
    "qa_chain.invoke({\"context\": format_docs(relevant_docs), \"query\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 평가 수행을 위한 데이터셋 전처리`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/testset.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 데이터 로드\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m testset = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/testset.xlsx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 데이터 확인\u001b[39;00m\n\u001b[32m      7\u001b[39m testset.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1548\u001b[39m     ext = \u001b[33m\"\u001b[39m\u001b[33mxls\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     ext = \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[39m, in \u001b[36minspect_excel_format\u001b[39m\u001b[34m(content_or_path, storage_options)\u001b[39m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m   1400\u001b[39m     content_or_path = BytesIO(content_or_path)\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1404\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[32m   1405\u001b[39m     stream = handle.handle\n\u001b[32m   1406\u001b[39m     stream.seek(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\ktds-edu\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/testset.xlsx'"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "import pandas as pd\n",
    "\n",
    "testset = pd.read_excel(\"../data/testset.xlsx\")\n",
    "\n",
    "# 데이터 확인\n",
    "testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = []\n",
    "\n",
    "# 각 행에 대해 RAG 체인을 호출하여 결과를 저장\n",
    "for row in testset.itertuples():\n",
    "    query = row.user_input  # 사용자 입력\n",
    "    reference = row.reference  # 참조 답변\n",
    "    relevant_docs = retriever.invoke(query)  # 검색된 문서\n",
    "    response = qa_chain.invoke(  # RAG 체인 생성 답변 생성\n",
    "        {\n",
    "            \"context\": format_docs(relevant_docs),\n",
    "            \"query\": query,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\": query,\n",
    "            \"retrieved_contexts\": [d.page_content for d in relevant_docs],\n",
    "            \"response\": response,\n",
    "            \"reference\": reference,\n",
    "        }\n",
    "    )\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 변환하여 확인\n",
    "evaluation_dataset.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "evaluation_dataset.to_pandas().to_csv(\"data/evaluation_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 평가 수행`\n",
    "\n",
    "- **LLMContextRecall**\n",
    "\n",
    "  - 검색된 컨텍스트가 정답을 생성하는 데 필요한 **모든 정보를 포함**하고 있는지 평가\n",
    "\n",
    "- **Faithfulness**\n",
    "\n",
    "  - 생성된 응답이 검색된 컨텍스트와 얼마나 **사실적으로 일관**되는지를 측정\n",
    "\n",
    "- **FactualCorrectness**\n",
    "  - 생성된 응답과 reference의 **사실적 정확**성을 비교하고 평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 래퍼 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "# 평가\n",
    "result = evaluate(\n",
    "    dataset=evaluation_dataset,  # 평가 데이터셋\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],  # 평가 메트릭\n",
    "    llm=evaluator_llm,  # LLM 래퍼\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 데이터프레임으로 변환\n",
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 저장\n",
    "result.to_pandas().to_csv(\"data/evaluation_result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

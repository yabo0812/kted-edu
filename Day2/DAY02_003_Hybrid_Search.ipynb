{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  하이브리드 검색\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Langsmith tracing 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
    "import os\n",
    "print(os.getenv('LANGSMITH_TRACING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## RAG 검색기\n",
    "\n",
    "1. **의미론적 검색 (Semantic Search)**\n",
    "    - Vector Store를 기반으로 한 검색 방식으로, 텍스트의 의미적 유사성을 고려하여 검색을 수행함\n",
    "    - 임베딩 벡터 간의 유사도를 계산하여 의미적으로 관련성이 높은 문서를 찾아내는 특징이 있음\n",
    "    - 동의어나 문맥적 의미를 파악할 수 있어 자연어 질의에 효과적임\n",
    "\n",
    "1. **키워드 검색 (Keyword Search)**\n",
    "    - BM25와 같은 전통적인 검색 알고리즘을 사용하여 키워드 매칭을 기반으로 검색을 수행함\n",
    "    - 정확한 단어나 구문 매칭에 강점이 있으며, 계산 효율성이 높은 특징을 가짐\n",
    "    - 직접적인 키워드 일치를 찾는 데 유용하나, 의미적 유사성을 파악하는 데는 한계가 있음\n",
    "\n",
    "1. **하이브리드 검색 (Hybrid Search)**\n",
    "    - 키워드 기반 검색과 의미론적 검색을 결합한 방식으로, EnsembleRetriever를 통해 구현됨\n",
    "    - 두 검색 방식의 장점을 활용하여 더 정확하고 포괄적인 검색 결과를 제공함\n",
    "    - 정확한 키워드 매칭과 의미적 연관성을 모두 고려하여 검색 성능을 향상시키는 특징이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) **Semantic Search** (의미론적 검색) \n",
    "\n",
    "- **의미론적 검색**은 텍스트의 **벡터 표현**을 활용해 의미적 유사성 기반 검색 수행\n",
    "- **Vector Store**에 저장된 임베딩 벡터 간 **유사도 계산**으로 관련 문서 검색\n",
    "- 검색어와 문서 간의 **문맥적 의미**와 **동의어 관계**를 효과적으로 파악\n",
    "- **자연어 질의**에 강점을 보이며 기존 키워드 검색의 한계를 보완\n",
    "- 전통적인 검색 방식과 달리 **의미 기반 매칭**으로 더 정확하고 포괄적인 검색 결과 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 벡터 저장소 초기화`\n",
    "- cosine distance 기준으로 인덱싱 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 데이터 로드\n",
    "def load_text_files(txt_files):\n",
    "    data = []\n",
    "\n",
    "    for text_file in txt_files:\n",
    "        loader = TextLoader(text_file, encoding='utf-8')\n",
    "        data += loader.load()\n",
    "\n",
    "    return data\n",
    "\n",
    "korean_txt_files = glob(os.path.join('data', '*_KR.md')) \n",
    "korean_data = load_text_files(korean_txt_files)\n",
    "\n",
    "# 문장을 구분하여 분할 - 정규표현식 사용 (문장 구분자: 마침표, 느낌표, 물음표 다음에 공백이 오는 경우)\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",    # TikToken 인코더 이름\n",
    "    separators=['\\n\\n', '\\n', r'(?<=[.!?])\\s+'],   # 구분자\n",
    "    chunk_size=300,            # 문서 분할 크기\n",
    "    chunk_overlap=50,          # 문서 분할 중첩  \n",
    "    is_separator_regex=True,      # 구분자가 정규식인지 여부\n",
    "    keep_separator=True,          # 구분자 유지 여부\n",
    ")\n",
    "\n",
    "korean_chunks = text_splitter.split_documents(korean_data)\n",
    "\n",
    "print(\"한국어 청크 수:\", len(korean_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(korean_chunks):\n",
    "    print(f\"[{i}]\", doc.page_content)\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "# Document 객체에 메타데이터 추가\n",
    "\n",
    "korean_docs = []\n",
    "\n",
    "for chunk in korean_chunks:\n",
    "    doc = Document(page_content=chunk.page_content, metadata=chunk.metadata)\n",
    "    doc.metadata['company'] = '테슬라' if '테슬라' in doc.metadata['source'] else '리비안'\n",
    "    doc.metadata['language'] = 'ko'\n",
    "    doc.page_content = f\"<Document>\\n{doc.page_content}\\n</Document>\\n<Source>이 문서는 미국 전기차 회사인 '{doc.metadata['company']}'에 대한 문서입니다.</Source>\"   \n",
    "    korean_docs.append(doc)\n",
    "\n",
    "print(\"한국어 문서 수:\", len(korean_docs))\n",
    "print(\"=\"*200)\n",
    "print(korean_docs[0].metadata)\n",
    "print(\"-\"*200)\n",
    "print(korean_docs[0].page_content)\n",
    "print(\"=\"*200)\n",
    "print(korean_docs[-1].metadata)\n",
    "print(\"-\"*200)\n",
    "print(korean_docs[-1].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# korean_docs 파일을 jsonlines 파일로 저장\n",
    "def save_jsonlines(docs, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for doc in docs:\n",
    "            f.write(json.dumps(doc.model_dump_json(), ensure_ascii=False) + '\\n')\n",
    "\n",
    "save_jsonlines(korean_docs, 'data/korean_docs_final.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI Embeddings 모델을 로드\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Chroma 벡터 저장소 생성하기\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=korean_docs,\n",
    "    embedding=embeddings,    \n",
    "    collection_name=\"db_korean_cosine_metadata\", \n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_metadata = {'hnsw:space': 'cosine'}, # l2, ip, cosine 중에서 선택 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 문서 수 확인\n",
    "print(\"Chroma DB에 저장된 문서 수:\", chroma_db._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 벡터 저장소 로드`\n",
    "- 미리 인덱싱해서 저장해 둔 저장소를 가져와서 사용\n",
    "- 이때 기존에 사용한 임베딩 모델을 초기화 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소 로드 \n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"db_korean_cosine_metadata\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 문서 수 확인\n",
    "print(\"Chroma DB에 저장된 문서 수:\", chroma_db._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Semantic Search 실행`\n",
    "- 벡터 저장소 검색기 객체 활용\n",
    "- 임베딩 벡터 간의 유사도를 기반으로 문서 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기 지정하여 테스트 \n",
    "chroma_k_retriever = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 2},\n",
    ")\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chroma_k_retriever.invoke(query)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) **Keyword Search** (키워드 검색) \n",
    "\n",
    "- **키워드 검색**은 **BM25** 등 전통적 알고리즘 기반의 단어 매칭 방식\n",
    "- 정확한 **단어/구문 매칭**에 강점이 있으며 **계산 효율성**이 우수함\n",
    "- **직접적인 키워드** 검색에는 효과적이나 의미적 연관성 파악에는 제한적\n",
    "- 구현이 단순하고 **처리 속도가 빠르다**는 장점이 있음\n",
    "- 정확한 키워드 매칭이 필요한 경우에 적합하나 **의미론적 검색의 보완**이 필요함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) BM25 검색기 생성`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BM25: TF-IDF (Term Frequency-Inverse Document Frequency)의 확장된 버전\n",
    "- `rank_bm25` 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소에 저정한 문서 객체를 로드하여 확인\n",
    "chroma_db.get().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 검색기 생성을 위해 문서 객체를 로드\n",
    "documents = chroma_db.get()[\"documents\"]\n",
    "metadatas = chroma_db.get()[\"metadatas\"]\n",
    "\n",
    "# Document 객체로 변환\n",
    "from langchain_core.documents import Document\n",
    "docs = [Document(page_content=content, metadata=meta) for content, meta in zip(documents, metadatas)]\n",
    "\n",
    "print(\"문서의 수:\" , len(docs))\n",
    "print(\"=\" * 200)\n",
    "for doc in docs[:3]:\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 200)\n",
    "    print(doc.metadata)\n",
    "    print(\"=\" * 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# BM25 검색기 생성\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "\n",
    "# BM25 검색기를 사용하여 검색\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "\n",
    "retrieved_docs = bm25_retriever.invoke(query)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 점수를 확인 - \"리비안은\" 라는 단어가 쿼리에 포함되어 있지 않아 검색 결과가 없음\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "tokenized_query = query.split()\n",
    "print(tokenized_query)\n",
    "print(\"=\"*200)\n",
    "\n",
    "# 문서의 BM25 점수 확인\n",
    "doc_scores = bm25_retriever.vectorizer.get_scores(tokenized_query)\n",
    "\n",
    "# 문서의 BM25 점수를 내림차순으로 정렬\n",
    "doc_scores_sorted = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 상위 5개 문서의 인덱스와 점수를 출력\n",
    "for idx, score in doc_scores_sorted[:5]:\n",
    "    print(f\"[{idx}] {docs[idx].page_content}\")\n",
    "    print(f\"BM25 Score: {score}\")\n",
    "    print(\"-\"*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 의미를 갖는 쿼리로 변경하여 다시 검색 \n",
    "query = \"리비안이 설립된 연도는?\"\n",
    "\n",
    "retrieved_docs = bm25_retriever.invoke(query)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 점수를 확인 - \"설립된\" 이라는 단어가 쿼리에 포함되어 있어 검색 결과가 있음\n",
    "query = \"리비안이 설립된 연도는?\"\n",
    "tokenized_query = query.split()\n",
    "print(tokenized_query)\n",
    "print(\"=\"*200)\n",
    "\n",
    "# 문서의 BM25 점수 확인\n",
    "doc_scores = bm25_retriever.vectorizer.get_scores(tokenized_query)\n",
    "\n",
    "# 문서의 BM25 점수를 내림차순으로 정렬\n",
    "doc_scores_sorted = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 상위 5개 문서의 인덱스와 점수를 출력\n",
    "for idx, score in doc_scores_sorted[:5]:\n",
    "    print(f\"[{idx}] {docs[idx].page_content}\")\n",
    "    print(f\"BM25 Score: {score}\")\n",
    "    print(\"-\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) kiwi 한국어 토크나이저`\n",
    "- `kiwipiepy` 설치 필요 (pip install kiwipiepy / uv add kiwipiepy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 토크나이저를 사용하여 문장을 토큰화\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "kiwi_model = Kiwi()\n",
    "\n",
    "print(kiwi_model.analyze(\"리비안은 언제 사업을 시작했나요?\"))\n",
    "print(\"=\"*200)\n",
    "print(kiwi_model.analyze(\"리비안이 설립된 연도는?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kiwi_model.tokenize(\"테슬라는 언제 설립되었나요?\"))\n",
    "print(\"=\"*200)\n",
    "print(kiwi_model.tokenize(\"테슬라가 설립된 연도는?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어를 추가 \n",
    "kiwi_model.add_user_word('리비안', 'NNP')  # NNP: 고유명사\n",
    "\n",
    "print(kiwi_model.analyze(\"리비안은 언제 사업을 시작했나요?\"))\n",
    "print(\"=\"*200)\n",
    "print(kiwi_model.analyze(\"리비안이 설립된 연도는?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 토크나이저를 사용하여 문장을 토큰화하는 함수를 정의 \n",
    "\n",
    "def bm25_kiwi_process_func(text):\n",
    "    \"\"\"\n",
    "    BM25Retriever에서 사용할 전처리 함수\n",
    "    한국어 토크나이저를 사용하여 문장을 토큰화 (Kiwi 사용)\n",
    "    :param text: 토큰화할 문장\n",
    "    \"\"\"\n",
    "    # 한국어 토크나이저를 사용하여 문장을 토큰화\n",
    "    return [t.form for t in kiwi_model.tokenize(text)]\n",
    "\n",
    "\n",
    "# BM25Retriever 객체 생성\n",
    "bm25_kiwi_retriever = BM25Retriever.from_documents(\n",
    "    documents=docs,\n",
    "    preprocess_func=bm25_kiwi_process_func, # 전처리 함수 지정\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전에 사용한 검색어를 입력하여 문서를 검색\n",
    "query = \"리비안이 설립된 연도는?\"\n",
    "\n",
    "retrieved_docs = bm25_kiwi_retriever.invoke(query)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 점수를 확인\n",
    "query = \"리비안이 설립된 연도는?\"\n",
    "\n",
    "tokenized_query = [t.form for t in kiwi_model.tokenize(query)]\n",
    "print(tokenized_query)\n",
    "print(\"=\"*200)\n",
    "\n",
    "# 문서의 BM25 점수 확인\n",
    "doc_scores = bm25_kiwi_retriever.vectorizer.get_scores(tokenized_query)\n",
    "\n",
    "# 문서의 BM25 점수를 내림차순으로 정렬\n",
    "doc_scores_sorted = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 상위 5개 문서의 인덱스와 점수를 출력\n",
    "for idx, score in doc_scores_sorted[:5]:\n",
    "    print(f\"[{idx}] {docs[idx].page_content}\")\n",
    "    print(f\"BM25 Score: {score}\")\n",
    "    print(\"-\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) **Hybrid Search** (하이브리드 검색) \n",
    "\n",
    "- **하이브리드 검색**은 **키워드 검색**과 **의미론적 검색**을 **EnsembleRetriever**로 통합\n",
    "- 정확한 **키워드 매칭**과 **의미적 유사성**을 동시에 고려하여 검색 수행\n",
    "- 두 검색 방식의 **장점을 결합**하여 더 포괄적이고 정확한 결과 도출\n",
    "- 검색 성능 향상을 위해 각 방식의 **가중치 조정**이 가능함\n",
    "- 키워드와 의미 기반 검색의 **시너지 효과**로 더 향상된 검색 성능 실현 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "# 앙상블 검색기 생성\n",
    "ensemble_retrievers = [chroma_k_retriever, bm25_kiwi_retriever]\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=ensemble_retrievers, \n",
    "    weights=[0.5, 0.5]          # 각 검색기의 가중치\n",
    ")\n",
    "\n",
    "# 검색기를 사용하여 검색\n",
    "query = \"리비안이 설립된 연도는?\"\n",
    "\n",
    "retrieved_docs = ensemble_retriever.invoke(query)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 검색 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) **테스트 데이터** \n",
    "\n",
    "- 합성된 데이터는 **품질 검증**과 **수동 수정** 과정을 거쳐 정제\n",
    "- 테스트용 데이터는 **다양한 유형의 질문**과 **답변 패턴**을 포함해야 함\n",
    "- 신뢰할 수 있는 검색 성능 평가를 위해 **고품질 테스트 데이터** 확보가 중요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존에 생성해 둔 테스트셋 로드\n",
    "# 테스트셋 로드\n",
    "import pandas as pd\n",
    "df_qa_test = pd.read_excel(\"data/testset.xlsx\")\n",
    "\n",
    "print(f\"테스트셋: {df_qa_test.shape[0]}개 문서\")\n",
    "df_qa_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) **Information Retrieval 평가지표**\n",
    "\n",
    "- K-RAG 패키지 사용 (pip install krag)\n",
    "- Hit Rate, MRR, mAP@k, NDCG@k 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 테스트 데이터셋의 컨텍스트를 문서 객체로 변환`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋의 특정 행에 있는 컨텍스트 데이터를 Document 객체 리스트로 변환\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "context_docs = []\n",
    "for i, row in df_qa_test.iterrows():\n",
    "    row_docs = []\n",
    "    for doc in eval(row['reference_contexts']):\n",
    "        row_docs.append(Document(page_content=doc))\n",
    "\n",
    "    context_docs.append(row_docs)\n",
    "\n",
    "\n",
    "print(f\"컨텍스트 문서: {len(context_docs)}개 문서\")\n",
    "print(\"=\"*200)\n",
    "print(context_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# korean_docs 문서가 저장되어 있는 jsonlines 파일을 로드\n",
    "korean_docs = []\n",
    "with open('data/korean_docs_final.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        doc = json.loads(line)\n",
    "        korean_docs.append(Document.model_validate_json(doc))\n",
    "        \n",
    "print(f\"한국어 문서: {len(korean_docs)}개 문서\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 키워드 검색 (Kiwi 토크나이저 + BM25 검색기)`\n",
    "\n",
    "- krag 파키지 설지 : https://pypi.org/project/krag/\n",
    "- pip install krag 또는 uv pip install krag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krag.tokenizers import KiwiTokenizer\n",
    "from krag.retrievers import KiWiBM25RetrieverWithScore\n",
    "\n",
    "# 한국어 토크나이저 생성\n",
    "kiwi_tokenizer = KiwiTokenizer(model_type='knlm', typos='basic')\n",
    "\n",
    "# '리비안' 단어 추가\n",
    "kiwi_tokenizer.kiwi.add_user_word('리비안', 'NNP')  # NNP: 고유명사     \n",
    "\n",
    "# 토큰화 테스트\n",
    "print(kiwi_tokenizer.tokenize(\"리비안은 언제 사업을 시작했나요?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 검색기 초기화 (k=3)\n",
    "retriever_bm25_kiwi = KiWiBM25RetrieverWithScore(\n",
    "    documents=korean_docs, \n",
    "    kiwi_tokenizer=kiwi_tokenizer, \n",
    "    k=3, \n",
    ") \n",
    "\n",
    "# 검색기 테스트\n",
    "query = \"리비안이 설립된 연도는?\"\n",
    "retrieved_docs = retriever_bm25_kiwi.invoke(query)\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 점수를 확인\n",
    "query = \"리비안이 설립된 연도는?\"\n",
    "\n",
    "tokenized_query = [t.form for t in kiwi_tokenizer.kiwi.tokenize(query)]\n",
    "print(tokenized_query)\n",
    "print(\"=\"*200)\n",
    "\n",
    "# 문서의 BM25 점수 확인\n",
    "doc_scores = retriever_bm25_kiwi.bm25_retriever.vectorizer.get_scores(tokenized_query)\n",
    "\n",
    "# 문서의 BM25 점수를 내림차순으로 정렬\n",
    "doc_scores_sorted = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 상위 5개 문서의 인덱스와 점수를 출력\n",
    "for idx, score in doc_scores_sorted[:5]:\n",
    "    print(f\"[{idx}] {korean_docs[idx].page_content}\")\n",
    "    print(f\"BM25 Score: {score}\")\n",
    "    print(\"-\"*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 검색기를 사용하여 문서 검색\n",
    "question = df_qa_test['user_input'].iloc[0]\n",
    "print(\"질문:\", question)\n",
    "print(\"=\"*200)\n",
    "context = df_qa_test['reference_contexts'].iloc[0]\n",
    "print(\"관련 문서:\", context)\n",
    "print(\"=\"*200)\n",
    "\n",
    "# BM25 검색\n",
    "retrieved_docs = retriever_bm25_kiwi.invoke(question)\n",
    "\n",
    "# 검색 결과 출력 \n",
    "for doc in retrieved_docs:\n",
    "    print(f\"BM25 점수: {doc.metadata[\"bm25_score\"]:.2f}\")    \n",
    "    print(f\"\\n{doc.page_content}\\n[출처: {doc.metadata['company']}]\")\n",
    "    print(\"-\"*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 테스트 데이터셋에 대하여 평가지표 계산\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from krag.evaluators import RougeOfflineRetrievalEvaluators\n",
    "\n",
    "def evaluate_qa_test(df_qa_test: pd.DataFrame, retriever: BaseRetriever, k=2) -> dict:\n",
    "    \"\"\"\n",
    "    테스트 데이터셋에 대한 검색 결과 평가\n",
    "    \"\"\"\n",
    "\n",
    "    context_docs = []\n",
    "    retrieved_docs = []\n",
    "\n",
    "    df_test = df_qa_test.copy()\n",
    "    \n",
    "    for idx, _ in df_test.iterrows():\n",
    "        question = df_test['user_input'].iloc[idx]\n",
    "        context_doc = [Document(page_content=doc) for doc in eval(df_test['reference_contexts'].iloc[idx])]\n",
    "        context_docs.append(context_doc)\n",
    "        retrieved_doc = retriever.invoke(question)  \n",
    "        retrieved_docs.append(retrieved_doc)  \n",
    "\n",
    "\n",
    "    # 평가자 인스턴스 생성\n",
    "    evaluator = RougeOfflineRetrievalEvaluators(\n",
    "        actual_docs=context_docs,\n",
    "        predicted_docs=retrieved_docs, \n",
    "        match_method='rouge2',\n",
    "        threshold=0.8,\n",
    "    )\n",
    "\n",
    "\n",
    "    # 평가지표 계산\n",
    "    precision = evaluator.calculate_precision(k=k)['micro_precision']\n",
    "    recall = evaluator.calculate_recall(k=k)['micro_recall']\n",
    "    f1_score = evaluator.calculate_f1_score(k=k)['micro_f1']\n",
    "    hit_rate = evaluator.calculate_hit_rate(k=k)['hit_rate']\n",
    "    mrr = evaluator.calculate_mrr(k=k)['mrr']\n",
    "    map_score = evaluator.calculate_map(k=k)['map']\n",
    "    ndcg = evaluator.calculate_ndcg(k=k)['ndcg']\n",
    "\n",
    "    print(f\"K={k}\")\n",
    "    print(\"-\"*200)\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall: {recall:.3f}\")\n",
    "    print(f\"F1 Score: {f1_score:.3f}\")\n",
    "    print(f\"Hit Rate: {hit_rate:.3f}\")\n",
    "    print(f\"MRR: {mrr:.3f}\")\n",
    "    print(f\"MAP: {map_score:.3f}\")\n",
    "    print(f\"NDCG: {ndcg:.3f}\")\n",
    "    print(\"=\"*200)\n",
    "    print()\n",
    "\n",
    "    result = {\n",
    "        'k': k,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'hit_rate': hit_rate,\n",
    "        'mrr': mrr,\n",
    "        'map': map_score,\n",
    "        'ndcg': ndcg,\n",
    "        \n",
    "    }\n",
    "\n",
    "    return pd.Series(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=1)\n",
    "retriever_bm25_kiwi.k = 1\n",
    "result_bm25_k1 = evaluate_qa_test(df_qa_test, retriever_bm25_kiwi, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=2)\n",
    "retriever_bm25_kiwi.k = 2\n",
    "result_bm25_k2 = evaluate_qa_test(df_qa_test, retriever_bm25_kiwi, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=3)\n",
    "retriever_bm25_kiwi.k = 3\n",
    "result_bm25_k3 = evaluate_qa_test(df_qa_test, retriever_bm25_kiwi, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=4)\n",
    "retriever_bm25_kiwi.k = 4\n",
    "result_bm25_k4 = evaluate_qa_test(df_qa_test, retriever_bm25_kiwi, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=5)\n",
    "retriever_bm25_kiwi.k = 5\n",
    "result_bm25_k5 = evaluate_qa_test(df_qa_test, retriever_bm25_kiwi, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 시맨틱 검색 (Chroma 벡터저장소 검색기)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma 검색기 초기화\n",
    "retriever_chroma_db = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=1)\n",
    "result_chroma_db_k1 = evaluate_qa_test(df_qa_test, retriever_chroma_db, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=2)\n",
    "result_chroma_db_k2 = evaluate_qa_test(df_qa_test, retriever_chroma_db, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=3)\n",
    "result_chroma_db_k3 = evaluate_qa_test(df_qa_test, retriever_chroma_db, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=4)\n",
    "result_chroma_db_k4 = evaluate_qa_test(df_qa_test, retriever_chroma_db, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=5)\n",
    "result_chroma_db_k5 = evaluate_qa_test(df_qa_test, retriever_chroma_db, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) 하이브리드 검색 (EnsembleRetriever 사용)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "retriever_bm25_kiwi.k = 5\n",
    "ensemble_retrievers = [retriever_chroma_db, retriever_bm25_kiwi]\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=ensemble_retrievers, \n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# 평가 (k=1)\n",
    "result_ensemble_k1 = evaluate_qa_test(df_qa_test, ensemble_retriever, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=2)\n",
    "result_ensemble_k2 = evaluate_qa_test(df_qa_test, ensemble_retriever, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=3)\n",
    "result_ensemble_k3 = evaluate_qa_test(df_qa_test, ensemble_retriever, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=4)\n",
    "result_ensemble_k4 = evaluate_qa_test(df_qa_test, ensemble_retriever, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 (k=5)\n",
    "result_ensemble_k5 = evaluate_qa_test(df_qa_test, ensemble_retriever, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) 검색 성능 비교`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3가지 검색기의 평가 결과를 하나의 DataFrame으로 결합 (각 검색기별로 k=1, 2, 3, 4, 5에 대한 결과 포함)\n",
    "import pandas as pd\n",
    "\n",
    "# 결과를 딕셔너리 리스트로 만들기\n",
    "results_data = [\n",
    "    {'retriever': 'BM25-Kiwi', 'k': 1, **result_bm25_k1.to_dict()},\n",
    "    {'retriever': 'Chroma-DB', 'k': 1, **result_chroma_db_k1.to_dict()},\n",
    "    {'retriever': 'Ensemble', 'k': 1, **result_ensemble_k1.to_dict()},\n",
    "    {'retriever': 'BM25-Kiwi', 'k': 2, **result_bm25_k2.to_dict()},\n",
    "    {'retriever': 'Chroma-DB', 'k': 2, **result_chroma_db_k2.to_dict()},\n",
    "    {'retriever': 'Ensemble', 'k': 2, **result_ensemble_k2.to_dict()},\n",
    "    {'retriever': 'BM25-Kiwi', 'k': 3, **result_bm25_k3.to_dict()},\n",
    "    {'retriever': 'Chroma-DB', 'k': 3, **result_chroma_db_k3.to_dict()},\n",
    "    {'retriever': 'Ensemble', 'k': 3, **result_ensemble_k3.to_dict()},\n",
    "    {'retriever': 'BM25-Kiwi', 'k': 4, **result_bm25_k4.to_dict()},\n",
    "    {'retriever': 'Chroma-DB', 'k': 4, **result_chroma_db_k4.to_dict()},\n",
    "    {'retriever': 'Ensemble', 'k': 4, **result_ensemble_k4.to_dict()},\n",
    "    {'retriever': 'BM25-Kiwi', 'k': 5, **result_bm25_k5.to_dict()},\n",
    "    {'retriever': 'Chroma-DB', 'k': 5, **result_chroma_db_k5.to_dict()},\n",
    "    {'retriever': 'Ensemble', 'k': 5, **result_ensemble_k5.to_dict()}\n",
    "]\n",
    "\n",
    "# 데이터프레임 생성\n",
    "results = pd.DataFrame(results_data)\n",
    "\n",
    "# 결과 표시\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 검색기들의 성능 비교를 위한 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 시각화 스타일 설정\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 검색기별로 각 평가지표를 시각화\n",
    "def plot_retriever_performance(results, metric):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=results, x='k', y=metric, hue='retriever')\n",
    "    plt.title(f'{metric} by Retriever and k')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend(title='Retriever')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Precision 시각화\n",
    "plot_retriever_performance(results, 'precision')\n",
    "\n",
    "# Recall 시각화\n",
    "plot_retriever_performance(results, 'recall')\n",
    "\n",
    "# F1 Score 시각화\n",
    "plot_retriever_performance(results, 'f1_score')\n",
    "\n",
    "# Hit Rate 시각화\n",
    "plot_retriever_performance(results, 'hit_rate')\n",
    "\n",
    "# MRR 시각화\n",
    "plot_retriever_performance(results, 'mrr')\n",
    "\n",
    "# MAP 시각화\n",
    "plot_retriever_performance(results, 'map')\n",
    "\n",
    "# NDCG 시각화\n",
    "plot_retriever_performance(results, 'ndcg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LangChainì˜ ê°œë…ê³¼ ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ì´í•´\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChainì´ë€ \n",
    "\n",
    "í•µì‹¬ ë‚´ìš©:\n",
    "- **LangChain**ì€ LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬\n",
    "\n",
    "- **Chain**ì€ ì‘ì—…ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” íŒŒì´í”„ë¼ì¸ êµ¬ì¡°ë¥¼ ì œê³µ\n",
    "\n",
    "- **Agent**ëŠ” ììœ¨ì  ì˜ì‚¬ê²°ì •ì´ ê°€ëŠ¥í•œ ì‹¤í–‰ ë‹¨ìœ„\n",
    "\n",
    "ê²°ë¡ :\n",
    "- LangChainì€ Chainê³¼ Agentë¼ëŠ” ë‘ ê°€ì§€ í•µì‹¬ ê¸°ëŠ¥ì„ í†µí•´ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ íš¨ìœ¨ì ìœ¼ë¡œ ì§€ì›\n",
    "\n",
    "\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"https://python.langchain.com/svg/langchain_stack_112024_dark.svg\" \n",
    "            alt=\"langchain_stack\" \n",
    "            width=\"600\" \n",
    "            style=\"border: 0;\">\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain ì»´í¬ë„ŒíŠ¸ \n",
    "\n",
    "- LangChain **ì£¼ìš” ì»´í¬ë„ŒíŠ¸**: LLM/ChatModel, Prompt, Memory, Tool, Document Loader, Text Splitter, Embedding, Vectorstore\n",
    "\n",
    "- **ì–¸ì–´ ì²˜ë¦¬ ê¸°ëŠ¥**ì€ LLM/ChatModelì´ ì¤‘ì‹¬ì´ ë˜ë©°, Promptì™€ Memoryë¡œ ëŒ€í™”ë¥¼ ê´€ë¦¬\n",
    "\n",
    "- **ë¬¸ì„œ ì²˜ë¦¬ì™€ ê²€ìƒ‰**ì€ Document Loader, Text Splitter, Embedding, Vectorstoreê°€ ë‹´ë‹¹\n",
    "\n",
    "- **ëª¨ë“ˆì„±**ì´ í•µì‹¬ íŠ¹ì§•ìœ¼ë¡œ, ë…ë¦½ì ì¸ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì¡°í•©í•´ RAGì™€ ê°™ì€ ë³µì¡í•œ ì‹œìŠ¤í…œì„ êµ¬í˜„ ê°€ëŠ¥ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í™˜ê²½ ì„¤ì • ë° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ëª¨ë¸ (Models)\n",
    "- LLM, ChatModel ë“±ìœ¼ë¡œ êµ¬ë¶„\n",
    "- OpenAI, Anthropic, Google ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì„ ì§€ì›\n",
    "- í…ìŠ¤íŠ¸ ìƒì„±, ëŒ€í™”, ìš”ì•½ ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ìƒì„±\n",
    "model = ChatOpenAI(model=\"gpt-4.1-2025-04-14\")\n",
    "\n",
    "# ëª¨ë¸ì— ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ê¸°\n",
    "response = model.invoke(\"ì•ˆë…•í•˜ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 10, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'id': 'chatcmpl-BlVJ6mjfdsREiPdDKRmf62ObkdYEV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5f30b6e7-67d6-46fb-8c3e-c427948b5b73-0', usage_metadata={'input_tokens': 10, 'output_tokens': 12, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‘ë‹µ ê°ì²´(AIMessage): ë©”ì‹œì§€(content)ì™€ ë©”íƒ€ë°ì´í„°(response_metadata ë“±)ë¥¼ í¬í•¨\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€:  ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# ì‘ë‹µ ê°ì²´ì˜ ë©”ì‹œì§€ ë‚´ìš© ì¶œë ¥\n",
    "print(\"ë‹µë³€: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë©”íƒ€ë°ì´í„°:  {'token_usage': {'completion_tokens': 12, 'prompt_tokens': 10, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'id': 'chatcmpl-BlVJ6mjfdsREiPdDKRmf62ObkdYEV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "# ì‘ë‹µ ê°ì²´ì˜ ë©”íƒ€ë°ì´í„° ì¶œë ¥\n",
    "print(\"ë©”íƒ€ë°ì´í„°: \", response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ë©”ì‹œì§€ (Messages)\n",
    "- Chat Modelì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í†µí•©ëœ ë©”ì‹œì§€ í˜•ì‹ì„ ì œê³µ\n",
    "- ê° ëª¨ë¸ ì œê³µìì˜ íŠ¹ì • ë©”ì‹œì§€ í˜•ì‹ì„ ì‹ ê²½ ì“°ì§€ ì•Šê³ ë„ ë‹¤ì–‘í•œ ì±„íŒ… ëª¨ë¸ì„ í™œìš© ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. HumanMessage`\n",
    "- ì‚¬ìš©ì ì—­í• ì— í•´ë‹¹ (user, human ë“±)\n",
    "- ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€:  \"Glory\"ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ë©´ \"ì˜ê´‘\"ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# ì‚¬ìš©ì ë©”ì‹œì§€ ìƒì„±\n",
    "human_message = HumanMessage(content=\"Gloryë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# ë²ˆì—­ ìš”ì²­ ë° ì‘ë‹µ ë°›ê¸°\n",
    "response = model.invoke([human_message])  # ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬\n",
    "\n",
    "# ë‹µë³€ ì¶œë ¥\n",
    "print(\"ë‹µë³€: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Glory\"ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ë©´ \"ì˜ê´‘\"ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 17, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-BlRD9hqjNiA7P9hDzdXhQz2ba7z4V', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e652adee-939b-46aa-887e-1818160e0147-0', usage_metadata={'input_tokens': 17, 'output_tokens': 17, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë¬¸ìì—´ì„ ì…ë ¥í•˜ë©´, ìë™ìœ¼ë¡œ HumanMessageë¡œ ë³€í™˜í•˜ì—¬ ìš”ì²­\n",
    "model.invoke(\"Gloryë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. AIMessage`\n",
    "- AI ëª¨ë¸ì˜ ì‘ë‹µì„ í‘œí˜„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Glory\"ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ë©´ \"ì˜ê´‘\"ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 17, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-BlRD8SywBQp8sDT1KPLAm14K4eFkJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c50ee79b-df74-4c8d-87fb-0e89a92da7ec-0', usage_metadata={'input_tokens': 17, 'output_tokens': 17, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI ëª¨ë¸ì˜ ì‘ë‹µ ê°ì²´ë¥¼ ì¶œë ¥\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Glory\"ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ë©´ \"ì˜ê´‘\"ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ ì‘ë‹µ í…ìŠ¤íŠ¸ ë¶€ë¶„ì„ ì¶œë ¥\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 17,\n",
       " 'output_tokens': 17,\n",
       " 'total_tokens': 34,\n",
       " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       " 'output_token_details': {'audio': 0, 'reasoning': 0}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. SystemMessage`\n",
    "- ì‹œìŠ¤í…œ ì—­í• ì— í•´ë‹¹ (system, developer ë“±)\n",
    "- AI ëª¨ë¸ì˜ ë™ì‘ê³¼ ì œì•½ì‚¬í•­ì„ ì •ì˜í•˜ëŠ”ë° ì‚¬ìš©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='ë‹¹ì‹ ì€ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìƒì„±\n",
    "system_msg = SystemMessage(\n",
    "    content=\"ë‹¹ì‹ ì€ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    ")\n",
    "\n",
    "# ë©”ì‹œì§€ ê°ì²´ í™•ì¸\n",
    "system_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€:  \"Glory\"ì˜ í•œêµ­ì–´ ë²ˆì—­ì€ \"ì˜ê´‘\"ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ë²ˆì—­ ìš”ì²­ (HumanMessage)ê³¼ ì‹œìŠ¤í…œ ë©”ì‹œì§€(SystemMessage)ë¥¼ í•¨ê»˜ ì‚¬ìš©\n",
    "human_message = HumanMessage(content=\"Glory\")\n",
    "messages = [system_msg, human_message]\n",
    "\n",
    "# ëª¨ë¸ì— ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ì‘ë‹µ ë°›ê¸°\n",
    "response = model.invoke(messages)\n",
    "\n",
    "# ë‹µë³€ ì¶œë ¥\n",
    "print(\"ë‹µë³€: \", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Prompt Template)\n",
    "- í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í†µí•´ ì¼ê´€ëœ ì…ë ¥ í˜•ì‹ì„ ì œê³µ\n",
    "    1. ì‚¬ìš©ìì˜ ì…ë ¥ê³¼ íŒŒë¼ë¯¸í„°ë¥¼ ì–¸ì–´ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬\n",
    "    2. ì–¸ì–´ ëª¨ë¸ì—ê²Œ ì „ë‹¬í•  ì§€ì‹œë¬¸ì„ ë§Œë“œëŠ” í‹€\n",
    "- ë³€ìˆ˜ë¥¼ í¬í•¨í•œ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±ì´ ê°€ëŠ¥\n",
    "    1. ëª¨ë“  í…œí”Œë¦¿ì€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì…ë ¥ì„ ë°›ì•„ì„œ ì²˜ë¦¬\n",
    "    2. ì¶œë ¥ì€ PromptValue í˜•íƒœë¡œ ë°˜í™˜ë˜ë©°, ì´ëŠ” ë¬¸ìì—´ì´ë‚˜ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. ë¬¸ìì—´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (String PromptTemplate)`\n",
    "- ê°€ì¥ ê¸°ë³¸ì ì¸ í˜•íƒœ\n",
    "- ë‹¨ì¼ ë¬¸ìì—´ì„ í˜•ì‹í™”í•˜ëŠ”ë° ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='ê³ ì–‘ì´ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•´ì¤˜')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# í…œí”Œë¦¿ ìƒì„±\n",
    "# \"{topic}ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•´ì¤˜\"ë¼ëŠ” í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬\n",
    "# topicì´ë¼ëŠ” ë³€ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±\n",
    "template = PromptTemplate.from_template(\"{topic}ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•´ì¤˜\")\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "# \"ê³ ì–‘ì´\"ë¼ëŠ” ì£¼ì œë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "# invoke ë©”ì„œë“œë¥¼ í†µí•´ í…œí”Œë¦¿ì— ê°’ì„ ì „ë‹¬\n",
    "prompt = template.invoke({\"topic\": \"ê³ ì–‘ì´\"})\n",
    "\n",
    "# í…œí”Œë¦¿ ì¶œë ¥\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ChatPromptTemplate)`\n",
    "- ì—¬ëŸ¬ ë©”ì‹œì§€ë¥¼ í¬í•¨í•˜ëŠ” ëŒ€í™”í˜• í…œí”Œë¦¿ì„ ë§Œë“¤ ë•Œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤', additional_kwargs={}, response_metadata={}), HumanMessage(content='ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ì±„íŒ… í…œí”Œë¦¿ ìƒì„±\n",
    "# ì—¬ê¸°ì„œëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í¬í•¨í•˜ì—¬ ì •ì˜\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤\"),\n",
    "        (\"user\", \"{subject}ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "prompt = template.invoke({\"subject\": \"ì¸ê³µì§€ëŠ¥\"})\n",
    "\n",
    "# ì¶œë ¥\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë” (MessagesPlaceholder)`\n",
    "- ê¸°ì¡´ ë©”ì‹œì§€ ëª©ë¡ì„ í…œí”Œë¦¿ì˜ íŠ¹ì • ìœ„ì¹˜ì— ì‚½ì…í•  ë•Œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ì œ ì´ë¦„ì€ ìŠ¤í‹°ë¸Œì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ì œ ì´ë¦„ì„ ê¸°ì–µí•˜ë‚˜ìš”?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ìˆëŠ” í…œí”Œë¦¿\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤\"),\n",
    "        MessagesPlaceholder(\n",
    "            \"chat_history\"\n",
    "        ),  # ì±„íŒ… ê¸°ë¡ì„ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ì‚¬ìš© (ì˜ˆ: ì´ì „ ëŒ€í™” ë‚´ìš©) -> ì´ ìœ„ì¹˜ì— ë©”ì‹œì§€ ëª©ë¡ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŒ\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "prompt = template.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ì œ ì´ë¦„ì€ ìŠ¤í‹°ë¸Œì…ë‹ˆë‹¤.\"),\n",
    "            AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\"),\n",
    "            HumanMessage(content=\"ì œ ì´ë¦„ì„ ê¸°ì–µí•˜ë‚˜ìš”?\"),\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# ì¶œë ¥\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ì¶œë ¥ íŒŒì„œ (Output Parser)\n",
    "1. **ì—­í• ê³¼ ê¸°ëŠ¥**\n",
    "    - ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜\n",
    "    - ì±„íŒ… ëª¨ë¸ê³¼ LLMì˜ ì¶œë ¥ì„ ì •ê·œí™”\n",
    "    - ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì„ ìœ„í•œ ë°ì´í„° í˜•ì‹ ë³€í™˜\n",
    "\n",
    "2. **ì‚¬ìš© ì‹œ ê³ ë ¤ì‚¬í•­**\n",
    "    - OpenAI function callingê³¼ ê°™ì€ ê¸°ëŠ¥ì´ ìˆëŠ” ê²½ìš°, í•´ë‹¹ ê¸°ëŠ¥ì„ ìš°ì„  ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) StrOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¼ë¡ ì…ë‹ˆë‹¤! ì„œìš¸ì€ ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì´ì ê°€ì¥ í° ë„ì‹œë¡œ, ë‹¤ì–‘í•œ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” íŠ¹ì§•ì„ ìš”ì•½í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì—­ì‚¬ì™€ ì „í†µ**\n",
      "   - 600ë…„ ì´ìƒì˜ ì—­ì‚¬ë¥¼ ì§€ë‹Œ ë„ì‹œë¡œ ì¡°ì„ ì‹œëŒ€(1392~1910)ë¶€í„° ìˆ˜ë„ì˜€ìŠµë‹ˆë‹¤.\n",
      "   - ê²½ë³µê¶, ì°½ë•ê¶, ë•ìˆ˜ê¶ ë“± ìœ ì„œ ê¹Šì€ ê¶ê¶ë“¤ì´ ë„ì‹¬ì— ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **í˜„ëŒ€ì™€ ì²¨ë‹¨**\n",
      "   - ì„¸ê³„ì ì¸ ê·œëª¨ì˜ ê³ ì¸µ ë¹Œë”©, ê°•ë‚¨, ì—¬ì˜ë„ì™€ ê°™ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ì§€ì—­, ì‚¼ì„±, SK, í˜„ëŒ€ ë“± ê¸€ë¡œë²Œ ëŒ€ê¸°ì—… ë³¸ì‚¬ê°€ ë°€ì§‘í•´ ìˆìŠµë‹ˆë‹¤.\n",
      "   - ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ì¸í„°ë„· ì¸í”„ë¼ì™€ êµí†µ ì‹œìŠ¤í…œ(ì§€í•˜ì² , ë²„ìŠ¤)ì„ ìë‘í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì¸êµ¬ì™€ ê·œëª¨**\n",
      "   - ì¸êµ¬ ì•½ 960ë§Œ ëª…(2024ë…„ ê¸°ì¤€)ì´ ê±°ì£¼í•˜ëŠ” í•œêµ­ ìµœëŒ€ ë„ì‹œì…ë‹ˆë‹¤.\n",
      "   - ì£¼ë³€ ê²½ê¸° ì§€ì—­ê³¼ í•¨ê»˜ â€˜ìˆ˜ë„ê¶Œâ€™ì´ë¼ ë¶ˆë¦¬ë©° ì¸êµ¬ 2ì²œ5ë°±ë§Œ ëª…ì´ ì‚´ì•„ê°€ëŠ” ê±°ëŒ€í•œ ë„ì‹œê¶Œì„ í˜•ì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. **ë¬¸í™”ì™€ ë¼ì´í”„ìŠ¤íƒ€ì¼**\n",
      "   - í•œë¥˜(K-pop, ë“œë¼ë§ˆ, ì˜í™”) ë¬¸í™”ì˜ ì¤‘ì‹¬ì§€ë¡œ, ë‹¤ì–‘í•œ ê³µì—°, ë¯¸ìˆ ê´€, ë°•ë¬¼ê´€ì´ í™œë°œíˆ ìš´ì˜ë©ë‹ˆë‹¤.\n",
      "   - ì „í†µê³¼ í˜„ëŒ€ê°€ ê³µì¡´í•˜ëŠ” ë„ì‹œë¡œ, ì¸ì‚¬ë™, ë¶ì´Œ í•œì˜¥ë§ˆì„ê³¼ ê°™ì€ ì „í†µ ê±°ë¦¬ì™€, í™ëŒ€, ê°•ë‚¨, ì´íƒœì› ë“± í˜„ëŒ€ì ì´ê³  íŠ¸ë Œë””í•œ ì§€ì—­ì´ ê³µì¡´í•©ë‹ˆë‹¤.\n",
      "\n",
      "5. **ê´€ê´‘ëª…ì†Œ**\n",
      "   - ë‚¨ì‚°íƒ€ì›Œ, í•œê°•ê³µì›, ë™ëŒ€ë¬¸ë””ìì¸í”Œë¼ì(DDP), ë¡¯ë°ì›”ë“œíƒ€ì›Œ ë“± ë‹¤ì–‘í•œ ëœë“œë§ˆí¬ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "   - ì‡¼í•‘, ë¯¸ì‹, ì•¼ê²½ ë“± ë‹¤ì–‘í•œ ì¦ê¸¸ ê±°ë¦¬ê°€ í’ë¶€í•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ìì—°ê³¼ ì¡°ê²½**\n",
      "   - ë„ì‹¬ í•œê°€ìš´ë°ë¥¼ íë¥´ëŠ” í•œê°•ê³¼, ë¶í•œì‚°, ë‚¨ì‚° ë“± ë‹¤ì–‘í•œ ì‚°ê³¼ ìì—°ê³µì›ì´ ìˆì–´, ì‹œë¯¼ë“¤ì´ ì‰½ê²Œ ìì—°ì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "7. **êµìœ¡, ì˜ë£Œ**\n",
      "   - ì„œìš¸ëŒ€í•™êµ, ì—°ì„¸ëŒ€í•™êµ, ê³ ë ¤ëŒ€í•™êµ ë“± ëª…ë¬¸ ëŒ€í•™ì´ ìœ„ì¹˜í•´ ìˆê³ , ì˜ë£Œ ì‹œìŠ¤í…œë„ ë°œë‹¬í•´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì¢…í•©ì ìœ¼ë¡œ, ì„œìš¸ì€ ì—­ì‚¬ì™€ í˜„ëŒ€, ì „í†µê³¼ í˜ì‹ ì´ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ë‹¤ì±„ë¡œìš´ ë„ì‹œë¡œ êµ­ì œì ì¸ ìœ„ìƒì„ ê°€ì§„ ëŒ€ë„ì‹œì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê¸°ë³¸ì ì¸ ë¬¸ìì—´ íŒŒì„œ ì‚¬ìš©\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate.from_template(\"ë„ì‹œ {city}ì˜ íŠ¹ì§•ì„ ì•Œë ¤ì£¼ì„¸ìš”\")\n",
    "\n",
    "# ëª¨ë¸ ì •ì˜\n",
    "model = ChatOpenAI(model=\"gpt-4.1-2025-04-14\")\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"city\": \"ì„œìš¸\"})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) êµ¬ì¡°í™”ëœ ì¶œë ¥ (with_structured_output ë©”ì†Œë“œ)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "\n",
    "# Pydantic í´ë˜ìŠ¤ë¡œ ì¶œë ¥ êµ¬ì¡°ë¥¼ ì •ì˜\n",
    "\n",
    "\n",
    "class CityInfo(BaseModel):\n",
    "\n",
    "    name: str = Field(description=\"ë„ì‹œ ì´ë¦„\")\n",
    "\n",
    "    description: str = Field(description=\"ë„ì‹œì˜ íŠ¹ì§•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='ë¯¸êµ­, ì´ë€ í•µì‹œì„¤ ê³µìŠµ ì •ë‹¹í™”í•˜ë©° í˜‘ìƒ ì˜ì§€ ì¬í™•ì¸' content=\"ë„ë„ë“œ íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ëŠ” 2025ë…„ 6ì›” 21ì¼ ì´ë€ í•µì‹œì„¤ì— ëŒ€í•œ ê³µìŠµì„ ì´ë€ì˜ í•µë¬´ê¸° ê°œë°œì„ ë§‰ê¸° ìœ„í•œ í•„ìˆ˜ ì¡°ì¹˜ë¡œ ì •ë‹¹í™”í–ˆë‹¤. ë¯¸êµ­ì€ ì´ë€ì˜ ì •ê¶Œ êµì²´ë¥¼ ì›í•˜ì§€ ì•Šìœ¼ë©° í˜‘ìƒí•  ì¤€ë¹„ê°€ ë˜ì–´ ìˆë‹¤ê³  ë°í˜”ë‹¤. J.D. ë°´ìŠ¤ ë¶€í†µë ¹ì€ ì´ë€ê³¼ì˜ ì „ìŸì´ë‚˜ ì •ê¶Œ êµì²´ë¥¼ ì›í•˜ì§€ ì•Šìœ¼ë©°, ì´ë€ì´ í•µë¬´ê¸° í”„ë¡œê·¸ë¨ì„ í•´ì²´í•˜ëŠ” 'ë˜‘ë˜‘í•œ ê¸¸'ì„ ì„ íƒí•˜ê¸¸ ë°”ë€ë‹¤ê³  ë§í–ˆë‹¤. í”¼íŠ¸ í—¤ê·¸ì„¸ìŠ¤ êµ­ë°©ë¶€ ì¥ê´€ì€ ì´ë²ˆ ì‘ì „ì´ ì œí•œì ì´ë©° ì „ë©´ì „ì´ ì•„ë‹ˆë¼ê³  ê°•ì¡°í–ˆë‹¤. ë§ˆì½” ë£¨ë¹„ì˜¤ êµ­ë¬´ë¶€ ì¥ê´€ì€ ì´ë€ì´ ì›í•œë‹¤ë©´ ì¦‰ì‹œ í˜‘ìƒí•  ì¤€ë¹„ê°€ ë˜ì–´ ìˆë‹¤ê³  ë°í˜”ë‹¤. í•œí¸, ë¯¸êµ­ ë‚´ì—ì„œëŠ” ì´ë²ˆ ê³µìŠµì— ëŒ€í•œ ìš°ë ¤ì™€ ë¹„íŒë„ ì¡´ì¬í•˜ë©°, íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì€ ê³µìŠµì„ ë¹„íŒí•œ ê³µí™”ë‹¹ í†° ë§¤ì‹œ í•˜ì›ì˜ì›ì„ ê°•í•˜ê²Œ ë¹„ë‚œí–ˆë‹¤.\" names='ë„ë„ë“œ íŠ¸ëŸ¼í”„, J.D. ë°´ìŠ¤, í”¼íŠ¸ í—¤ê·¸ì„¸ìŠ¤, ë§ˆì½” ë£¨ë¹„ì˜¤, í†° ë§¤ì‹œ, ì§ í•˜ì„ìŠ¤' office='ì—°í•©ë‰´ìŠ¤'\n",
      "--------------------\n",
      "ë¯¸êµ­, ì´ë€ í•µì‹œì„¤ ê³µìŠµ ì •ë‹¹í™”í•˜ë©° í˜‘ìƒ ì˜ì§€ ì¬í™•ì¸\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 1. ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "class NewsInfo(BaseModel):\n",
    "    title: str = Field(description=\"ë‰´ìŠ¤ ì œëª©\")\n",
    "    content: str = Field(description=\"ë‰´ìŠ¤ ë³¸ë¬¸\")\n",
    "    names: str = Field(description=\"ê¸°ì ì´ë¦„\")\n",
    "    office: str = Field(description=\"ì‹ ë¬¸ì‚¬\")\n",
    "\n",
    "\n",
    "# 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "prompt = PromptTemplate.from_template(\"ë‰´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš” ë‰´ìŠ¤: {news}\")\n",
    "\n",
    "# 3. ëª¨ë¸ ìƒì„± ë° êµ¬ì¡°í™”ëœ ì¶œë ¥ ë°”ì¸ë”©\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini-2025-04-14\", temperature=0)\n",
    "structured_model = model.with_structured_output(NewsInfo)\n",
    "\n",
    "# 4. í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ ì²´ì¸ ì—°ê²°\n",
    "chain = prompt | structured_model\n",
    "\n",
    "# 5. ì²´ì¸ ì‹¤í–‰\n",
    "result = chain.invoke(\n",
    "    {\n",
    "        \"news\": \"ì—°í•©ë‰´ìŠ¤ êµ¬ë…ì¤‘PICK ì•ˆë‚´\\\n",
    "[ç¾ ì´ë€ ê³µê²©] ç¾ì •ë¶€ 'ì´ë€, ì§„ì •ì„± ë³´ì´ì§€ì•Šì•„ íƒ€ê²©â€¦ë‚´ì¼ì´ë¼ë„ í˜‘ìƒì¤€ë¹„ë¼'\\\n",
    "ì…ë ¥2025.06.23. ì˜¤ì „ 4:36  ìˆ˜ì •2025.06.23. ì˜¤ì „ 4:37 ê¸°ì‚¬ì›ë¬¸\\\n",
    "ê¹€ë™í˜„ ê¸°ì\\\n",
    "ì—¬ë¡ ì „ ì† 'ì „ìŸ ìˆ˜ë ' ìš°ë ¤ ì°¨ë‹¨â€¦'ì´ë€ì˜ ì •ê¶Œêµì²´ë‚˜ ì „ë©´ì „ ì›í•˜ì§€ ì•Šì•„'\\\n",
    "'ç¾ì˜ ì–µì œë ¥ íšŒë³µ, ì „ì„¸ê³„ì— ë³´ì—¬ì¤¬ë‹¤â€¦ë¯¸êµ­ì´ ë§í•  ë•Œ ì„¸ê³„ëŠ” ê·€ ê¸°ìš¸ì—¬ì•¼'\\\n",
    "íŠ¸ëŸ¼í”„, ê³µìŠµ ë¹„íŒí•œ ê³µí™”ë‹¹ ë§¤ì‹œ í•˜ì› ì˜ì› ë§¹ë¹„ë‚œâ€¦'í•œì‹¬í•œ íŒ¨ë°°ì'\\\n",
    "ì´ë€ ê³µìŠµ ë‹´í™”í•˜ëŠ” íŠ¸ëŸ¼í”„ ë¯¸êµ­ ëŒ€í†µë ¹\\\n",
    "(ì›Œì‹±í„´ AP=ì—°í•©ë‰´ìŠ¤) ë„ë„ë“œ íŠ¸ëŸ¼í”„ ë¯¸êµ­ ëŒ€í†µë ¹ì´ 2025ë…„ 6ì›” 21ì¼(í˜„ì§€ì‹œê°„) ë°±ì•…ê´€ì—ì„œ ë¯¸êµ°ì˜ ì´ë€ í•µì‹œì„¤ ê³µìŠµê³¼ ê´€ë ¨í•´ ëŒ€êµ­ë¯¼ ë‹´í™”ë¥¼ í•˜ê³  ìˆë‹¤. íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ ë’¤ë¡œ ì™¼ìª½ë¶€í„° J.D. ë°´ìŠ¤ ë¶€í†µë ¹, ë§ˆì½” ë£¨ë¹„ì˜¤ êµ­ë¬´ë¶€ ì¥ê´€, í”¼íŠ¸ í—¤ê·¸ì„¸ìŠ¤ êµ­ë°©ë¶€ ì¥ê´€ì´ ì„œ ìˆë‹¤. 2025.6.22\\\n",
    "(ì›Œì‹±í„´=ì—°í•©ë‰´ìŠ¤) ê¹€ë™í˜„ íŠ¹íŒŒì› = ë¯¸êµ­ ë„ë„ë“œ íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ëŠ” 22ì¼(í˜„ì§€ì‹œê°„) ì´ë€ í•µì‹œì„¤ì„ ê²¨ëƒ¥í•œ ì „ë‚ ì˜ ê³µìŠµì€ ì´ë€ì˜ í•µë¬´ê¸° ê°œë°œì„ ë§‰ëŠ” ë° í•„ìš”í–ˆë‹¤ë©´ì„œ ê·¸ ë‹¹ìœ„ì„±ì„ ì£¼ì¥í–ˆë‹¤.\\\n",
    "ë˜ ë¯¸êµ­ì€ ì´ë€ì˜ ì •ê¶Œ êµì²´ë¥¼ ì›í•˜ì§€ ì•Šê³  í˜‘ìƒí•  ì˜ì§€ê°€ ìˆë‹¤ëŠ” ì…ì¥ì„ ì¬ì°¨ ê°•ì¡°í•˜ë©´ì„œ ë¯¸êµ­ì´ ê³¼ê±° ì´ë¼í¬ì™€ ì•„í”„ê°€ë‹ˆìŠ¤íƒ„ ê°™ì€ ì¤‘ë™ ì „ìŸì˜ ìˆ˜ë ì— ë¹ ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” êµ­ë‚´ ìš°ë ¤ë¥¼ ì°¨ë‹¨í•˜ë ¤ê³  ë…¸ë ¥í–ˆë‹¤.\\\n",
    "J.D. ë°´ìŠ¤ ë¶€í†µë ¹ì€ ì´ë‚  ABCë‰´ìŠ¤ ì¸í„°ë·°ì—ì„œ ì´ë€ê³¼ì˜ ì „ìŸì´ë‚˜ ì´ë€ì˜ ì •ê¶Œ êµì²´ë¥¼ ì›í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼ë©´ì„œ 'ìš°ë¦¬ëŠ” ì´ë€ì˜ í•µ í”„ë¡œê·¸ë¨ê³¼ ì „ìŸí•˜ê³  ìˆë‹¤'ê³  ê·œì •í–ˆë‹¤.\\\n",
    "ê·¸ëŠ” ì´ë€ì´ í•µë¬´ê¸° í”„ë¡œê·¸ë¨ì„ í•´ì²´í•˜ëŠ” 'ë˜‘ë˜‘í•œ ê¸¸'ì„ ì„ íƒí•˜ê¸°ë¥¼ ë°”ë€ë‹¤ë©´ì„œ 'ë§Œì•½ ì´ë€ì´ ìš°ë¦¬ ì¥ë³‘ë“¤ì„ ê³µê²©í•˜ê±°ë‚˜ í•µë¬´ê¸°ë¥¼ ë§Œë“¤ë ¤ê³  ê³„ì† ì‹œë„í•˜ê¸°ë¡œ ê²°ì •í•œë‹¤ë©´ ìš°ë¦¬ëŠ” ì••ë„ì ì¸ ë¬´ë ¥ìœ¼ë¡œ ëŒ€ì‘í•  ê²ƒ'ì´ë¼ê³  ê²½ê³ í–ˆë‹¤.\\\n",
    "ê·¸ëŠ” ë¯¸êµ­ì´ ì¤‘ë™ì—ì„œ ë˜ ë‹¤ë¥¸ ì¥ê¸° ë¶„ìŸì— íœ˜ë§ë¦´ ìˆ˜ ìˆë‹¤ëŠ” ìš°ë ¤ì— ëŒ€í•´ì„œëŠ” 'ìš°ë¦¬ëŠ” ì´ë€ì˜ í•µ í”„ë¡œê·¸ë¨ì„ íŒŒê´´í•˜ê¸° ìœ„í•´ ë§¤ìš° ì¢ê³  ì œí•œì ì¸ ì ‘ê·¼ì„ íƒí–ˆë‹¤'ë©´ì„œ 'ëŒ€í†µë ¹ì€ ê·¸ ëˆ„êµ¬ë³´ë‹¤ ë” êµ°ì‚¬ ë¶„ìŸì˜ ì¥ê¸°í™”ë¥¼ ê±±ì •í•˜ê³  ìˆë‹¤'ê³  ì„¤ëª…í–ˆë‹¤.\\\n",
    "ì´ë€ ê³µìŠµ ë‹¹ì‹œ ë°±ì•…ê´€ ìƒí™©ì‹¤ì— ìˆëŠ” íŠ¸ëŸ¼í”„ ë¯¸êµ­ ëŒ€í†µë ¹\\\n",
    "[AP ì—°í•©ë‰´ìŠ¤ ìë£Œì‚¬ì§„. ì¬íŒë§¤ ë° DB ê¸ˆì§€]\\\n",
    "í”¼íŠ¸ í—¤ê·¸ì„¸ìŠ¤ êµ­ë°©ë¶€ ì¥ê´€ë„ ì´ë‚  ë¸Œë¦¬í•‘ì—ì„œ 'ì´ë€ ë³‘ë ¥ì´ë‚˜ ì´ë€ êµ­ë¯¼ì„ ê²¨ëƒ¥í•˜ì§€ ì•Šì•˜ë‹¤'ë©´ì„œ ì´ë²ˆ ì‘ì „ì´ ì „ë©´ì „ì´ ì•„ë‹ˆë¼ ì´ë€ì˜ í•µì‹œì„¤ë§Œì„ ê²¨ëƒ¥í•œ ì œí•œì ì¸ ê³µìŠµì´ë¼ê³  ê°•ì¡°í–ˆë‹¤.\\\n",
    "í—¤ê·¸ì„¸ìŠ¤ ì¥ê´€ì€ 'ê³µê°œ ë° ë¹„ê³µê°œ ë©”ì‹œì§€ë¥¼ ì—¬ëŸ¬ ì±„ë„ì„ í†µí•´ ì´ë€ì— ì§ì ‘ ì „ë‹¬í•˜ë©´ì„œ ì´ë€ì´ (ëŒ€í™”) í…Œì´ë¸”ë¡œ ì˜¬ ëª¨ë“  ê¸°íšŒë¥¼ ì£¼ê³  ìˆë‹¤. ì´ë€ì€ ë¯¸êµ­ì˜ ì…ì¥ê³¼ í‰í™”ë¥¼ í—ˆìš©í•˜ê¸° ìœ„í•´ ê·¸ë“¤ì´ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì¡°ì¹˜ë¥¼ í•´ì•¼ í•˜ëŠ”ì§€ ì •í™•íˆ ì•Œê³  ìˆìœ¼ë©° ìš°ë¦¬ëŠ” ì´ë€ì´ ê·¸ë ‡ê²Œ í•˜ê¸°ë¥¼ ë°”ë€ë‹¤'ê³  ë§í–ˆë‹¤.\\\n",
    "ë§ˆì½” ë£¨ë¹„ì˜¤ êµ­ë¬´ë¶€ ì¥ê´€ì€ ì´ë‚  í­ìŠ¤ë‰´ìŠ¤ ì¸í„°ë·°ì—ì„œ ì´ë€ì˜ ì •ê¶Œ êµì²´ê°€ ëª©ì ì´ ì•„ë‹ˆë¼ê³  ì„¤ëª…í•˜ê³ ì„œ ë¯¸êµ­ì€ ì´ë€ì´ ì›í•˜ë©´ ë‚´ì¼ì´ë¼ë„ ë°”ë¡œ í˜‘ìƒí•  ì¤€ë¹„ê°€ ëë‹¤ê³  ë°í˜”ë‹¤.\\\n",
    "ë‹¤ë§Œ ê·¸ëŠ” 'ì´ë€ì´ ê³„ì†í•´ì„œ í•µë¬´ê¸° ë³´ìœ êµ­ì´ ë˜ê³ ì í•œë‹¤ë©´ ë‚œ ê·¸ê²Œ ì •ê¶Œì„ ìœ„íƒœë¡­ê²Œ í•  ê²ƒì´ë¼ ì •ë§ë¡œ ìƒê°í•œë‹¤'ê³  ë§í•´ ì–´ë–¤ ê²½ìš°ì—ë„ ì´ë€ì˜ í•µë¬´ê¸° ê°œë°œì„ í—ˆìš©í•  ìˆ˜ ì—†ë‹¤ëŠ” ì…ì¥ì„ ë¶„ëª…íˆ í–ˆë‹¤.\\\n",
    "ë£¨ë¹„ì˜¤ ì¥ê´€ì€ ì´ë€ì´ ê·¸ê°„ ë¯¸êµ­ê³¼ì˜ í˜‘ìƒì—ì„œ 'íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì„ ê°€ì§€ê³  ë†€ë ¤ê³  í–ˆë‹¤'ë©´ì„œ ì´ë€ì´ í•µë¬´ê¸°ë¥¼ í¬ê¸°í•˜ê² ë‹¤ëŠ” ì§„ì •ì„±ì„ ë³´ì´ì§€ ì•Šì•„ í•µì‹œì„¤ì„ íƒ€ê²©í•  ìˆ˜ë°–ì— ì—†ì—ˆë‹¤ê³  ì„¤ëª…í–ˆë‹¤.\\\n",
    "íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ ê³ ìœ„ë‹¹êµ­ìë“¤ì€ ì´ë²ˆ ê³µìŠµì„ í†µí•´ ì´ë€ë¿ë§Œ ì•„ë‹ˆë¼ ë¯¸êµ­ì˜ ë‹¤ë¥¸ ì ë“¤ì—ê²Œë„ ë¯¸êµ­ì„ ê±°ìŠ¤ë¥´ì§€ ë§ë¼ëŠ” ê²½ê³  ë©”ì‹œì§€ë¥¼ ì „í•˜ê³ ì í•œë‹¤ëŠ” ì ì„ ë¶„ëª…íˆ í–ˆë‹¤.\\\n",
    "í—¤ê·¸ì„¸ìŠ¤ ì¥ê´€ì€ 'ë¯¸êµ­ì˜ ì–µì œë ¥ì„ ë˜ì°¾ì•˜ë‹¤ëŠ” ê²ƒì„ ì„¸ê³„ì— ë³´ì—¬ì¤¬ë‹¤'ë©´ì„œ 'ì´ ëŒ€í†µë ¹ì´ ë§í•  ë•Œ ì„¸ê³„ëŠ” ê·€ ê¸°ìš¸ì—¬ì•¼ í•œë‹¤'ê³  ì£¼ë¬¸í–ˆë‹¤.\\\n",
    "ë£¨ë¹„ì˜¤ ì¥ê´€ì€ ì´ë€ì²˜ëŸ¼ í–‰ë™í•´ì„œëŠ” ì•ˆ ëœë‹¤ëŠ” ì‚¬ì‹¤ì„ ì„¸ê³„ê°€ ê¹¨ë‹¬ì•˜ì„ ê²ƒì´ë¼ë©° 'íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì€ ìê¸°ê°€ ë¬´ì—‡ì„ í•  ê²ƒì¸ì§€ ë§í•´ì£¼ê³  ì‹¤ì œë¡œ í•˜ëŠ” ëŒ€í†µë ¹ì´ë©° ê·¸ëŸ° ì ì´ ì´ë€ ì •ê¶Œì„ í¬í•¨í•œ ë§ì€ ì‚¬ëŒì—ê²Œ ì¶©ê²©ì ì´ë¼ê³  ìƒê°í•œë‹¤'ê³  ë§í–ˆë‹¤.\\\n",
    "ë¯¸êµ­ ê³µí™”ë‹¹ì˜ ë§¤ì‹œ í•˜ì›ì˜ì›\\\n",
    "[AFP ì—°í•©ë‰´ìŠ¤ ìë£Œì‚¬ì§„. ì¬íŒë§¤ ë° DB ê¸ˆì§€]\\\n",
    "ì´ëŸ° ê°€ìš´ë° ì •ì¹˜ê¶Œì—ì„œëŠ” ë¯¸êµ­ì´ ì´ë€ê³¼ ë§¤ìš° ë¹„ì‹¸ê³  ê¸´ ì „ìŸì„ ì¹˜ë¥´ê²Œ ë  ìˆ˜ ìˆë‹¤ëŠ” ìš°ë ¤ê°€ ë¯¼ì£¼ë‹¹ê³¼ ê³µí™”ë‹¹ ì¼ê°ì—ì„œ ê³„ì† ì œê¸°ë˜ê³  ìˆë‹¤.\\\n",
    "í•˜ì› ì •ë³´ìœ„ì›íšŒì˜ ë¯¼ì£¼ë‹¹ ê°„ì‚¬ì¸ ì§ í•˜ì„ìŠ¤ í•˜ì›ì˜ì›ì€ ABC ì¸í„°ë·°ì—ì„œ 'ëŒ€í†µë ¹ì´ ì—„ì²­ë‚œ ë„ë°•ì„ í–ˆë‹¤'ë©° 'ì¤‘ë™ ì§€ì—­ì—ì„œ ìš°ë¦¬ê°€ êµ°ì‚¬ì ìœ¼ë¡œ ê°œì…í•œ ì—­ì‚¬ë¥¼ ë³´ë©´ ìµœìƒì˜ ì‹œë‚˜ë¦¬ì˜¤ëŒ€ë¡œ ëë‚˜ëŠ” ì ì´ ê±°ì˜ ì ˆëŒ€ ì—†ë‹¤. ì‹¤ì œë¡œëŠ” ë³´í†µ ìµœì•…ì˜ ì‹œë‚˜ë¦¬ì˜¤ì— ê°€ê¹Œìš´ ê²ƒìœ¼ë¡œ ëë‚œë‹¤'ê³  ë§í–ˆë‹¤.\\\n",
    "ê³µí™”ë‹¹ ë‚´ì—ì„œ ì´ë¡€ì ìœ¼ë¡œ ì´ë²ˆ ê³µìŠµì„ ë¹„íŒí•œ í†° ë§¤ì‹œ í•˜ì›ì˜ì›ì€ CBSë‰´ìŠ¤ ì¸í„°ë·°ì—ì„œ íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì´ ë¯¸êµ­ì„ ìš°ì„ í•˜ê² ë‹¤ê³  ì•½ì†í–ˆì§€ë§Œ ë¯¸êµ­ì„ ì§ì ‘ì ìœ¼ë¡œ ìœ„í˜‘í•˜ì§€ ì•ŠëŠ” ì´ë€ê³¼ ì‹¸ìš°ê³  ìˆë‹¤ë©´ì„œ 'ìš°ë¦¬ëŠ” ì´ ëª¨ë“  ì „ìŸ ë•Œë¬¸ì— ì§€ì³¤ë‹¤'ê³  ë°í˜”ë‹¤.\\\n",
    "ë§¤ì‹œ ì˜ì›ì€ ì§€ë‚œ 17ì¼ ë¯¼ì£¼ë‹¹ ì˜ì›ë“¤ê³¼ í•¨ê»˜ íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì´ ì´ë€ì„ ê³µê²©í•˜ê¸° ì „ ì˜íšŒì˜ ìŠ¹ì¸ì„ ë°›ë„ë¡ í•˜ëŠ” 'ì „ìŸ ê¶Œí•œ ê²°ì˜ì•ˆ'ì„ ë°œì˜í–ˆìœ¼ë©° ëŒ€í†µë ¹ì´ ë‹¨ë…ìœ¼ë¡œ ê²°ì •í•œ ì´ë²ˆ ê³µìŠµì„ ìœ„í—Œì´ë¼ê³  ë¹„íŒí•œ ë°” ìˆë‹¤.\\\n",
    "íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì€ ì´ë‚  ì‚¬íšŒê´€ê³„ë§ì„œë¹„ìŠ¤(SNS) íŠ¸ë£¨ìŠ¤ì†Œì…œì— ì¥ë¬¸ì˜ ê¸€ì„ ì˜¬ë ¤ ë§¤ì‹œ ì˜ì›ì„ ë§¹ë¹„ë‚œí–ˆë‹¤.\\\n",
    "íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì€ 'ê·¸ëŠ” ìê¸°ê°€ ë§ˆê°€(MAGAÂ·íŠ¸ëŸ¼í”„ í•µì‹¬ ì§€ì§€ì¸µ)ë¼ê³  ë§í•˜ê¸°ë¥¼ ì¢‹ì•„í•˜ì§€ë§Œ, ë§ˆê°€ê°€ ì•„ë‹ˆë‹¤. ì‹¤ì œë¡œ ë§ˆê°€ëŠ” ê·¸ë¥¼ ì›í•˜ì§€ ì•Šê³  ê·¸ë¥¼ ëª¨ë¥´ë©° ê·¸ë¥¼ ì¡´ì¤‘í•˜ì§€ ì•ŠëŠ”ë‹¤'ë©´ì„œ 'ë§ˆê°€ëŠ” ì´ í•œì‹¬í•œ íŒ¨ë°°ìì¸ í†° ë§¤ì‹œë¥¼ ì—­ë³‘ì²˜ëŸ¼ ë©€ë¦¬í•´ì•¼ í•œë‹¤'ê³  ì ì—ˆë‹¤.\\\n",
    "ì´ì–´ 'ë§¤ì‹œëŠ” ì•½í•˜ê³  ë¬´ëŠ¥í•˜ë©° ì–´ë–¤ ê²Œ ì•„ë¬´ë¦¬ ì¢‹ë‹¤ê³  í•´ë„ ìê¸° ì•ì— ë†“ì¸ ì‚¬ì‹¤ìƒ ëª¨ë“  ê²ƒì— 'ì•„ë‹ˆìš”'ë¼ê³  íˆ¬í‘œí•œë‹¤. ê·¸ëŠ” ìš°ë¦¬ì˜ ìœ„ëŒ€í•œ êµ°ëŒ€ì™€ êµ°ëŒ€ê°€ ìƒì§•í•˜ëŠ” ëª¨ë“  ê²ƒì— ë¬´ë¡€í•˜ë©°, ì‹¬ì§€ì–´ ìš°ë¦¬ êµ°ëŒ€ê°€ ì™„ì „í•˜ê³  ì „ì ìœ¼ë¡œ ìŠ¹ë¦¬í•œ ì–´ì œì˜ ê³µê²©ì—ì„œ ë³´ì—¬ì¤€ íƒì›”í•¨ê³¼ ìš©ë§¹ë„ ì¸ì •í•˜ì§€ ì•ŠëŠ”ë‹¤'ê³  ë¹„íŒí–ˆë‹¤.\\\n",
    "bluekey@yna.co.kr\\\n",
    "ê¹€ë™í˜„(bluekey@yna.co.kr)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 6. ê²°ê³¼ ì¶œë ¥ (CityInfo ê°ì²´)\n",
    "print(result)\n",
    "print(\"-\" * 20)\n",
    "print(result.title)\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ë©”ëª¨ë¦¬ (Memory)\n",
    "- ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ê³  ê´€ë¦¬\n",
    "- ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ ë©”ëª¨ë¦¬ íƒ€ì…ì„ ì œê³µ\n",
    "- ëŒ€í™” ìš”ì•½, ë²„í¼ë§ ë“±ì˜ ê¸°ëŠ¥ì„ í¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ê¸°ë°˜ íˆìŠ¤í† ë¦¬ êµ¬í˜„\n",
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    \"\"\"ë©”ëª¨ë¦¬ ê¸°ë°˜ ì±„íŒ… ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬\"\"\"\n",
    "\n",
    "    # ë©”ì‹œì§€ ëª©ë¡\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "\n",
    "    # ë©”ì‹œì§€ ì¶”ê°€\n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        self.messages.extend(messages)\n",
    "\n",
    "    # ë©”ì‹œì§€ ëª©ë¡ ì´ˆê¸°í™”\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "\n",
    "\n",
    "# ì„¸ì…˜ ì €ì¥ì†Œ\n",
    "store = {}\n",
    "\n",
    "\n",
    "# ì„¸ì…˜ IDë¡œ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    \"\"\"ì„¸ì…˜ IDì— í•´ë‹¹í•˜ëŠ” ì±„íŒ… ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "    # ì„¸ì…˜ IDê°€ ì €ì¥ì†Œì— ì—†ìœ¼ë©´ ìƒˆ InMemoryHistory ê°ì²´ ìƒì„±\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "\n",
    "    # í•´ë‹¹ ì„¸ì…˜ IDì˜ íˆìŠ¤í† ë¦¬ ë°˜í™˜\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì±„íŒ… ëª¨ë¸ê³¼ í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ {subject}ì— ëŠ¥ìˆ™í•œ ë¹„ì„œì…ë‹ˆë‹¤\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | ChatOpenAI(model=\"gpt-4.1-mini-2025-04-14\")\n",
    "\n",
    "# íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ì¶”ê°€\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,  # ì‹¤í–‰ ì²´ì¸\n",
    "    get_session_history,  # ì„¸ì…˜ IDì— í•´ë‹¹í•˜ëŠ” íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "    input_messages_key=\"question\",  # ì…ë ¥ ë©”ì‹œì§€ í‚¤\n",
    "    history_messages_key=\"history\",  # íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ í‚¤\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1+2ëŠ” 3ì…ë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 31, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlSlciZmKyvncDv1OnTLcP7sPk7rr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--6a45ba24-1821-42c9-a90c-876e65127bf6-0' usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ ì‹¤í–‰\n",
    "response = chain_with_history.invoke(\n",
    "    {\"subject\": \"ìˆ˜í•™\", \"question\": \"1+2ëŠ” ì–¼ë§ˆì¸ê°€ìš”?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}},\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='1+2ëŠ” ì–¼ë§ˆì¸ê°€ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='1+2ëŠ” 3ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 31, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlSlciZmKyvncDv1OnTLcP7sPk7rr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6a45ba24-1821-42c9-a90c-876e65127bf6-0', usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì„¸ì…˜ IDë¡œ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°\n",
    "get_session_history(\"user1\").messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1+2ëŠ” 3ì´ê³ , ì—¬ê¸°ì— ìˆ«ì 2ë¥¼ ê³±í•˜ë©´ 3 Ã— 2 = 6ì…ë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 61, 'total_tokens': 89, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlSm0BXvyXJSIfZx8RGF3kPzarWeo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--c6d1cd6f-71e6-4157-be09-03662cb84785-0' usage_metadata={'input_tokens': 61, 'output_tokens': 28, 'total_tokens': 89, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# íˆìŠ¤í† ë¦¬ ì´ìš©í•´ì„œ ëŒ€í™” ì§„í–‰\n",
    "response = chain_with_history.invoke(\n",
    "    {\"subject\": \"ìˆ˜í•™\", \"question\": \"ì—¬ê¸°ì— ìˆ«ì 2ë¥¼ ê³±í•˜ë©´ ì–¼ë§ˆì¸ê°€ìš”?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}},\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='1+2ëŠ” ì–¼ë§ˆì¸ê°€ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='1+2ëŠ” 3ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 31, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlSlciZmKyvncDv1OnTLcP7sPk7rr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6a45ba24-1821-42c9-a90c-876e65127bf6-0', usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='ì—¬ê¸°ì— ìˆ«ì 2ë¥¼ ê³±í•˜ë©´ ì–¼ë§ˆì¸ê°€ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='1+2ëŠ” 3ì´ê³ , ì—¬ê¸°ì— ìˆ«ì 2ë¥¼ ê³±í•˜ë©´ 3 Ã— 2 = 6ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 61, 'total_tokens': 89, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BlSm0BXvyXJSIfZx8RGF3kPzarWeo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c6d1cd6f-71e6-4157-be09-03662cb84785-0', usage_metadata={'input_tokens': 61, 'output_tokens': 28, 'total_tokens': 89, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì„¸ì…˜ IDë¡œ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°\n",
    "get_session_history(\"user1\").messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. ì—ì´ì „íŠ¸ (Agent)\n",
    "- ììœ¨ì  ì˜ì‚¬ê²°ì •ì´ ê°€ëŠ¥í•œ ì‹¤í–‰ ë‹¨ìœ„\n",
    "- LangChainì—ì„œëŠ” Agent í´ë˜ìŠ¤ë¥¼ í†µí•´ ì—ì´ì „íŠ¸ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„± - ReAct ì—ì´ì „íŠ¸ì— í•„ìš”í•œ ë³€ìˆ˜ë“¤ í¬í•¨\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ìˆ˜í•™ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"agent_scratchpad\"\n",
    "        ),  # ì—ì´ì „íŠ¸ê°€ ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ë¥¼ ê¸°ë¡í•  í”Œë ˆì´ìŠ¤í™€ë”\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# ë„êµ¬ ì •ì˜\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"ë‘ ìˆ«ìë¥¼ ë”í•˜ëŠ” ë„êµ¬\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def subtract(a: float, b: float) -> float:\n",
    "    \"\"\"ë‘ ìˆ«ìë¥¼ ë¹¼ëŠ” ë„êµ¬\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "# ë„êµ¬ ëª©ë¡ ìƒì„±\n",
    "tools = [add, subtract]\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒì„± (ë„êµ¬ í˜¸ì¶œ)\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=ChatOpenAI(model=\"gpt-4.1-mini\"), tools=tools, prompt=prompt\n",
    ")\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰ ë„êµ¬ ì •ì˜\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,  # ë„êµ¬ í˜¸ì¶œ ì—ì´ì „íŠ¸\n",
    "    tools=tools,  # ë„êµ¬ ëª©ë¡\n",
    "    verbose=True,  # ìƒì„¸ ë¡œê·¸ ì¶œë ¥\n",
    ")\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "agent_executor.invoke({\"input\": \"100ê³¼ 200ì„ ë”í•˜ë©´ ì–¼ë§ˆì¸ê°€ìš”?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## [ì‹¤ìŠµ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ìƒˆë¡œìš´ ChatPromptTemplateì„ ë§Œë“œì„¸ìš”.\n",
    "   - ì‹œìŠ¤í…œ ë©”ì‹œì§€: \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³¼í•™ ì„ ìƒë‹˜ì…ë‹ˆë‹¤\"\n",
    "   - ëŒ€í™” ê¸°ë¡ì„ í¬í•¨\n",
    "   - ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì„ ìˆ˜ ìˆëŠ” í˜•ì‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. StrOutputParserë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒì„ êµ¬í˜„í•´ë³´ì„¸ìš”.\n",
    "   - ì•ì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰\n",
    "   - \"ì„­ì”¨ì˜¨ë„ì™€ í™”ì”¨ì˜¨ë„ ê´€ê³„\"ë¥¼ ì„¤ëª…í•´ ë‹¬ë¼ê³  ìš”ì²­í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ì‘ì„± \n",
    "   - ê²°ê³¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
